{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hessian__COVID19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rCIMJJrJ9Co"
      },
      "source": [
        "COVID-19 Lockdown Modelling: multi-objective Bayesian optimization using ESOP)\r\n",
        "\r\n",
        "GP EI: Newton-CG (exact GP EI Hessian) vs. L-BFGS-B (without Hessian)\r\n",
        "\r\n",
        "https://github.com/purushottamkar/esop\r\n",
        "\r\n",
        "https://arxiv.org/abs/2005.11257\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUs0l8uQL534",
        "outputId": "dd23ac52-06d2-4d2e-d1ea-0b301cb7af95"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyGPGO\n",
            "  Downloading https://files.pythonhosted.org/packages/8d/87/a113c91ba014708114f7635d5c0f6a5e5c773480c5f0a537b257a02d180d/pyGPGO-0.4.0.dev1.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (3.7)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (4.41.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2018.9)\n",
            "Building wheels for collected packages: pyGPGO\n",
            "  Building wheel for pyGPGO (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyGPGO: filename=pyGPGO-0.4.0.dev1-cp36-none-any.whl size=19867 sha256=67613ef4fedcc300ece1fb69d41a16585c5e39eb267b21f299e9ed7f62251266\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/27/04/c4fa3bfe194d36e3cd51542132f43415a6813114a5e8301acb\n",
            "Successfully built pyGPGO\n",
            "Installing collected packages: pyGPGO\n",
            "Successfully installed pyGPGO-0.4.0.dev1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-VEXg5Jy_1"
      },
      "source": [
        "## Import modules\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import scipy\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import time\r\n",
        "\r\n",
        "from pyGPGO.logger import EventLogger\r\n",
        "from pyGPGO.GPGO import GPGO\r\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\r\n",
        "from pyGPGO.acquisition import Acquisition\r\n",
        "from pyGPGO.covfunc import squaredExponential, matern52\r\n",
        "\r\n",
        "from collections import OrderedDict\r\n",
        "from joblib import Parallel, delayed\r\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\r\n",
        "from scipy.optimize import minimize\r\n",
        "from scipy.spatial.distance import cdist\r\n",
        "from scipy.stats import norm, binned_statistic as binStat\r\n",
        "from matplotlib.pyplot import rc\r\n",
        "rc('text', usetex=False)\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\r\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\r\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYrttVTMVVE"
      },
      "source": [
        "### https://github.com/purushottamkar/esop/utils.py\r\n",
        "\r\n",
        "### https://arxiv.org/abs/2005.11257\r\n",
        "\r\n",
        "### VIPER Model\r\n",
        "\r\n",
        "# Convenient named constants for indices for various parameters pertaining to an individual in the VIPER model\r\n",
        "IDX_SUS = 0 # Susceptibility\r\n",
        "IDX_VLD = 1 # Viral load\r\n",
        "IDX_RLD = 2 # Recovery load\r\n",
        "IDX_RST = 3 # Resistance (never changed - intrinsic to the individual)\r\n",
        "IDX_X = 4   # X coordinate (only changed if the individual is travelling)\r\n",
        "IDX_Y = 5   # Y coordinate (only changed if the individual is travelling)\r\n",
        "IDX_STA = 6 # State\r\n",
        "IDX_QRN = 7 # Is this individual quarantined or not\r\n",
        "IDX_DPR = 8 # Disease progression rate\r\n",
        "IDX_TI = 9  # Timestamp of infection (only changed at time of infection)\r\n",
        "IDX_TQ = 10 # Timestamp of quarantine\r\n",
        "IDX_TR = 11 # Timestamp of recovery/expiry (only changed at time of recovery/expiry)\r\n",
        "\r\n",
        "nParams = 12\r\n",
        "\r\n",
        "sqrt2 = np.sqrt(2)\r\n",
        "\r\n",
        "# Convenient named constants for various states of an individual\r\n",
        "# Being quarantined is not a medical state and so it is tracked\r\n",
        "# separately (see IDX_QRN above) -- this allows VIPER to quarantine\r\n",
        "ST_S = 0\t# Susceptible\r\n",
        "ST_E = 1\t# Exposed\r\n",
        "ST_I = 2\t# Infectious\r\n",
        "ST_R = 3\t# Recovered\r\n",
        "ST_X = 4\t# Expired\r\n",
        "\r\n",
        "nStates = 5\r\n",
        "\r\n",
        "# Convenient named constants useful for reporting stats\r\n",
        "SIDX_S = 0\t# Number of susceptible but non-recovered individuals\r\n",
        "SIDX_E = 1\t# Number of exposed individuals\r\n",
        "SIDX_I = 2\t# Number of infectious individuals\r\n",
        "SIDX_Q = 3\t# Number of quarantined individuals\r\n",
        "SIDX_R = 4\t# Number of recovered individuals\r\n",
        "SIDX_X = 5\t# Number of expired individuals\r\n",
        "SIDX_V = 6\t# Average virulence of the viral strains in E and I populations\r\n",
        "SIDX_EI = 7\t# Number of infected individuals\r\n",
        "SIDX_D = 8\t# Number of individuals infected each day\r\n",
        "\r\n",
        "nStats = 9\r\n",
        "\r\n",
        "# This class provides an encapsulation for the VIPER model as well as methods\r\n",
        "# to perform epidemiological simulations under lock-down, quarantining etc\r\n",
        "class Population:\r\n",
        "\t# The base constructor -- almost never used directly\r\n",
        "\tdef __init__( self, N, BIR, BCR, INC, BVL, VMR, QTH, BQP, XTH, BXP, BTR, BTD, BDPR, alphaInit, popIdx, ind, SUS, RST, X, Y ):\r\n",
        "\t\tself.N = N\r\n",
        "\t\tself.BIR = BIR\r\n",
        "\t\tself.BCR = BCR\r\n",
        "\t\tself.INC = INC\r\n",
        "\t\tself.BVL = BVL\r\n",
        "\t\tself.VMR = VMR\r\n",
        "\t\tself.QTH = QTH\r\n",
        "\t\tself.BQP = BQP\r\n",
        "\t\tself.XTH = XTH\r\n",
        "\t\tself.BXP = BXP\r\n",
        "\t\tself.BTR = BTR\r\n",
        "\t\tself.BTD = BTD\r\n",
        "\t\tself.BDPR = BDPR\r\n",
        "\t\tself.alphaInit = alphaInit\r\n",
        "\t\t\r\n",
        "\t\tself.popIdx = popIdx\r\n",
        "\t\tself.ind = ind\r\n",
        "\t\tself.SUS = SUS\r\n",
        "\t\tself.RST = RST\r\n",
        "\t\tself.X = X\r\n",
        "\t\tself.Y = Y\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using scalar values alone\r\n",
        "\t# This provides a generic population with location, SUS, RST values\r\n",
        "\t# set uniformly randomly. To use India-specific initialization, use\r\n",
        "\t# the patch provided by the class Demographics (see below and setup.py)\r\n",
        "\t\r\n",
        "\t# N: the size of the population before the pandemic began\r\n",
        "\t# BIR: the (base) probability that a contact event will lead to a successful infection\r\n",
        "\t# BCR: the (base) contact radius\r\n",
        "\t# INC: the incubation period for the virus\r\n",
        "\t# BVL: the base viral load presented in individuals at the end of the exposed period\r\n",
        "\t# VMR: the rate at which the DPR mutates upon contact\r\n",
        "\t# QTH: the viral load over which an individual's chances of getting quarantined increase linearly\r\n",
        "\t# BQP: the (base) quarantining probability for a person with viral load at the QTH threshold\r\n",
        "\t# XTH: the viral load over which an individual's chances of getting expired increase linearly\r\n",
        "\t# BXP: the (base) expiry probability for a person with viral load at the XTH threshold\r\n",
        "\t# BTR: the (base) fraction of population that travels at any time instant\r\n",
        "\t# BTD: the (base) distance to which people travel\r\n",
        "\t# BDPR: the (base) disease progression rate for the initial strain of the virus\r\n",
        "\t# alphaInit: the initial fraction of population that is infected with the virus\r\n",
        "\t@classmethod\r\n",
        "\tdef valInit( cls, N, BIR = 0.5, BCR = 0.25, INC = 3, BVL = 0.05, VMR = 0.0, QTH = 0.3, BQP = 0.0, XTH = 0.7, BXP = 0.0, BTR = 0.01, BTD = 1.0, BDPR = 0.1, alphaInit = 0.01 ):\r\n",
        "\t\t# Give the individuals unique identifiers\r\n",
        "\t\tpopIdx = np.arange(N)\r\n",
        "\t\t\r\n",
        "\t\t# Initialize the individuals\r\n",
        "\t\tind = np.zeros( (N, nParams) )\r\n",
        "\r\n",
        "\t\t# Initially no one is infected or quarantined\r\n",
        "\t\tind[ :, IDX_VLD ] = 0\r\n",
        "\t\tind[ :, IDX_RLD ] = 0\r\n",
        "\t\tind[ :, IDX_STA ] = ST_S\r\n",
        "\t\tind[ :, IDX_DPR ] = 0\r\n",
        "\t\tind[ :, IDX_QRN ] = 0\r\n",
        "\t\t\r\n",
        "\t\t# People have susceptibilities uniformly in a range\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tSUS = np.random.uniform( 0.01, 0.99, (N,) )\r\n",
        "\t\tind[ :, IDX_SUS ] = SUS\r\n",
        "\t\t\r\n",
        "\t\t# People have resistances uniformly in a range\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tRST = 0.1 * np.random.uniform( 0.01, 0.99, (N,) )\r\n",
        "\t\tind[ :, IDX_RST ] = RST\r\n",
        "\r\n",
        "\t\t# Set their locations uniformly at random within the [0,1] x [0,1] square\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tX = np.random.uniform( 0, 1, (N,) )\r\n",
        "\t\tind[ :, IDX_X ] = X\r\n",
        "\t\tY = np.random.uniform( 0, 1, (N,) )\r\n",
        "\t\tind[ :, IDX_Y ] = Y\r\n",
        "\t\t\r\n",
        "\t\t# Set the timers to invalid values since nothing has happened yet\r\n",
        "\t\tind[ :, IDX_TI ] = 0\r\n",
        "\t\tind[ :, IDX_TQ ] = 0\r\n",
        "\t\tind[ :, IDX_TR ] = 0\r\n",
        "\t\t\r\n",
        "\t\treturn cls( N, BIR, BCR, INC, BVL, VMR, QTH, BQP, XTH, BXP, BTR, BTD, BDPR, alphaInit, popIdx, ind, SUS, RST, X, Y )\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using data loaded from file\r\n",
        "\t@classmethod\r\n",
        "\tdef fileInit( cls, filename ):\r\n",
        "\t\t# Get data from the file\r\n",
        "\t\twith open( filename, 'rb' ) as file:\r\n",
        "\t\t\tdata = pickle.load( file )\r\n",
        "\t\t\r\n",
        "\t\t# Create an object out of this data and return it\r\n",
        "\t\treturn cls( *data )\r\n",
        "\t\t\r\n",
        "\t# Save a copy of this object to a file\r\n",
        "\tdef dump( self, filename ):\r\n",
        "\t\tdata = ( self.N, self.BIR, self.BCR, self.INC, self.BVL, self.VMR, self.QTH, self.BQP, self.XTH, self.BXP, self.BTR, self.BTD, self.BDPR, self.alphaInit, self.popIdx, self.ind, self.SUS, self.RST, self.X, self.Y )\r\n",
        "\t\twith open( filename, 'wb' ) as file:\r\n",
        "\t\t\tpickle.dump( data, file )\r\n",
        "\t\t\t\r\n",
        "\t# Turn the clock back to before the pandemic started\r\n",
        "\tdef reset( self ):\r\n",
        "\t\t# Reinitialize the individuals\r\n",
        "\t\tself.ind.fill(0)\r\n",
        "\t\t\r\n",
        "\t\t# Reset their susceptibilities to their original values (they do change for recovered and expired individuals)\r\n",
        "\t\tself.ind[ :, IDX_SUS ] = self.SUS\r\n",
        "\t\t\t\t\t\t\t \r\n",
        "\t\t# Initially no one is infected or quarantined\r\n",
        "\t\tself.ind[ :, IDX_VLD ] = 0\r\n",
        "\t\tself.ind[ :, IDX_RLD ] = 0\r\n",
        "\t\tself.ind[ :, IDX_STA ] = ST_S\r\n",
        "\t\tself.ind[ :, IDX_DPR ] = 0\r\n",
        "\t\tself.ind[ :, IDX_QRN ] = 0\r\n",
        "\t\t\t\t\t\t\t \r\n",
        "\t\t# Reset their resistances to their original value (although they should not have changed)\r\n",
        "\t\tself.ind[ :, IDX_RST ] = self.RST\r\n",
        "\t\t\t\t  \r\n",
        "\t\t# Reset their locations\r\n",
        "\t\tself.ind[ :, IDX_X ] = self.X\r\n",
        "\t\tself.ind[ :, IDX_Y ] = self.Y\r\n",
        "\t\t\t\t  \r\n",
        "\t\t# Reset the timers to a happier time before the pandemic began\r\n",
        "\t\tself.ind[ :, IDX_TI ] = 0\r\n",
        "\t\tself.ind[ :, IDX_TQ ] = 0\r\n",
        "\t\tself.ind[ :, IDX_TR ] = 0\r\n",
        "\t\t\r\n",
        "\t# T: the number of time steps for which to run the simulation\r\n",
        "\t# LKP: the lock-down policy\r\n",
        "\tdef simulate( self, T, LKP, minimal = False, checkSanity = False ):\r\n",
        "\t\tnumInfInit = int( self.alphaInit * self.N )\r\n",
        "\t\t\r\n",
        "\t\t# Randomly select the unfortunate souls who are going to get infected initially\r\n",
        "\t\tidxInit = np.random.permutation( self.N )[ : numInfInit ]\r\n",
        "\t\t\r\n",
        "\t\t# Infect them!\r\n",
        "\t\tself.ind[ idxInit, IDX_STA ] = ST_E\t\t\t# These individuals are incubating right now\r\n",
        "\t\tself.ind[ idxInit, IDX_DPR ] = self.BDPR\t# The virus has not mutated yet\r\n",
        "\t\tself.ind[ idxInit, IDX_TI ] = 1\t\t\t\t# They got infected at t = 1\r\n",
        "\t\t\r\n",
        "\t\t# Store the intial stats\r\n",
        "\t\tstats = np.zeros( (nStats, T+1) )\r\n",
        "\t\tstats[ :, 0 ] = np.array( [ self.N - numInfInit, numInfInit, 0, 0, 0, 0, self.BDPR, numInfInit, numInfInit ] )\r\n",
        "\t\t\r\n",
        "\t\tfor t in range(T):\r\n",
        "\t\t\tif checkSanity:\r\n",
        "\t\t\t\tself.doSanityChecks()\r\n",
        "\t\t\t# Track the progress of disease in infected + exposed individuals\r\n",
        "\t\t\tself.letDiseaseProgress( t+2 )\r\n",
        "\t\t\t# As much as permitted by the lock-down level at this time instant, allow individuals to travel\r\n",
        "\t\t\tself.letIndividualsTravel( LKP[t] )\r\n",
        "\t\t\t# Allow interactions and fresh infections and get a daily count\r\n",
        "\t\t\tdaily = self.letIndividualsInfect( LKP[t], t+2 )\r\n",
        "\t\t\t# As dictated by the quarantine policy, catch and quarantine individuals\r\n",
        "\t\t\tself.applyQuarantinePolicy( t+2 )\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Compute essential statistics\r\n",
        "\t\t\tidxEorI = (self.ind[ :, IDX_STA ].astype( int ) == ST_E) | (self.ind[ :, IDX_STA ].astype( int ) == ST_I)\r\n",
        "\t\t\tstats[ SIDX_EI, t+1 ] = np.count_nonzero( idxEorI )\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Compute optional statistics\r\n",
        "\t\t\tif not minimal:\r\n",
        "\t\t\t\tstats[ SIDX_S, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_S )\r\n",
        "\t\t\t\tstats[ SIDX_E, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_E )\r\n",
        "\t\t\t\tstats[ SIDX_I, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_I )\r\n",
        "\t\t\t\tstats[ SIDX_Q, t+1 ] = np.count_nonzero( self.ind[ :, IDX_QRN ].astype( int ) == 1 )\r\n",
        "\t\t\t\tstats[ SIDX_R, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_R )\r\n",
        "\t\t\t\tstats[ SIDX_X, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_X )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tstats[ SIDX_D, t+1 ] = daily\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tif len(idxEorI) == 0:\r\n",
        "\t\t\t\t\tstats[ SIDX_V, t+1 ] = 0\r\n",
        "\t\t\t\telse:\r\n",
        "\t\t\t\t\tstats[ SIDX_V, t+1 ] = np.mean( self.ind[ idxEorI, IDX_DPR ] )\r\n",
        "\t\t\r\n",
        "\t\t# Simulation over!!\r\n",
        "\t\t\r\n",
        "\t\t# Compute disease progression statistics and return final results of the simulation\r\n",
        "\t\tif minimal:\r\n",
        "\t\t\treturn stats\r\n",
        "\t\telse:\r\n",
        "\t\t\tidxEverInfected = self.ind[ :, IDX_TI ].astype( int ) > 0\r\n",
        "\t\t\ttInfect = self.ind[ idxEverInfected, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxQuarantined = self.ind[ :, IDX_TQ ].astype( int ) > 0\r\n",
        "\t\t\ttQuarantine = self.ind[ idxQuarantined, IDX_TQ ] - self.ind[ idxQuarantined, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxRecovered = self.ind[ :, IDX_STA ].astype( int ) == ST_R\r\n",
        "\t\t\ttRecovery = self.ind[ idxRecovered, IDX_TR ] - self.ind[ idxRecovered, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxExpired = self.ind[ :, IDX_STA ].astype( int ) == ST_X\r\n",
        "\t\t\ttExpiry = self.ind[ idxExpired, IDX_TR ] - self.ind[ idxExpired, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\treturn ( stats, tInfect, tQuarantine, tRecovery, tExpiry )\r\n",
        "\t\t\t\r\n",
        "\t\r\n",
        "\t# Simulate incubation period, update viral and recovery loads, and process expiries and recoveries\r\n",
        "\tdef letDiseaseProgress( self, t ):\r\n",
        "\t\t# Process recoveries of infectious individuals\r\n",
        "\t\t# TODO: recovery does not necessarily grant immunity: high levels of immunity may\r\n",
        "\t\t# only be available to those in whom the disease did progress sufficiently\r\n",
        "\t\tidxRecovered = ((self.ind[ :, IDX_STA ].astype( int ) == ST_I) & (self.ind[ :, IDX_VLD ] < self.BVL))\r\n",
        "\t\tif len(idxRecovered) > 0:\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_TR ] = t\t\t# These people recovered at time t\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_SUS ] = 0\t\t# They are now immune from the disease\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_VLD ] = 0\t\t# Their remaining viral load vanishes in an instant\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_RLD ] = 0\t\t# Their recovery load is made good instantly\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_STA ] = ST_R\t# They are now recovered\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_DPR ] = 0\t\t# They are free of the virus\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_QRN ] = 0\t\t# They are released from any quarantine in which they may have been\r\n",
        "\t\t\r\n",
        "\t\t# Process expiries of infectious individuals\r\n",
        "\t\t# If expiry threshold is too high, assume no one is going to get expired!\r\n",
        "\t\tif self.XTH < 1 - 1e-6:\r\n",
        "\t\t\tidxExpiryRisk = self.popIdx[ (self.ind[ :, IDX_STA ].astype( int ) == ST_I) & (self.ind[ :, IDX_VLD ] > self.XTH) ]\r\n",
        "\t\t\tif len(idxExpiryRisk) > 0:\r\n",
        "\t\t\t\texpiryProb = self.BXP + ( 1 - self.BXP ) * (self.ind[ idxExpiryRisk, IDX_VLD ] - self.XTH)/(1 - self.XTH)\r\n",
        "\t\t\t\ttosses = np.random.uniform( 0, 1, ( len(expiryProb), ) )\r\n",
        "\t\t\t\tidxExpired = idxExpiryRisk[ tosses < expiryProb ]\r\n",
        "\t\t\t\tif len(idxExpired) > 0:\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_TR ] = t\t\t# These people expired at time t\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_SUS ] = 0\t\t# Either way, they are now immune from the disease\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_VLD ] = 0\t\t# Their remaining viral load vanishes in an instant\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_RLD ] = 0\t\t# Their recovery load does not matter any more\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_STA ] = ST_X\t# They are removed from the population\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_DPR ] = 0\t\t# Either way, they are now free of the virus\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_QRN ] = 0\t\t# They are released from any quarantine in which they may have been\r\n",
        "\t\t\r\n",
        "\t\t# Update viral and recovery loads\r\n",
        "\t\tidxInfected = self.popIdx[ self.ind[ :, IDX_STA ].astype( int ) == ST_I ]\r\n",
        "\t\tif len(idxInfected) > 0:\r\n",
        "\t\t\t# Some of the viral load is shed into recovery load, depending on the resistance of the person\r\n",
        "\t\t\tVLD_DeltaNeg = self.ind[ idxInfected, IDX_RST ] * self.ind[ idxInfected, IDX_VLD ]\r\n",
        "\t\t\t# The viral load also goes up, depending on the disease progression rate\r\n",
        "\t\t\tNormalLoad = 1 - self.ind[ idxInfected, IDX_VLD ] - self.ind[ idxInfected, IDX_RLD ]\r\n",
        "\t\t\tVLD_DeltaPos = NormalLoad * self.ind[ idxInfected, IDX_DPR ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_RLD ] += VLD_DeltaNeg\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_VLD ] += (VLD_DeltaPos - VLD_DeltaNeg)\r\n",
        "\t\t\r\n",
        "\t\t# Process incubation maturity cases\r\n",
        "\t\tidxExposed = self.popIdx[ self.ind[ :, IDX_STA ].astype( int ) == ST_E ]\r\n",
        "\t\tif len(idxExposed) > 0:\r\n",
        "\t\t\ttExposed = self.ind[ idxExposed, IDX_TI ].astype( int )\r\n",
        "\t\t\tidxMatured = idxExposed[ tExposed == t - self.INC ]\r\n",
        "\t\t\tif len(idxMatured) > 0:\r\n",
        "\t\t\t\tself.ind[ idxMatured, IDX_VLD ] = self.BVL\t# These people now have a base viral load\r\n",
        "\t\t\t\tself.ind[ idxMatured, IDX_STA ] = ST_I\t# They are now infectious\r\n",
        "\t\t\t\t\r\n",
        "\t# Let individuals travel according to the current lock-down level\r\n",
        "\tdef letIndividualsTravel( self, level ):\r\n",
        "\t\t# Only non-quarantined and non-expired individuals can travel\r\n",
        "\t\tidxTravelAllowed = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 0) & (self.ind[ :, IDX_STA ].astype( int ) != ST_X) ]\r\n",
        "\t\tif len(idxTravelAllowed) > 0:\r\n",
        "\t\t\tnTravelAllowed = len(idxTravelAllowed)\r\n",
        "\t\t\tnTravellers = int( nTravelAllowed * self.BTR )\r\n",
        "\t\t\tif nTravellers > 0:\r\n",
        "\t\t\t\t# Allow a random set of people who are allowed to travel, to do so\r\n",
        "\t\t\t\tidxTravellers = idxTravelAllowed[ np.random.permutation( nTravelAllowed )[ :nTravellers ] ]\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# The travel distance is limited by the lock-down level\r\n",
        "\t\t\t\ttDist = self.BTD * np.exp( -level )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# Dividing by sqrt2 since perturbations are made to two dimensions\r\n",
        "\t\t\t\ttravelX = tDist / sqrt2 * np.random.uniform( -1, 1, (nTravellers,) )\r\n",
        "\t\t\t\ttravelY = tDist / sqrt2 * np.random.uniform( -1, 1, (nTravellers,) )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# Make sure individuals do not travel to another planet or something\r\n",
        "\t\t\t\tself.ind[ idxTravellers, IDX_X ] = ( self.ind[ idxTravellers, IDX_X ] + travelX ) % 1\r\n",
        "\t\t\t\tself.ind[ idxTravellers, IDX_Y ] = ( self.ind[ idxTravellers, IDX_Y ] + travelY ) % 1\r\n",
        "\t\t\r\n",
        "\t# Let individuals infect each other based on the current lock-down level\r\n",
        "\tdef letIndividualsInfect( self, level, t ):\r\n",
        "\t\t# All non-quarantined non-expired individuals can participate in interactions\r\n",
        "\t\t# Individuals going through the incubation period do participate but neither infect nor can be infected\r\n",
        "\t\tidxParticipants = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 0) & (self.ind[ :, IDX_STA ].astype( int ) != ST_X) ]\r\n",
        "\t\t# Find a mask for the (non-quarantined) infectious participants\r\n",
        "\t\tmaskInfectious = self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_I\r\n",
        "\t\t# Find a mask for non-immune susceptible/recovered individuals\r\n",
        "\t\tmaskSusceptible = (self.ind[ idxParticipants, IDX_SUS ] > 0) & ( (self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_S) | (self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_R) )\r\n",
        "\t\t\r\n",
        "\t\t# If there is either no one infecting or else no one to infect, nothing left to do\r\n",
        "\t\tif ( np.count_nonzero( maskInfectious ) == 0 ) | ( np.count_nonzero( maskSusceptible ) == 0 ):\r\n",
        "\t\t\treturn 0\r\n",
        "\t\t\r\n",
        "\t\t# Jiggle the coordinates pf the participants a bit to simulate random interactions\r\n",
        "\t\t# The jiggle dies down with lock-down level\r\n",
        "\t\tXParticipants = self.ind[ idxParticipants, IDX_X:IDX_Y + 1 ]\r\n",
        "\t\tjitter = self.BCR * np.exp( -level ) / sqrt2 * np.random.uniform( 0, 1, (2,) )\r\n",
        "\t\tXParticipants += jitter\r\n",
        "\t\t\r\n",
        "\t\t# Create interaction bins out of these jittered coordinates\r\n",
        "\t\t# The jitter added earlier allows individuals to fall into potentially different bins each time\r\n",
        "\t\t# TODO: this is slow at the moment, especially at high lock-down levels when number of bins\r\n",
        "\t\t# skyrockets since everyone is trapped inside their virtual houses. Speed this up by using a\r\n",
        "\t\t# reverse hash to iterate only over non-empty bins (there can be at most N such bins)\r\n",
        "\t\trContact = self.BCR * np.exp( -level ) / sqrt2\r\n",
        "\t\tXParticipants = np.floor( XParticipants / rContact )\r\n",
        "\t\tnBinsPerCoord = np.max( XParticipants ) + 1\r\n",
        "\t\tBParticipants = ( XParticipants[:, 0] * nBinsPerCoord + XParticipants[:, 1] ).astype( int )\r\n",
        "\t\t\r\n",
        "\t\t# Find the bins for infectious and susceptible individuals\r\n",
        "\t\tBInfectious = BParticipants[ maskInfectious ]\r\n",
        "\t\tBSusceptible = BParticipants[ maskSusceptible ]\r\n",
        "\t\t\r\n",
        "\t\t# Find the infection probabilities in each bin\r\n",
        "\t\tbins = np.arange( np.max(BParticipants) + 2 )\r\n",
        "\t\t# print( \"At time %d, we have jitter (%f, %f) and %d bins\" % ( t, jitter[0], jitter[1], len(bins) ) )\r\n",
        "\t\tbinParticipantCount = np.histogram( BParticipants, bins )[0]\r\n",
        "\t\tbinParticipantCount[ binParticipantCount < 1 ] = 1 # Avoid a divide-by-zero error\r\n",
        "\t\tbinInfectiousCount = np.histogram( BInfectious, bins )[0]\r\n",
        "\t\tbinInfectionProb = binInfectiousCount / binParticipantCount * self.BIR\r\n",
        "\t\t\r\n",
        "\t\t# Find the mean DPR within each bin -- this will be used to decide the DPR for newly infected people\r\n",
        "\t\tidxInfectious = idxParticipants[maskInfectious]\r\n",
        "\t\tbinDPR = binStat( BInfectious, self.ind[ idxInfectious, IDX_DPR ], statistic = \"mean\", bins = bins )[0]\r\n",
        "\t\tbinDPR[ np.isnan( binDPR ) ] = 0 # Fix values for bins where there were no infectious people\r\n",
        "\t\t\r\n",
        "\t\t# Find the infection probabilities for each susceptible individual\r\n",
        "\t\tidxSusceptible = idxParticipants[maskSusceptible]\r\n",
        "\t\tinfectionProb = binInfectionProb[BSusceptible] * self.ind[ idxSusceptible, IDX_SUS ]\r\n",
        "\t\t\r\n",
        "\t\t# Find new DPRs for the mutated viruses for the susceptible individuals\r\n",
        "\t\t# Currently this bit of code has been inactivated since we have set VMR = 0.0\r\n",
        "\t\tnewDPR = binDPR[BSusceptible] * ( 1 + self.VMR * ( 2 * np.random.randint( 0, 2, ( len(BSusceptible), ) ) - 1 ) )\r\n",
        "\t\tnewDPR[ newDPR < 0.001 ] = 0.001 # Make sure DPR never dips too low\r\n",
        "\t\tnewDPR[ newDPR > 0.999 ] = 0.999 # Make sure DPR never goes too high\r\n",
        "\t\t\r\n",
        "\t\t# Get some random bits to decide who gets infected among the susceptible\r\n",
        "\t\ttosses = np.random.uniform( 0, 1, ( len(infectionProb), ) )\r\n",
        "\t\tmaskInfected = tosses < infectionProb\r\n",
        "\t\tidxInfected = idxSusceptible[maskInfected]\r\n",
        "\t\tif len(idxInfected) > 0:\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_STA ] = ST_E\t\t\t\t\t\t# These individuals are incubating right now\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_DPR ] = newDPR[maskInfected]\t\t# These individuals get the mutated version\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_TI ] = t\t\t\t\t\t\t\t# They got infected at t = t\r\n",
        "\t\t\t\r\n",
        "\t\treturn len(idxInfected)\r\n",
        "\t\t\r\n",
        "\t# Quarantine individuals based on quarantine policy\r\n",
        "\tdef applyQuarantinePolicy( self, t ):\r\n",
        "\t\t# If quarantine threshold is too high, assume no one is going to get quarantined!\r\n",
        "\t\tif self.QTH > 1 - 1e-6:\r\n",
        "\t\t\treturn\r\n",
        "\t\t\t\r\n",
        "\t\t# Only non-quarantined and non-expired individuals with viral loads above the quarantine threshold can be quarantined\r\n",
        "\t\tidxPotential = self.popIdx[ ( self.ind[ :, IDX_QRN ].astype( int ) == 0 ) & ( self.ind[ :, IDX_STA ].astype( int ) != ST_X ) & ( self.ind[ :, IDX_VLD ] > self.QTH ) ]\r\n",
        "\t\tif len(idxPotential) > 0:\r\n",
        "\t\t\tquarantineProb = self.BQP + ( 1 - self.BQP ) * ( self.ind[ idxPotential, IDX_VLD ] - self.QTH ) / ( 1 - self.QTH )\r\n",
        "\t\t\ttosses = np.random.uniform( 0, 1, ( len(quarantineProb), ) )\r\n",
        "\t\t\tidxQuarantined = idxPotential[ tosses < quarantineProb ]\r\n",
        "\t\t\tif len(idxQuarantined) > 0:\r\n",
        "\t\t\t\tself.ind[ idxQuarantined, IDX_QRN ] = 1\t\t# Put them in quarantine\r\n",
        "\t\t\t\tself.ind[ idxQuarantined, IDX_TQ ] = t\t\t# Note down the time of quarantining\r\n",
        "\t\t\t\t\r\n",
        "\t# Do sanity checks to make sure there are no anomalies\r\n",
        "\tdef doSanityChecks( self ):\r\n",
        "\t\t# Make sure there are no negative values anywhere\r\n",
        "\t\tminVal = np.min( self.ind )\r\n",
        "\t\tassert minVal >= 0, \"Negative values detected in the parameter values: %f\" % minVal\r\n",
        "\t\r\n",
        "\t\t# Make sure everyone is in one of the five states S, E, I, R, X\r\n",
        "\t\tstates = set( np.unique( self.ind[ :, IDX_STA ] ).astype( int ) )\r\n",
        "\t\tgold = set( np.arange( nStates ) )\r\n",
        "\t\tassert len( states - gold ) == 0, \"Invalid states detected %\" % \"\".join([str(i)+\", \" for i in states])\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one except those in I state have a non-zero viral and recovery load\r\n",
        "\t\tidxNonInfected = (self.ind[ :, IDX_STA ].astype( int ) != ST_I)\r\n",
        "\t\tassert max( self.ind[ idxNonInfected, IDX_VLD ] ) < 1e-6, \"Non-infectious individuals with non-zero viral load detected\"\r\n",
        "\t\tassert max( self.ind[ idxNonInfected, IDX_RLD ] ) < 1e-6, \"Non-infectious individuals with non-zero recovery load detected\"\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one other than those in state I are in quarantine\r\n",
        "\t\t# This may have to be modified if VIPER is extended to enable false positives in quarantining\r\n",
        "\t\tidxInvalidQuarantine = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 1) & (self.ind[ :, IDX_STA ].astype( int ) != ST_I) ]\r\n",
        "\t\tassert len(idxInvalidQuarantine) == 0, \"Non-infectious individuals quarantined\"\r\n",
        "\t\t\r\n",
        "\t\t# Make sure all individual locations are within bounds\r\n",
        "\t\tminX = np.min( self.ind[ :, IDX_X ] )\r\n",
        "\t\tassert minX >= 0, \"Negative values detected in X coordinates %f\" % minX\r\n",
        "\t\tminY = np.min( self.ind[ :, IDX_Y ] )\r\n",
        "\t\tassert minY >= 0, \"Negative values detected in Y coordinates %f\" % minY\r\n",
        "\t\tmaxX = np.max( self.ind[ :, IDX_X ] )\r\n",
        "\t\tassert maxX <= 1, \"Large values detected in X coordinates %f\" % maxX\r\n",
        "\t\tmaxY = np.max( self.ind[ :, IDX_Y ] )\r\n",
        "\t\tassert maxY <= 1, \"Large values detected in Y coordinates %f\" % maxY\r\n",
        "\t\t\r\n",
        "# This class provides patches to the SUS, RST and location parameters for an object of the\r\n",
        "# Population class. RST and SUS values are fitted to Indian statistics and locations are\r\n",
        "# clustered into cities for a certain fraction of the population.\r\n",
        "class Demographics:\r\n",
        "\t# The base constructor -- almost never used directly\r\n",
        "\tdef __init__( self, N, urbanRatio, numCities, cityRadius, loc, isUrban, cityCenters, cityIdx, demoData ):\r\n",
        "\t\tself.N = N\r\n",
        "\t\tself.urbanRatio = urbanRatio\r\n",
        "\t\tself.numCities = numCities\r\n",
        "\t\tself.cityRadius = cityRadius\r\n",
        "\t\tself.loc = loc\r\n",
        "\t\tself.isUrban = isUrban\r\n",
        "\t\tself.cityCenters = cityCenters\r\n",
        "\t\tself.cityIdx = cityIdx\r\n",
        "\t\tself.demoData = demoData\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using scalar values for various parameters\r\n",
        "\t# This provides a patch to the generic population generated using the class\r\n",
        "\t# Population (see above and setup.py) with a certain fraction living in cities\r\n",
        "\t# and RST and SUS values distributed to fit India statistics\r\n",
        "\t\r\n",
        "\t# N: the size of the population before the pandemic began\r\n",
        "\t# urbanRatio: what fraction of this population lives in cities?\r\n",
        "\t# numCities: how many cities do we have\r\n",
        "\t# cityRadius: the soft geographical extent of each city. ~99.7 of the population\r\n",
        "\t# of any city should live within 3 x cityRadius distance of the city center\r\n",
        "\t@classmethod\r\n",
        "\tdef valInit( cls, N, urbanRatio = 0.34, numCities = 4, cityRadius = 0.1 ):\r\n",
        "\t\t( loc, isUrban, cityCenters, cityIdx ) = cls.getInitLocations( N, urbanRatio, numCities, cityRadius )\r\n",
        "\t\tdemoData = cls.getDemographics(N)\r\n",
        "\t\treturn cls( N, urbanRatio, numCities, cityRadius, loc, isUrban, cityCenters, cityIdx, demoData )\r\n",
        "\t\t\r\n",
        "\t# Constructor that initializes using data loaded from file\r\n",
        "\t@classmethod\r\n",
        "\tdef fileInit( cls, filename ):\r\n",
        "\t\t# Get data from the file\r\n",
        "\t\twith open( filename, 'rb' ) as file:\r\n",
        "\t\t\tdata = pickle.load( file )\r\n",
        "\t\t\r\n",
        "\t\t# Create an object out of this data and return it\r\n",
        "\t\treturn cls( *data )\r\n",
        "\t\t\r\n",
        "\t# Save a copy of this object to a file\r\n",
        "\tdef dump( self, filename ):\r\n",
        "\t\tdata = ( self.N, self.urbanRatio, self.numCities, self.cityRadius, self.loc, self.isUrban, self.cityCenters, self.cityIdx, self.demoData )\r\n",
        "\t\twith open( filename, 'wb' ) as file:\r\n",
        "\t\t\tpickle.dump( data, file )\r\n",
        "\t\t\t\r\n",
        "\t# Distribute people into cities and non-urban areas randomly as requested\r\n",
        "\t@classmethod\r\n",
        "\tdef getInitLocations( cls, N, urbanRatio, numCities, cityRadius ):\r\n",
        "\t\tloc = np.zeros( (N, 2) )\r\n",
        "\t\tisUrban = np.zeros( (N,) )\r\n",
        "\t\t\r\n",
        "\t\t# Find out who all is living in the cities\r\n",
        "\t\tnumUrban = int( N * urbanRatio )\r\n",
        "\t\tpermLoc = np.random.permutation( N )\r\n",
        "\t\tisUrban[ permLoc[ : numUrban ] ] = 1\r\n",
        "\t\t\r\n",
        "\t\t# Non-urban populations are distributed uniformly randomly\r\n",
        "\t\tloc[ permLoc[ numUrban : ], : ] = np.random.uniform( 0, 1, ( N - numUrban, 2 ) )\r\n",
        "\t\t\r\n",
        "\t\t# Urban populations are distributed in clusters around city centers\r\n",
        "\t\t# First, let us find the city centers\r\n",
        "\t\tcityCenters = np.random.uniform( 0, 1, ( numCities, 2 ) )\r\n",
        "\t\t# Next, assign each city dweller, a city uniformly randomly\r\n",
        "\t\tcityIdx = np.random.randint( 0, numCities, (numUrban,) )\r\n",
        "\t\t# Finally, set the location of each city dweller as a jitter around their respective city centers\r\n",
        "\t\tloc[ permLoc[ : numUrban ], : ] = cityCenters[ cityIdx, : ]\r\n",
        "\t\tloc[ permLoc[ : numUrban ], : ] += np.random.normal( 0, cityRadius / sqrt2, ( numUrban, 2 ) )\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one leaves the planet!\r\n",
        "\t\tloc[ loc < 0 ] = 0\r\n",
        "\t\tloc[ loc > 1 ] = 1\r\n",
        "\t\t\r\n",
        "\t\treturn ( loc, isUrban, cityCenters, cityIdx )\r\n",
        "\t\r\n",
        "\t# Get RST and SUS values for the population that are derived from India statistics. For references\r\n",
        "\t# mentioned below e.g. (Ramakrishnan et al. 2019), please refer to the ESOP paper\r\n",
        "\t# https://arxiv.org/abs/2005.11257\r\n",
        "\t\r\n",
        "\t# Age groups are 0-20, 20-30, 30-40, 40-45, 45-50, 50-55, 55-60, 60-65, 65-70, 70-75, 75-80, 80+\r\n",
        "\t# There are 12 age groups that are indexed 0 through 11\r\n",
        "\t# This funny splitting of groups is due to the way in which various papers report their statistics\r\n",
        "\t# Whereas (Group 2003, Table 2) uses age intervals such as 20-30 years, 30-40 years, on the other\r\n",
        "\t# hand, (Ramakrishnan et al. 2019, Table 1) uses 45-55 years, 55-65 years as intervals instead\r\n",
        "\t\r\n",
        "\t# Genders are Female, Male -- these are indexed as Female = 0, Male = 1\r\n",
        "\t# The above convention is chosen to simplfy the susceptibility calculations\r\n",
        "\t# In all tables below, the first column is for the female gender and the second column for males\r\n",
        "\t@classmethod\r\n",
        "\tdef getDemographics( cls, N ):\r\n",
        "\t\t# Taken from (Ministry Home Affairs India 2016, Detailed Tables)\r\n",
        "\t\tageSplitbyGender = np.array([\r\n",
        "\t\t\t[ 0.363, 0.380 ],\r\n",
        "\t\t\t[ 0.205, 0.197 ],\r\n",
        "\t\t\t[ 0.152, 0.151 ],\r\n",
        "\t\t\t[ 0.061, 0.061 ],\r\n",
        "\t\t\t[ 0.054, 0.053 ],\r\n",
        "\t\t\t[ 0.043, 0.044 ],\r\n",
        "\t\t\t[ 0.037, 0.035 ],\r\n",
        "\t\t\t[ 0.031, 0.030 ],\r\n",
        "\t\t\t[ 0.022, 0.021 ],\r\n",
        "\t\t\t[ 0.015, 0.014 ],\r\n",
        "\t\t\t[ 0.009, 0.008 ], \r\n",
        "\t\t\t[ 0.008, 0.006 ]\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\tcumSplitbyGender = np.cumsum( ageSplitbyGender, axis = 0 )\r\n",
        "\t\t\r\n",
        "\t\t# According to the 2011 census, India's gender ratio is 51.5% males to 48.5% females\r\n",
        "\t\tgenderSplit = 0.515\r\n",
        "\t\t\r\n",
        "\t\t# Taken from (Group 2003, Table 2)\r\n",
        "\t\tdiabetesSplit = np.array([\r\n",
        "\t\t\t[ 0.000, 0.000 ],\r\n",
        "\t\t\t[ 0.000, 0.000 ],\r\n",
        "\t\t\t[ 0.125, 0.114 ],\r\n",
        "\t\t\t[ 0.227, 0.218 ],\r\n",
        "\t\t\t[ 0.227, 0.218 ],\r\n",
        "\t\t\t[ 0.326, 0.330 ],\r\n",
        "\t\t\t[ 0.326, 0.330 ],\r\n",
        "\t\t\t[ 0.346, 0.410 ],\r\n",
        "\t\t\t[ 0.346, 0.410 ],\r\n",
        "\t\t\t[ 0.330, 0.326 ],\r\n",
        "\t\t\t[ 0.330, 0.326 ],\r\n",
        "\t\t\t[ 0.177, 0.242 ]\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\t# Taken from (Ramakrishnan et al. 2019, Table 1)\r\n",
        "\t\thypertensionSplit = np.array([\r\n",
        "\t\t\t[ 0.062, 0.161 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.346, 0.424 ],\r\n",
        "\t\t\t[ 0.346, 0.424 ],\r\n",
        "\t\t\t[ 0.454, 0.490 ],\r\n",
        "\t\t\t[ 0.454, 0.490 ],\r\n",
        "\t\t\t[ 0.514, 0.515 ],\r\n",
        "\t\t\t[ 0.514, 0.515 ],\r\n",
        "\t\t\t[ 0.513, 0.522 ],\r\n",
        "\t\t\t[ 0.513, 0.522 ],\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\tdemoData = np.zeros( ( N, 5 ) )\r\n",
        "\t\t# Sample random numbers in bulk for speed\r\n",
        "\t\trandomCoins = np.random.uniform( 0, 1, ( N, 4 ) )\r\n",
        "\t\t\r\n",
        "\t\tIDX_AGE = 0\t\t# The age group of the person\r\n",
        "\t\tIDX_SEN = 1\t\t# The seniority of the person\r\n",
        "\t\tIDX_GEN = 2\t\t# The gender of the person\r\n",
        "\t\tIDX_DBT = 3\t\t# The diabetic status of the person\r\n",
        "\t\tIDX_HTN = 4\t\t# The hypertensive status of the person\r\n",
        "\t\t\r\n",
        "\t\t# TODO: The below for loop can surely be sped-up using vectorization/broadcasting techniques\r\n",
        "\t\tfor i in range( N ):\r\n",
        "\t\t\t# Since our primary data only gives us conditional statistics e.g. gender ratio, age split by gender\r\n",
        "\t\t\t# and not joint statistics, we should not sample individual attributes jointly but rather sequentially\r\n",
        "\t\t\t\r\n",
        "\t\t\tthisGender = 0\r\n",
        "\t\t\t# First sample the gender of the person\r\n",
        "\t\t\tif randomCoins[ i, 0 ] <= genderSplit:\r\n",
        "\t\t\t\tthisGender = 1\t\t\t\t\t\t\t# Its a boy!\r\n",
        "\t\t\tdemoData[ i, IDX_GEN ] = thisGender\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, sample the age-group of the person - use fresh randomness\r\n",
        "\t\t\tthisAgeGroup = np.digitize( randomCoins[ i, 1 ], cumSplitbyGender[ :, thisGender ], right = True )\r\n",
        "\t\t\tdemoData[ i, IDX_AGE ] = thisAgeGroup\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, decide the seniority of the person\r\n",
        "\t\t\tthisSeniority = 0\r\n",
        "\t\t\t# Persons above 55 years of age are classified as senior according to (Joshi 2020, Table 1)\r\n",
        "\t\t\tif thisAgeGroup > 5:\r\n",
        "\t\t\t\tthisSeniority = 1\r\n",
        "\t\t\tdemoData[ i, IDX_SEN ] = thisSeniority\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, decide the diabetic status of the person - use fresh randomness\r\n",
        "\t\t\tthisDiabetic = 0\r\n",
        "\t\t\tif randomCoins[ i, 2 ] <= diabetesSplit[ thisAgeGroup, thisGender ]:\r\n",
        "\t\t\t\tthisDiabetic = 1\r\n",
        "\t\t\tdemoData[ i, IDX_DBT ] = thisDiabetic\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Finally, decide the hypertensive status of the person - use fresh randomness\r\n",
        "\t\t\tthisHypertensive = 0\r\n",
        "\t\t\tif randomCoins[ i, 3 ] <= hypertensionSplit[ thisAgeGroup, thisGender ]:\r\n",
        "\t\t\t\tthisHypertensive = 1\r\n",
        "\t\t\tdemoData[ i, IDX_HTN ] = thisHypertensive\r\n",
        "\t\t\t\r\n",
        "\t\treturn demoData\r\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB9oG9icO595"
      },
      "source": [
        "## Inputs:\r\n",
        "\r\n",
        "obj_func = 'Optimizing COVID-19 Lockdown'\r\n",
        "n_test = 100\r\n",
        "\r\n",
        "util_loser = 'dEI_GP'\r\n",
        "util_winner = 'EI_GP'\r\n",
        "n_init = 4"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmTRQrOAPQ5R"
      },
      "source": [
        "## Cumulative Regret Calculator:\r\n",
        "\r\n",
        "def min_max_array(x):\r\n",
        "  new_list = []\r\n",
        "  for i, num in enumerate(x):\r\n",
        "    new_list.append(np.min(x[0:i+1]))\r\n",
        "  return new_list"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPWUiXbEPbxv"
      },
      "source": [
        "## Derivatives: squared-exponential kernel:\r\n",
        "\r\n",
        "def l2norm_(X, Xstar):\r\n",
        "    return cdist(X, Xstar)\r\n",
        "\r\n",
        "def kronDelta(X, Xstar):\r\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\r\n",
        "\r\n",
        "class squaredExponentialDeriv(squaredExponential):\r\n",
        "\r\n",
        "  def K(self, X, Xstar):  \r\n",
        "    r = l2norm_(X, Xstar)/self.l\r\n",
        "    K = self.sigmaf * np.exp(-0.5 * r ** 2) + self.sigman * kronDelta(X, Xstar)\r\n",
        "    return K\r\n",
        "\r\n",
        "  def dK(self, X, Xstar):\r\n",
        "    r = l2norm_(X, Xstar)/self.l\r\n",
        "    dK = self.sigmaf/(self.l ** 2) * np.exp(-0.5 * r ** 2) * l2norm_(X, Xstar)\r\n",
        "    return dK\r\n",
        "\r\n",
        "  def d2K(self, X, Xstar):\r\n",
        "    r = l2norm_(X, Xstar)/self.l\r\n",
        "    d2K = self.sigmaf/(self.l ** 2) * np.exp(-0.5 * r ** 2) * (r ** 2 - 1)\r\n",
        "    return d2K\r\n",
        "\r\n",
        "cov_func = squaredExponential()\r\n",
        "d_cov_func = squaredExponentialDeriv()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YwnaFDUQPXv"
      },
      "source": [
        "### Acquisition function derivatives:\r\n",
        "\r\n",
        "class Acquisition_new(Acquisition):    \r\n",
        "    def __init__(self, mode, eps=1e-06, **params):\r\n",
        "        \r\n",
        "        self.params = params\r\n",
        "        self.eps = eps\r\n",
        "\r\n",
        "        mode_dict = {\r\n",
        "            'EI_GP': self.EI_GP,\r\n",
        "            'dEI_GP': self.dEI_GP\r\n",
        "        }\r\n",
        "\r\n",
        "        self.f = mode_dict[mode]\r\n",
        "    \r\n",
        "    def EI_GP(self, tau, mean, std):\r\n",
        "        \r\n",
        "        z = -1 * (mean - tau - self.eps) / (std + self.eps)\r\n",
        "        return z * (std + self.eps) * norm.cdf(z) + (std + self.eps) * norm.pdf(z)[0]\r\n",
        "    \r\n",
        "    def dEI_GP(self, tau, mean, std, ds, dm, dvdv, d2s, d2m):\r\n",
        "    \r\n",
        "        z = -1 * (mean - tau - self.eps) / (std + self.eps)\r\n",
        "        \r\n",
        "        dsdx = ds / (std + self.eps)\r\n",
        "        d2sdx = -dsdx**2 / ((std + self.eps)) - (dvdv + d2s) / (std + self.eps)\r\n",
        "        dmdx = (dm - z * dsdx) / (std + self.eps)\r\n",
        "        d2mdx = (d2m -(z * d2sdx + 2 * dmdx * dsdx)) / (std + self.eps)\r\n",
        "        \r\n",
        "        f = (std + self.eps) * (z * norm.cdf(z) + norm.pdf(z)[0])\r\n",
        "        df = (z * norm.cdf(z) + norm.pdf(z)[0]) * dsdx + (std + self.eps) * norm.cdf(z) * dmdx\r\n",
        "        d2f = (z * norm.cdf(z) + norm.pdf(z)[0]) * d2sdx + dsdx * dmdx * norm.cdf(z) \\\r\n",
        "            + d2mdx * (std + self.eps) * norm.cdf(z) + dsdx * norm.cdf(z) * dmdx \\\r\n",
        "            + norm.pdf(z)[0] * (std + self.eps) * dmdx\r\n",
        "            \r\n",
        "        return f, df, d2f\r\n",
        "    \r\n",
        "    def _eval(self, tau, mean, std):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, **self.params)\r\n",
        "    \r\n",
        "    def d_eval(self, tau, mean, std, ds, dm, dvdv, d2s, d2m):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2s, d2m, **self.params)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWiJocDIUTBa"
      },
      "source": [
        "### Surrogate derivatives: \r\n",
        "\r\n",
        "class dGaussianProcess(GaussianProcess):\r\n",
        "    sigmaf = 1\r\n",
        "    l = 1e-4\r\n",
        "    sigman = 1e-6\r\n",
        "    \r\n",
        "    def AcqGrad(self, Xstar, return_std=False):\r\n",
        "        Xstar = np.atleast_2d(Xstar)\r\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\r\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\r\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\r\n",
        "        v = solve(self.L, Kstar.T)\r\n",
        "        dv = solve(self.L, dKstar.T)\r\n",
        "        d2v = solve(self.L, d2Kstar.T)\r\n",
        "        \r\n",
        "        ds = -np.dot(dv.T, v)\r\n",
        "        d2s = np.dot(d2v.T, v)\r\n",
        "        dvdv = np.dot(dv.T, dv)\r\n",
        "        \r\n",
        "        dm = np.dot(dKstar, self.alpha)\r\n",
        "        d2m = np.dot(d2Kstar, self.alpha)\r\n",
        "        return ds, dm, dvdv, d2s, d2m"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV2Zg7B9U_YT"
      },
      "source": [
        "class d2GPGO(GPGO):  \r\n",
        "    n_start = 100\r\n",
        "    p = np.full((n_start,1),1)\r\n",
        "    \r\n",
        "    def func(self, xnew):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        f  = np.empty((self.n_start,))\r\n",
        "        df = np.empty((self.n_start,))\r\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[0]\r\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[1]\r\n",
        "        df_array = np.full((len(xnew),),df)\r\n",
        "        return f, df_array\r\n",
        "    \r\n",
        "    def hessp_nonzero(self, xnew, p):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        df2 = np.empty((self.n_start,))\r\n",
        "        df2 = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[2]\r\n",
        "        H2 = np.empty((self.n_start,))\r\n",
        "        df2 = np.asarray(df2)\r\n",
        "        p = np.asarray(p)\r\n",
        "        H2 = np.multiply(df2,p)\r\n",
        "        return H2\r\n",
        "    \r\n",
        "    def d_optimizeAcq(self, method='Newton-CG', n_start=n_start):\r\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\r\n",
        "        start_points_arr = np.array([list(s.values())\r\n",
        "                                     for s in start_points_dict])\r\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\r\n",
        "        f_best = np.empty((n_start,))\r\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\r\n",
        "                                                                 x0=start_point,\r\n",
        "                                                                 method=method,\r\n",
        "                                                                 jac = True,\r\n",
        "                                                                 hessp = self.hessp_nonzero,\r\n",
        "                                                                 bounds=self.parameter_range) for start_point in\r\n",
        "                                               start_points_arr)\r\n",
        "        \r\n",
        "        x_best = np.array([res.x for res in opt])\r\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\r\n",
        "\r\n",
        "        self.best = x_best[np.argmin(f_best)]     \r\n",
        "    \r\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\r\n",
        "        \r\n",
        "        if not resume:\r\n",
        "            self.init_evals = init_evals\r\n",
        "            self._firstRun(self.init_evals)\r\n",
        "            self.logger._printInit(self)\r\n",
        "        for iteration in range(max_iter):\r\n",
        "            self.d_optimizeAcq()\r\n",
        "            #self.updateGP()\r\n",
        "            self.updateGP_min()\r\n",
        "            self.logger._printCurrent(self)\r\n",
        "\r\n",
        "    def updateGP_min(self):\r\n",
        "\r\n",
        "        kw = {param: self.best[i]\r\n",
        "              for i, param in enumerate(self.parameter_key)}\r\n",
        "        f_new = self.f(**kw)\r\n",
        "        self.GP.update(np.atleast_2d(self.best), np.atleast_1d(f_new))\r\n",
        "        self.tau = np.min(self.GP.y)\r\n",
        "        self.history.append(self.tau)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH1y-f17VGEu"
      },
      "source": [
        "class GPGO_min(GPGO):\r\n",
        "\r\n",
        "  def updateGP(self):\r\n",
        "\r\n",
        "        kw = {param: self.best[i]\r\n",
        "              for i, param in enumerate(self.parameter_key)}\r\n",
        "        f_new = self.f(**kw)\r\n",
        "        self.GP.update(np.atleast_2d(self.best), np.atleast_1d(f_new))\r\n",
        "        self.tau = np.min(self.GP.y)\r\n",
        "        self.history.append(self.tau)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8-7_K9cVCis",
        "outputId": "c15203ea-f3b6-4704-ea68-d5143dfab76d"
      },
      "source": [
        "start_lose = time.time()\r\n",
        "start_lose"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1610386409.8468318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Llhv7cLGpw7H",
        "outputId": "65871efd-d290-4b19-fbdc-cccea93603f5"
      },
      "source": [
        "## url = 'https://github.com/purushottamkar/esop/blob/master/pop_generic'\r\n",
        "\r\n",
        "from google.colab import files #pop_generic file is saved to the same Google Colab folder as this workbook\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "## Defines new data object as pop_generic"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d03f8331-b591-431e-86ed-d39f62314680\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d03f8331-b591-431e-86ed-d39f62314680\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pop_generic to pop_generic\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7XzVypVHmy"
      },
      "source": [
        "### Objective Function\r\n",
        "\r\n",
        "if obj_func == 'Optimizing COVID-19 Lockdown':\r\n",
        "\r\n",
        "  # Constraints:\r\n",
        "  param_lb_uniform = 0\r\n",
        "  param_ub_uniform = 1\r\n",
        "\r\n",
        "  # 1-D inputs' parameter bounds:\r\n",
        "  param = {'x': ('cont', (param_lb_uniform, param_ub_uniform))}\r\n",
        "\r\n",
        "  pop = Population.fileInit(\"pop_generic\")\r\n",
        "  pop.INC = 10\r\n",
        "  N = pop.N\r\n",
        "  T = 500\r\n",
        "  P0 = 30\r\n",
        "  L0 = 5\r\n",
        "\r\n",
        "  SIDX_S = 0  # Number of individuals: susceptible & non-recovered\r\n",
        "  SIDX_E = 1  # Number of individuals: exposed\r\n",
        "  SIDX_I = 2  # Number of individuals: infectious\r\n",
        "  SIDX_Q = 3  # Number of individuals: quarantined\r\n",
        "  SIDX_R = 4  # Number of individuals: recovered\r\n",
        "  SIDX_X = 5  # Number of individuals: expired\r\n",
        "  SIDX_V = 6  # Average virulence of viral strains\r\n",
        "  SIDX_EI = 7 # Number of individuals: infected\r\n",
        "  SIDX_D = 8  # Number of individuals: daily infections\r\n",
        "\r\n",
        "  I0c = 50\r\n",
        "  I0w = 50\r\n",
        "  evalCount = 0\r\n",
        "  globalDict = {}\r\n",
        "  freshMask = []\r\n",
        "  # Upper and lower bounds on legal values of lock-down intialization points:\r\n",
        "  ul = 100\r\n",
        "  ll = 0\r\n",
        "\r\n",
        "  def getI0( x ): \r\n",
        "    global I0c, I0w, ul, ll\r\n",
        "    SVal = int( np.floor( I0c + (x - 0.5) / 0.5 * I0w ) )\r\n",
        "    # Make sure that the recovered value is a legal one\r\n",
        "    correctedSVal = min( max( SVal, ll ), ul )\r\n",
        "    return correctedSVal\r\n",
        "\r\n",
        "  # Get a lockdown schedule corresponding to a certain I0 value\r\n",
        "  def getLKP( I0 ):\r\n",
        "    LKP = np.zeros((T,))\r\n",
        "    LKP[I0:I0+P0] = L0\r\n",
        "    return LKP\r\n",
        "\r\n",
        "  # Find out the objective value corresponding to the stats sent as input\r\n",
        "  # For this experiment, the objective value is simply f_epi since f_eco is\r\n",
        "  # already decided since the duration of the lock-down is fixed at P0 = 30\r\n",
        "  def obj( stats ):\r\n",
        "    global SIDX_EI\r\n",
        "    fEpi = np.max( stats[ SIDX_EI, : ] )\r\n",
        "    return fEpi\r\n",
        "\r\n",
        "  # Ask the VIPER simulator what does it think will happen if lock-down is\r\n",
        "  # initiated as specified in the normalized parameter x\r\n",
        "  def f_syn_polarity( x ):\r\n",
        "    global I0c, I0w, evalCount, globalDict, freshMask\r\n",
        "    # Before starting a simulation, turn back time to reset everything\r\n",
        "    pop.reset()\r\n",
        "    # Replicable simulations\r\n",
        "    np.random.seed(0)\r\n",
        "    I0 = getI0(x)\r\n",
        "    # Avoid re-sampling the same points\r\n",
        "    #if I0 in globalDict:\r\n",
        "    #  freshMask.append(False)\r\n",
        "    #  return globalDict[I0]\r\n",
        "    LKP = getLKP( I0 )\r\n",
        "    stats = pop.simulate( T = T, LKP = LKP, minimal = True )\r\n",
        "    globalDict[I0] = obj( stats )\r\n",
        "    freshMask.append( True )\r\n",
        "    evalCount += 1\r\n",
        "    return obj( stats )\r\n",
        "\r\n",
        "  # Once ESOP is done, find out which parameter, i.e. which value of I0 won!\r\n",
        "  def getWinner():\r\n",
        "    global globalDict\r\n",
        "    keys = np.array( list( globalDict.keys() ) )\r\n",
        "    vals = np.array( list( globalDict.values() ) )\r\n",
        "    winnerIdx = np.argmin( vals )\r\n",
        "    winner = keys[ winnerIdx ]\r\n",
        "    return winner\r\n",
        "\r\n",
        "  max_iter = 10"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULjUdz_VVMhi"
      },
      "source": [
        "### Set-seeds:\r\n",
        "\r\n",
        "run_num_1 = 1\r\n",
        "run_num_2 = 2\r\n",
        "run_num_3 = 3333\r\n",
        "run_num_4 = 4\r\n",
        "run_num_5 = 555\r\n",
        "run_num_6 = 6\r\n",
        "run_num_7 = 7\r\n",
        "run_num_8 = 88\r\n",
        "run_num_9 = 99999\r\n",
        "run_num_10 = 1000\r\n",
        "run_num_11 = 11\r\n",
        "run_num_12 = 1222\r\n",
        "run_num_13 = 13\r\n",
        "run_num_14 = 14\r\n",
        "run_num_15 = 155\r\n",
        "run_num_16 = 1667\r\n",
        "run_num_17 = 1777\r\n",
        "run_num_18 = 188\r\n",
        "run_num_19 = 19\r\n",
        "run_num_20 = 20\r\n",
        "\r\n",
        "y_global_orig = 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D17KR38gYRE6",
        "outputId": "87cbef07-8cf1-4fcc-e919-02ed528b873a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 1\r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_loser_1 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_1 = d2GPGO(surrogate_loser_1, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.417022]. \t  11254.0 \t 12696.0\n",
            "init   \t [0.68467162]. \t  8453.0 \t 12696.0\n",
            "init   \t [0.24385644]. \t  12696.0 \t 12696.0\n",
            "init   \t [0.52583438]. \t  9416.0 \t 12696.0\n",
            "1      \t [0.67289702]. \t  \u001b[92m8173.0\u001b[0m \t 8173.0\n",
            "2      \t [0.00847621]. \t  \u001b[92m13577.0\u001b[0m \t 8173.0\n",
            "3      \t [0.73759115]. \t  \u001b[92m9869.0\u001b[0m \t 8173.0\n",
            "4      \t [0.11344079]. \t  \u001b[92m13409.0\u001b[0m \t 8173.0\n",
            "5      \t [0.34658064]. \t  \u001b[92m12158.0\u001b[0m \t 8173.0\n",
            "6      \t [0.25357886]. \t  \u001b[92m12681.0\u001b[0m \t 8173.0\n",
            "7      \t [0.262744]. \t  \u001b[92m12765.0\u001b[0m \t 8173.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrYi8mQSwUaj",
        "outputId": "7f18b603-ca52-41e0-8c42-0f139039dad6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 2\r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_loser_2 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_2 = d2GPGO(surrogate_loser_2, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.4359949]. \t  11013.0 \t 13577.0\n",
            "init   \t [0.27990374]. \t  12840.0 \t 13577.0\n",
            "init   \t [0.74772621]. \t  10110.0 \t 13577.0\n",
            "init   \t [0.007856]. \t  13577.0 \t 13577.0\n",
            "1      \t [0.62355804]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "2      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "3      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "4      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "5      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "6      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "7      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "8      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n",
            "9      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 6672.0\n",
            "10     \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NsIJB6Bws4q",
        "outputId": "a0c6159f-f5dc-4aef-b123-d3ead9fbb722"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 3\r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_loser_3 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_3 = d2GPGO(surrogate_loser_3, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.75157561]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "init   \t [0.51198591]. \t  9464.0 \t 14019.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 14019.0\n",
            "1      \t [0.5561781]. \t  \u001b[92m8554.0\u001b[0m \t 8554.0\n",
            "2      \t [0.44732037]. \t  \u001b[92m10874.0\u001b[0m \t 8554.0\n",
            "3      \t [0.19297376]. \t  \u001b[92m13101.0\u001b[0m \t 8554.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 8554.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 8554.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 8554.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 8554.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 8554.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8554.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8554.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AW-ZhjzxC7S",
        "outputId": "ddde4042-d85f-43be-96a3-379de67cde11"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 4\r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_loser_4 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_4 = d2GPGO(surrogate_loser_4, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.96702984]. \t  13962.0 \t 14019.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 14019.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "1      \t [0.00949436]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.58873335]. \t  \u001b[92m7940.0\u001b[0m \t 7940.0\n",
            "4      \t [0.90925644]. \t  \u001b[92m13431.0\u001b[0m \t 7940.0\n",
            "5      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7940.0\n",
            "6      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7940.0\n",
            "7      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7940.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_362CbCxTja",
        "outputId": "b6cc9119-ded4-4ffd-d088-5ea32a8887d7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 5\r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_loser_5 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_5 = d2GPGO(surrogate_loser_5, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.71783409]. \t  9343.0 \t 13169.0\n",
            "init   \t [0.21573829]. \t  13169.0 \t 13169.0\n",
            "init   \t [0.88513393]. \t  13154.0 \t 13169.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13169.0\n",
            "1      \t [0.50046669]. \t  \u001b[92m9472.0\u001b[0m \t 9343.0\n",
            "2      \t [0.60739275]. \t  \u001b[92m7178.0\u001b[0m \t 7178.0\n",
            "3      \t [0.56613346]. \t  \u001b[92m7747.0\u001b[0m \t 7178.0\n",
            "4      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7178.0\n",
            "5      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7178.0\n",
            "6      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7178.0\n",
            "7      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7178.0\n",
            "8      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7178.0\n",
            "9      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7178.0\n",
            "10     \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7178.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq1gQLFgxbhj",
        "outputId": "5e075026-0d4c-4bb0-96ff-b49852bb524e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 6\r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_loser_6 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_6 = d2GPGO(surrogate_loser_6, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89286015]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50038269]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.00757141]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blHM3jnYxpVL",
        "outputId": "220f000b-3073-4d16-d688-8baa20141f22"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 7\r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_loser_7 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_7 = d2GPGO(surrogate_loser_7, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.07630829]. \t  13442.0 \t 13503.0\n",
            "init   \t [0.3076631]. \t  12533.0 \t 13503.0\n",
            "init   \t [0.06469076]. \t  13503.0 \t 13503.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13503.0\n",
            "1      \t [0.98036145]. \t  \u001b[92m14019.0\u001b[0m \t 9464.0\n",
            "2      \t [0.68720353]. \t  \u001b[92m8453.0\u001b[0m \t 8453.0\n",
            "3      \t [0.67392032]. \t  \u001b[92m8173.0\u001b[0m \t 8173.0\n",
            "4      \t [0.87162387]. \t  \u001b[92m13019.0\u001b[0m \t 8173.0\n",
            "5      \t [0.00538944]. \t  \u001b[92m13577.0\u001b[0m \t 8173.0\n",
            "6      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8173.0\n",
            "7      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8173.0\n",
            "8      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 8173.0\n",
            "9      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 8173.0\n",
            "10     \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 8173.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV5G9m-5x2Br",
        "outputId": "a0f73387-1a60-4b56-efec-a8fae853120b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 8\r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_loser_8 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_8 = d2GPGO(surrogate_loser_8, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.64755105]. \t  7277.0 \t 13962.0\n",
            "init   \t [0.93600076]. \t  13728.0 \t 13962.0\n",
            "init   \t [0.96051377]. \t  13962.0 \t 13962.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 13962.0\n",
            "1      \t [0.01382912]. \t  \u001b[92m13603.0\u001b[0m \t 7277.0\n",
            "2      \t [0.37401417]. \t  \u001b[92m11677.0\u001b[0m \t 7277.0\n",
            "3      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7277.0\n",
            "4      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7277.0\n",
            "5      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7277.0\n",
            "6      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7277.0\n",
            "7      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7277.0\n",
            "8      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7277.0\n",
            "9      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "10     \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18hoXfzQzcF6",
        "outputId": "9173d3cc-338a-4726-e834-00c229d67b46"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 9\r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_loser_9 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_9 = d2GPGO(surrogate_loser_9, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.20706637]. \t  13263.0 \t 13685.0\n",
            "init   \t [0.72910832]. \t  9585.0 \t 13685.0\n",
            "init   \t [0.80093216]. \t  11701.0 \t 13685.0\n",
            "init   \t [0.04439363]. \t  13685.0 \t 13685.0\n",
            "1      \t [0.59904747]. \t  \u001b[92m7210.0\u001b[0m \t 7210.0\n",
            "2      \t [0.47931887]. \t  \u001b[92m10418.0\u001b[0m \t 7210.0\n",
            "3      \t [0.90715029]. \t  \u001b[92m13431.0\u001b[0m \t 7210.0\n",
            "4      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7210.0\n",
            "5      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7210.0\n",
            "6      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7210.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wrqaX_EzcXC",
        "outputId": "997f7c15-ab22-4fdb-ed6f-a3f63f582e73"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 10\r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_loser_10 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_10 = d2GPGO(surrogate_loser_10, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65358959]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [0.9795807]. \t  \u001b[92m13990.0\u001b[0m \t 7572.0\n",
            "2      \t [0.71272955]. \t  \u001b[92m9343.0\u001b[0m \t 7572.0\n",
            "3      \t [0.21573829]. \t  \u001b[92m13169.0\u001b[0m \t 7572.0\n",
            "4      \t [0.88513393]. \t  \u001b[92m13154.0\u001b[0m \t 7572.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7572.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7572.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7572.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7572.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7572.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soFmsoi9zcdB",
        "outputId": "8eb0bc72-2f08-4966-8171-9c0bf75ebec5"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 11\r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_loser_11 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_11 = d2GPGO(surrogate_loser_11, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.18026969]. \t  13281.0 \t 13281.0\n",
            "init   \t [0.61298159]. \t  7424.0 \t 13281.0\n",
            "init   \t [0.29368678]. \t  12546.0 \t 13281.0\n",
            "init   \t [0.29132308]. \t  12546.0 \t 13281.0\n",
            "1      \t [0.99379924]. \t  \u001b[92m14063.0\u001b[0m \t 7424.0\n",
            "2      \t [0.70345528]. \t  \u001b[92m9060.0\u001b[0m \t 7424.0\n",
            "3      \t [0.0740075]. \t  \u001b[92m13442.0\u001b[0m \t 7424.0\n",
            "4      \t [0.3076631]. \t  \u001b[92m12533.0\u001b[0m \t 7424.0\n",
            "5      \t [0.06469076]. \t  \u001b[92m13503.0\u001b[0m \t 7424.0\n",
            "6      \t [0.51622115]. \t  \u001b[92m9464.0\u001b[0m \t 7424.0\n",
            "7      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7424.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7424.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7424.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7424.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CONGlWtUzciA",
        "outputId": "3eed4c62-1ab3-4cc8-86b5-f34c78e33632"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 12\r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_loser_12 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_12 = d2GPGO(surrogate_loser_12, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.06748528]. \t  13503.0 \t 13505.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "1      \t [0.99080111]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.70345528]. \t  \u001b[92m9060.0\u001b[0m \t 9060.0\n",
            "3      \t [0.65817875]. \t  \u001b[92m7572.0\u001b[0m \t 7572.0\n",
            "4      \t [0.42232996]. \t  \u001b[92m11151.0\u001b[0m \t 7572.0\n",
            "5      \t [0.05316146]. \t  \u001b[92m13656.0\u001b[0m \t 7572.0\n",
            "6      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7572.0\n",
            "7      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7572.0\n",
            "8      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "9      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 7572.0\n",
            "10     \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR9WC6s8zcm9",
        "outputId": "60229c9d-ec26-431a-822e-e405950f6a60"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 13\r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_loser_13 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_13 = d2GPGO(surrogate_loser_13, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.77770241]. \t  10939.0 \t 13619.0\n",
            "init   \t [0.92603084]. \t  13619.0 \t 13619.0\n",
            "init   \t [0.88451529]. \t  13154.0 \t 13619.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13619.0\n",
            "1      \t [0.00250195]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.62660258]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "4      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "5      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "6      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDfu9f9PzcsN",
        "outputId": "626f5d1c-394f-4af1-a47c-ef8f626fca6a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 14\r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_loser_14 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_14 = d2GPGO(surrogate_loser_14, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51394334]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rxpin3Fzcxp",
        "outputId": "a94e0b63-b05b-43a6-a0e6-65555653be0d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 15\r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_loser_15 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_15 = d2GPGO(surrogate_loser_15, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65232633]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [0.9795807]. \t  \u001b[92m13990.0\u001b[0m \t 7572.0\n",
            "2      \t [0.71272955]. \t  \u001b[92m9343.0\u001b[0m \t 7572.0\n",
            "3      \t [0.21573829]. \t  \u001b[92m13169.0\u001b[0m \t 7572.0\n",
            "4      \t [0.88513393]. \t  \u001b[92m13154.0\u001b[0m \t 7572.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7572.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7572.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7572.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7572.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7572.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXp3WoVTzc22",
        "outputId": "c9522c76-ef14-46c9-bf32-e65e45cdb442"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 16\r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_loser_16 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_16 = d2GPGO(surrogate_loser_16, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89472424]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50038269]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.00757141]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGQANct4zc8j",
        "outputId": "0fe26e7b-17c6-4b17-accd-de5dc4602c21"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 17\r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_loser_17 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_17 = d2GPGO(surrogate_loser_17, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.03062042]. \t  13305.0 \t 13505.0\n",
            "init   \t [0.08122315]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tJrFjh5zdDN",
        "outputId": "b7d7b1ae-a9f4-4b65-ad2c-0226d18d657f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 18\r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_loser_18 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_18 = d2GPGO(surrogate_loser_18, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51197762]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2cJMYL8zdMB",
        "outputId": "88db8d62-bf6b-4dfd-c509-f4c63c7b6842"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 19\r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_loser_19 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_19 = d2GPGO(surrogate_loser_19, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.0975336]. \t  13585.0 \t 13585.0\n",
            "init   \t [0.40764505]. \t  11522.0 \t 13585.0\n",
            "init   \t [0.26268]. \t  12765.0 \t 13585.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13585.0\n",
            "1      \t [0.9950895]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "2      \t [0.74013984]. \t  \u001b[92m10110.0\u001b[0m \t 6992.0\n",
            "3      \t [0.007856]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "4      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "5      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "6      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "7      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "8      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0JmbY_6zdTQ",
        "outputId": "cda8858e-869e-40a6-ffd9-f09be59b597f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 20\r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_loser_20 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_20 = d2GPGO(surrogate_loser_20, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.5881308]. \t  7940.0 \t 13914.0\n",
            "init   \t [0.90925644]. \t  13431.0 \t 13914.0\n",
            "init   \t [0.89555325]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "1      \t [0.00214044]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 7940.0\n",
            "3      \t [0.1964637]. \t  \u001b[92m13101.0\u001b[0m \t 7940.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7940.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7940.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7940.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7940.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7940.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7940.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se976GulzdZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aada41f6-84a1-4194-d3d6-2a6eff14b161"
      },
      "source": [
        "end_lose = time.time()\r\n",
        "end_lose\r\n",
        "\r\n",
        "time_lose = end_lose - start_lose\r\n",
        "time_lose\r\n",
        "\r\n",
        "start_win = time.time()\r\n",
        "start_win"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1610387798.986176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEx2XiTi13jM",
        "outputId": "5c927038-137d-4d75-e5a9-33e6bc951312"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 1 \r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_winner_1 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_1 = GPGO_min(surrogate_winner_1, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.417022]. \t  11254.0 \t 12696.0\n",
            "init   \t [0.68467162]. \t  8453.0 \t 12696.0\n",
            "init   \t [0.24385644]. \t  12696.0 \t 12696.0\n",
            "init   \t [0.52583438]. \t  9416.0 \t 12696.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 8453.0\n",
            "2      \t [0.73022551]. \t  \u001b[92m9869.0\u001b[0m \t 8453.0\n",
            "3      \t [0.11344079]. \t  \u001b[92m13409.0\u001b[0m \t 8453.0\n",
            "4      \t [0.34658064]. \t  \u001b[92m12158.0\u001b[0m \t 8453.0\n",
            "5      \t [0.25357886]. \t  \u001b[92m12681.0\u001b[0m \t 8453.0\n",
            "6      \t [0.262744]. \t  \u001b[92m12765.0\u001b[0m \t 8453.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zugirIgK14Oy",
        "outputId": "50e8e6b1-7966-4a92-9215-276b83a2e553"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 2 \r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_winner_2 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_2 = GPGO_min(surrogate_winner_2, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.4359949]. \t  11013.0 \t 13577.0\n",
            "init   \t [0.27990374]. \t  12840.0 \t 13577.0\n",
            "init   \t [0.74772621]. \t  10110.0 \t 13577.0\n",
            "init   \t [0.007856]. \t  13577.0 \t 13577.0\n",
            "1      \t [0.64511474]. \t  \u001b[92m7277.0\u001b[0m \t 7277.0\n",
            "2      \t [0.93600076]. \t  \u001b[92m13728.0\u001b[0m \t 7277.0\n",
            "3      \t [0.96051377]. \t  \u001b[92m13962.0\u001b[0m \t 7277.0\n",
            "4      \t [0.88857941]. \t  \u001b[92m13154.0\u001b[0m \t 7277.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7277.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7277.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7277.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7277.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7277.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7277.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mzHrT7j14Yi",
        "outputId": "07fa9398-0e2d-45c2-add0-1efd8400e21b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 3 \r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_winner_3 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_3 = GPGO_min(surrogate_winner_3, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.75157561]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "init   \t [0.51198591]. \t  9464.0 \t 14019.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 14019.0\n",
            "1      \t [0.55679395]. \t  \u001b[92m8554.0\u001b[0m \t 8554.0\n",
            "2      \t [0.44732037]. \t  \u001b[92m10874.0\u001b[0m \t 8554.0\n",
            "3      \t [0.19297376]. \t  \u001b[92m13101.0\u001b[0m \t 8554.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 8554.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 8554.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 8554.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 8554.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 8554.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8554.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8554.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWCaOA0q14cC",
        "outputId": "c50fdd9f-716d-483a-d8a8-a12a7fc20869"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 4 \r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_winner_4 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_4 = GPGO_min(surrogate_winner_4, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.96702984]. \t  13962.0 \t 14019.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 14019.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.35712688]. \t  \u001b[92m12143.0\u001b[0m \t 10387.0\n",
            "3      \t [0.60419659]. \t  \u001b[92m7178.0\u001b[0m \t 7178.0\n",
            "4      \t [0.56613346]. \t  \u001b[92m7747.0\u001b[0m \t 7178.0\n",
            "5      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7178.0\n",
            "6      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7178.0\n",
            "7      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7178.0\n",
            "8      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7178.0\n",
            "9      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7178.0\n",
            "10     \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7178.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk_ztlly14lC",
        "outputId": "508975f8-81f8-421b-d67e-12baf82c1cac"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 5 \r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_winner_5 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_5 = GPGO_min(surrogate_winner_5, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.71783409]. \t  9343.0 \t 13169.0\n",
            "init   \t [0.21573829]. \t  13169.0 \t 13169.0\n",
            "init   \t [0.88513393]. \t  13154.0 \t 13169.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13169.0\n",
            "1      \t [0.49991138]. \t  \u001b[92m9953.0\u001b[0m \t 9343.0\n",
            "2      \t [0.62864535]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "3      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "4      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "5      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "6      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "7      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "8      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "9      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n",
            "10     \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKgBRmWy14-C",
        "outputId": "37027ee1-3897-41e4-f0ee-9171b913b0a9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 6 \r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_winner_6 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_6 = GPGO_min(surrogate_winner_6, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89286015]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50110601]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdqhsfhQ15C_",
        "outputId": "90d72b46-28bb-462d-ff18-3cf4b8f8474e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 7 \r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_winner_7 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_7 = GPGO_min(surrogate_winner_7, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.07630829]. \t  13442.0 \t 13503.0\n",
            "init   \t [0.3076631]. \t  12533.0 \t 13503.0\n",
            "init   \t [0.06469076]. \t  13503.0 \t 13503.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13503.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.69643804]. \t  \u001b[92m8731.0\u001b[0m \t 8731.0\n",
            "3      \t [0.66735401]. \t  \u001b[92m7888.0\u001b[0m \t 7888.0\n",
            "4      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7888.0\n",
            "5      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7888.0\n",
            "6      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7888.0\n",
            "7      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7888.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mS2c3bY15HS",
        "outputId": "481efa44-9ebb-4b59-cc6b-e10a2ca3fe9e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 8 \r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_winner_8 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_8 = GPGO_min(surrogate_winner_8, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.64755105]. \t  7277.0 \t 13962.0\n",
            "init   \t [0.93600076]. \t  13728.0 \t 13962.0\n",
            "init   \t [0.96051377]. \t  13962.0 \t 13962.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 13962.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 7277.0\n",
            "2      \t [0.35392416]. \t  \u001b[92m12143.0\u001b[0m \t 7277.0\n",
            "3      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7277.0\n",
            "4      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7277.0\n",
            "5      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7277.0\n",
            "6      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7277.0\n",
            "7      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7277.0\n",
            "8      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7277.0\n",
            "9      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7277.0\n",
            "10     \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7277.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWr4DqE615LK",
        "outputId": "23241675-d527-4e50-e295-2f67c1fc1c2a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 9 \r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_winner_9 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_9 = GPGO_min(surrogate_winner_9, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.20706637]. \t  13263.0 \t 13685.0\n",
            "init   \t [0.72910832]. \t  9585.0 \t 13685.0\n",
            "init   \t [0.80093216]. \t  11701.0 \t 13685.0\n",
            "init   \t [0.04439363]. \t  13685.0 \t 13685.0\n",
            "1      \t [0.59602253]. \t  \u001b[92m7210.0\u001b[0m \t 7210.0\n",
            "2      \t [0.47931887]. \t  \u001b[92m10418.0\u001b[0m \t 7210.0\n",
            "3      \t [0.90715029]. \t  \u001b[92m13431.0\u001b[0m \t 7210.0\n",
            "4      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7210.0\n",
            "5      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7210.0\n",
            "6      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7210.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgON7wCa15Px",
        "outputId": "1c5c9680-e1c1-45f4-f6c2-84633a61ac03"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 10 \r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_winner_10 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_10 = GPGO_min(surrogate_winner_10, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65358959]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "2      \t [0.72737403]. \t  \u001b[92m9585.0\u001b[0m \t 7572.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7572.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7572.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7572.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7572.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7572.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7572.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7572.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss_C7dO615UP",
        "outputId": "fc0aad27-e9a1-4c1c-a810-b82aa09b68d4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 11 \r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_winner_11 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_11 = GPGO_min(surrogate_winner_11, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.18026969]. \t  13281.0 \t 13281.0\n",
            "init   \t [0.61298159]. \t  7424.0 \t 13281.0\n",
            "init   \t [0.29368678]. \t  12546.0 \t 13281.0\n",
            "init   \t [0.29132308]. \t  12546.0 \t 13281.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7424.0\n",
            "2      \t [0.7055666]. \t  \u001b[92m9060.0\u001b[0m \t 7424.0\n",
            "3      \t [0.0740075]. \t  \u001b[92m13442.0\u001b[0m \t 7424.0\n",
            "4      \t [0.3076631]. \t  \u001b[92m12533.0\u001b[0m \t 7424.0\n",
            "5      \t [0.06469076]. \t  \u001b[92m13503.0\u001b[0m \t 7424.0\n",
            "6      \t [0.51622115]. \t  \u001b[92m9464.0\u001b[0m \t 7424.0\n",
            "7      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7424.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7424.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7424.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7424.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVqYzvY315Y9",
        "outputId": "ff39d5ba-f522-41f5-fed2-87cb48d08f9e"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 12 \r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_winner_12 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_12 = GPGO_min(surrogate_winner_12, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.06748528]. \t  13503.0 \t 13505.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.70526508]. \t  \u001b[92m9060.0\u001b[0m \t 9060.0\n",
            "3      \t [0.65613203]. \t  \u001b[92m7572.0\u001b[0m \t 7572.0\n",
            "4      \t [0.42232996]. \t  \u001b[92m11151.0\u001b[0m \t 7572.0\n",
            "5      \t [0.05316146]. \t  \u001b[92m13656.0\u001b[0m \t 7572.0\n",
            "6      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7572.0\n",
            "7      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7572.0\n",
            "8      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "9      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 7572.0\n",
            "10     \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAwtYRMv15d2",
        "outputId": "eeed2fcc-baef-4839-d579-85ec0bbf42bf"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 13 \r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_winner_13 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_13 = GPGO_min(surrogate_winner_13, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.77770241]. \t  10939.0 \t 13619.0\n",
            "init   \t [0.92603084]. \t  13619.0 \t 13619.0\n",
            "init   \t [0.88451529]. \t  13154.0 \t 13619.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13619.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36128068]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.62379855]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "4      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "5      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "6      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz33Woa215is",
        "outputId": "a22611e7-b29e-4da4-843c-6907eeeb30f9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 14 \r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_winner_14 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_14 = GPGO_min(surrogate_winner_14, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51394334]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72684554]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwyuIc115oH",
        "outputId": "bf8c1de0-9985-44cd-97c1-382c5cc46e8c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 15 \r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_winner_15 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_15 = GPGO_min(surrogate_winner_15, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65232633]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "2      \t [0.72750075]. \t  \u001b[92m9585.0\u001b[0m \t 7572.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7572.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7572.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7572.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7572.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7572.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7572.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7572.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRLyr5cS15t3",
        "outputId": "e23051b4-77ad-425d-90a4-7238dcd8d044"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 16 \r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_winner_16 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_16 = GPGO_min(surrogate_winner_16, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89472424]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50227766]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnuBlG515zz",
        "outputId": "d3a63bb0-50de-4bcd-97d9-ce8258f834f4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 17 \r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_winner_17 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_17 = GPGO_min(surrogate_winner_17, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.03062042]. \t  13305.0 \t 13505.0\n",
            "init   \t [0.08122315]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72740123]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWK-H-6Y157M",
        "outputId": "41270295-3ad0-4c16-ff6e-6d833003799f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 18 \r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_winner_18 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_18 = GPGO_min(surrogate_winner_18, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51197762]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72640948]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y924TuRx16Dm",
        "outputId": "fb5c5be0-f449-49bc-ca44-388d8812fc42"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 19 \r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_winner_19 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_19 = GPGO_min(surrogate_winner_19, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.0975336]. \t  13585.0 \t 13585.0\n",
            "init   \t [0.40764505]. \t  11522.0 \t 13585.0\n",
            "init   \t [0.26268]. \t  12765.0 \t 13585.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13585.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "2      \t [0.7441146]. \t  \u001b[92m10110.0\u001b[0m \t 6992.0\n",
            "3      \t [0.007856]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "4      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "5      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "6      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "7      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "8      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONx9ETQg16KN",
        "outputId": "ba43b6e8-7a49-458c-f187-8957fb447a00"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 20 \r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_winner_20 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_20 = GPGO_min(surrogate_winner_20, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.5881308]. \t  7940.0 \t 13914.0\n",
            "init   \t [0.90925644]. \t  13431.0 \t 13914.0\n",
            "init   \t [0.89555325]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "2      \t [0.3645615]. \t  \u001b[92m12051.0\u001b[0m \t 7940.0\n",
            "3      \t [0.1964637]. \t  \u001b[92m13101.0\u001b[0m \t 7940.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7940.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7940.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7940.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7940.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7940.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7940.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qfV1wj83xw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d5b709-d64b-43a6-cf18-22ebedc65123"
      },
      "source": [
        "end_win = time.time()\r\n",
        "end_win\r\n",
        "\r\n",
        "time_win = end_win - start_win\r\n",
        "time_win"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1219.2191252708435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_BXyha3yPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf5b005-666c-42ea-f947-81b014e3aefd"
      },
      "source": [
        "### Training regret minimization: run number = 1\r\n",
        "\r\n",
        "loser_output_1 = np.append(np.max(loser_1.GP.y[0:n_init]),loser_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_1 = np.append(np.max(winner_1.GP.y[0:n_init]),winner_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_1 = np.log(-y_global_orig + loser_output_1)\r\n",
        "regret_winner_1 = np.log(-y_global_orig + winner_output_1)\r\n",
        "\r\n",
        "train_regret_loser_1 = min_max_array(regret_loser_1)\r\n",
        "train_regret_winner_1 = min_max_array(regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1 = min(train_regret_loser_1)\r\n",
        "min_train_regret_winner_1 = min(train_regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1, min_train_regret_winner_1"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Jzxu4qEgxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220abc59-e698-4626-dc35-6fba8c123cee"
      },
      "source": [
        "### Training regret minimization: run number = 2\r\n",
        "\r\n",
        "loser_output_2 = np.append(np.max(loser_2.GP.y[0:n_init]),loser_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_2 = np.append(np.max(winner_2.GP.y[0:n_init]),winner_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_2 = np.log(-y_global_orig + loser_output_2)\r\n",
        "regret_winner_2 = np.log(-y_global_orig + winner_output_2)\r\n",
        "\r\n",
        "train_regret_loser_2 = min_max_array(regret_loser_2)\r\n",
        "train_regret_winner_2 = min_max_array(regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2 = min(train_regret_loser_2)\r\n",
        "min_train_regret_winner_2 = min(train_regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2, min_train_regret_winner_2"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.805674944038582, 8.892473968347087)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suF8efHHEg3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd32f14b-22bc-4a34-a2b5-88ce14657909"
      },
      "source": [
        "### Training regret minimization: run number = 3\r\n",
        "\r\n",
        "loser_output_3 = np.append(np.max(loser_3.GP.y[0:n_init]),loser_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_3 = np.append(np.max(winner_3.GP.y[0:n_init]),winner_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_3 = np.log(-y_global_orig + loser_output_3)\r\n",
        "regret_winner_3 = np.log(-y_global_orig + winner_output_3)\r\n",
        "\r\n",
        "train_regret_loser_3 = min_max_array(regret_loser_3)\r\n",
        "train_regret_winner_3 = min_max_array(regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3 = min(train_regret_loser_3)\r\n",
        "min_train_regret_winner_3 = min(train_regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3, min_train_regret_winner_3"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.054154288786854, 9.054154288786854)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPemfBgeEg8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcaa52b8-e2ef-4206-b334-67a2ae26fdf4"
      },
      "source": [
        "### Training regret minimization: run number = 4\r\n",
        "\r\n",
        "loser_output_4 = np.append(np.max(loser_4.GP.y[0:n_init]),loser_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_4 = np.append(np.max(winner_4.GP.y[0:n_init]),winner_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_4 = np.log(-y_global_orig + loser_output_4)\r\n",
        "regret_winner_4 = np.log(-y_global_orig + winner_output_4)\r\n",
        "\r\n",
        "train_regret_loser_4 = min_max_array(regret_loser_4)\r\n",
        "train_regret_winner_4 = min_max_array(regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4 = min(train_regret_loser_4)\r\n",
        "min_train_regret_winner_4 = min(train_regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4, min_train_regret_winner_4"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.878776071707552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5SRriB83yR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e8500b4-3d58-4295-ad8b-f04de329a0bb"
      },
      "source": [
        "### Training regret minimization: run number = 5\r\n",
        "\r\n",
        "loser_output_5 = np.append(np.max(loser_5.GP.y[0:n_init]),loser_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_5 = np.append(np.max(winner_5.GP.y[0:n_init]),winner_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_5 = np.log(-y_global_orig + loser_output_5)\r\n",
        "regret_winner_5 = np.log(-y_global_orig + winner_output_5)\r\n",
        "\r\n",
        "train_regret_loser_5 = min_max_array(regret_loser_5)\r\n",
        "train_regret_winner_5 = min_max_array(regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5 = min(train_regret_loser_5)\r\n",
        "min_train_regret_winner_5 = min(train_regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5, min_train_regret_winner_5"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.878776071707552, 8.805674944038582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUVta_GJFFaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d1d2e2-f946-4679-9a96-c1c1516021c2"
      },
      "source": [
        "### Training regret minimization: run number = 6\r\n",
        "\r\n",
        "loser_output_6 = np.append(np.max(loser_6.GP.y[0:n_init]),loser_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_6 = np.append(np.max(winner_6.GP.y[0:n_init]),winner_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_6 = np.log(-y_global_orig + loser_output_6)\r\n",
        "regret_winner_6 = np.log(-y_global_orig + winner_output_6)\r\n",
        "\r\n",
        "train_regret_loser_6 = min_max_array(regret_loser_6)\r\n",
        "train_regret_winner_6 = min_max_array(regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6 = min(train_regret_loser_6)\r\n",
        "min_train_regret_winner_6 = min(train_regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6, min_train_regret_winner_6"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7V7-xKKFFm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48bc60f1-7086-42bc-ad73-1cdde2b45e3e"
      },
      "source": [
        "### Training regret minimization: run number = 7\r\n",
        "\r\n",
        "loser_output_7 = np.append(np.max(loser_7.GP.y[0:n_init]),loser_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_7 = np.append(np.max(winner_7.GP.y[0:n_init]),winner_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_7 = np.log(-y_global_orig + loser_output_7)\r\n",
        "regret_winner_7 = np.log(-y_global_orig + winner_output_7)\r\n",
        "\r\n",
        "train_regret_loser_7 = min_max_array(regret_loser_7)\r\n",
        "train_regret_winner_7 = min_max_array(regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7 = min(train_regret_loser_7)\r\n",
        "min_train_regret_winner_7 = min(train_regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7, min_train_regret_winner_7"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.00859131751613, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMQ0rwZoFFuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c88ed0-cd03-4441-9989-c5dcb4cffb4a"
      },
      "source": [
        "### Training regret minimization: run number = 8\r\n",
        "\r\n",
        "loser_output_8 = np.append(np.max(loser_8.GP.y[0:n_init]),loser_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_8 = np.append(np.max(winner_8.GP.y[0:n_init]),winner_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_8 = np.log(-y_global_orig + loser_output_8)\r\n",
        "regret_winner_8 = np.log(-y_global_orig + winner_output_8)\r\n",
        "\r\n",
        "train_regret_loser_8 = min_max_array(regret_loser_8)\r\n",
        "train_regret_winner_8 = min_max_array(regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8 = min(train_regret_loser_8)\r\n",
        "min_train_regret_winner_8 = min(train_regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8, min_train_regret_winner_8"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW39Qs4ZFFzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c519edd3-438f-4ec4-e6b9-bc56301c2e65"
      },
      "source": [
        "### Training regret minimization: run number = 9\r\n",
        "\r\n",
        "loser_output_9 = np.append(np.max(loser_9.GP.y[0:n_init]),loser_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_9 = np.append(np.max(winner_9.GP.y[0:n_init]),winner_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_9 = np.log(-y_global_orig + loser_output_9)\r\n",
        "regret_winner_9 = np.log(-y_global_orig + winner_output_9)\r\n",
        "\r\n",
        "train_regret_loser_9 = min_max_array(regret_loser_9)\r\n",
        "train_regret_winner_9 = min_max_array(regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9 = min(train_regret_loser_9)\r\n",
        "min_train_regret_winner_9 = min(train_regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9, min_train_regret_winner_9"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH5fvkDWFF4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "871b1d18-f607-4846-9ad4-899fa0f266f1"
      },
      "source": [
        "### Training regret minimization: run number = 10\r\n",
        "\r\n",
        "loser_output_10 = np.append(np.max(loser_10.GP.y[0:n_init]),loser_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_10 = np.append(np.max(winner_10.GP.y[0:n_init]),winner_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_10 = np.log(-y_global_orig + loser_output_10)\r\n",
        "regret_winner_10 = np.log(-y_global_orig + winner_output_10)\r\n",
        "\r\n",
        "train_regret_loser_10 = min_max_array(regret_loser_10)\r\n",
        "train_regret_winner_10 = min_max_array(regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10 = min(train_regret_loser_10)\r\n",
        "min_train_regret_winner_10 = min(train_regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10, min_train_regret_winner_10"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdGgTNueFF8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ba35cf-ac3a-4529-beda-9df76763a5db"
      },
      "source": [
        "### Training regret minimization: run number = 11\r\n",
        "\r\n",
        "loser_output_11 = np.append(np.max(loser_11.GP.y[0:n_init]),loser_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_11 = np.append(np.max(winner_11.GP.y[0:n_init]),winner_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_11 = np.log(-y_global_orig + loser_output_11)\r\n",
        "regret_winner_11 = np.log(-y_global_orig + winner_output_11)\r\n",
        "\r\n",
        "train_regret_loser_11 = min_max_array(regret_loser_11)\r\n",
        "train_regret_winner_11 = min_max_array(regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11 = min(train_regret_loser_11)\r\n",
        "min_train_regret_winner_11 = min(train_regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11, min_train_regret_winner_11"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVeNgJSbFGAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2691862-329a-49c9-a3ea-36a549010545"
      },
      "source": [
        "### Training regret minimization: run number = 12\r\n",
        "\r\n",
        "loser_output_12 = np.append(np.max(loser_12.GP.y[0:n_init]),loser_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_12 = np.append(np.max(winner_12.GP.y[0:n_init]),winner_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_12 = np.log(-y_global_orig + loser_output_12)\r\n",
        "regret_winner_12 = np.log(-y_global_orig + winner_output_12)\r\n",
        "\r\n",
        "train_regret_loser_12 = min_max_array(regret_loser_12)\r\n",
        "train_regret_winner_12 = min_max_array(regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12 = min(train_regret_loser_12)\r\n",
        "min_train_regret_winner_12 = min(train_regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12, min_train_regret_winner_12"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.932212512329214, 8.932212512329214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GIrEFAMFGD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbbbac68-b79d-42cf-86de-c7e5884e75ce"
      },
      "source": [
        "### Training regret minimization: run number = 13\r\n",
        "\r\n",
        "loser_output_13 = np.append(np.max(loser_13.GP.y[0:n_init]),loser_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_13 = np.append(np.max(winner_13.GP.y[0:n_init]),winner_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_13 = np.log(-y_global_orig + loser_output_13)\r\n",
        "regret_winner_13 = np.log(-y_global_orig + winner_output_13)\r\n",
        "\r\n",
        "train_regret_loser_13 = min_max_array(regret_loser_13)\r\n",
        "train_regret_winner_13 = min_max_array(regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13 = min(train_regret_loser_13)\r\n",
        "min_train_regret_winner_13 = min(train_regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13, min_train_regret_winner_13"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.805674944038582, 8.805674944038582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV0iCAUQFGIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b4d9169-96b0-4bde-f1af-aee61b310a69"
      },
      "source": [
        "### Training regret minimization: run number = 14\r\n",
        "\r\n",
        "loser_output_14 = np.append(np.max(loser_14.GP.y[0:n_init]),loser_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_14 = np.append(np.max(winner_14.GP.y[0:n_init]),winner_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_14 = np.log(-y_global_orig + loser_output_14)\r\n",
        "regret_winner_14 = np.log(-y_global_orig + winner_output_14)\r\n",
        "\r\n",
        "train_regret_loser_14 = min_max_array(regret_loser_14)\r\n",
        "train_regret_winner_14 = min_max_array(regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14 = min(train_regret_loser_14)\r\n",
        "min_train_regret_winner_14 = min(train_regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14, min_train_regret_winner_14"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqZhhnBFGMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42aef2a8-e68c-479c-f343-48313ee4e131"
      },
      "source": [
        "### Training regret minimization: run number = 15\r\n",
        "\r\n",
        "loser_output_15 = np.append(np.max(loser_15.GP.y[0:n_init]),loser_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_15 = np.append(np.max(winner_15.GP.y[0:n_init]),winner_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_15 = np.log(-y_global_orig + loser_output_15)\r\n",
        "regret_winner_15 = np.log(-y_global_orig + winner_output_15)\r\n",
        "\r\n",
        "train_regret_loser_15 = min_max_array(regret_loser_15)\r\n",
        "train_regret_winner_15 = min_max_array(regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15 = min(train_regret_loser_15)\r\n",
        "min_train_regret_winner_15 = min(train_regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15, min_train_regret_winner_15"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPmJ7j3RFGRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "890784f2-f5ef-4c00-98d9-fcdf061d69e6"
      },
      "source": [
        "### Training regret minimization: run number = 16\r\n",
        "\r\n",
        "loser_output_16 = np.append(np.max(loser_16.GP.y[0:n_init]),loser_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_16 = np.append(np.max(winner_16.GP.y[0:n_init]),winner_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_16 = np.log(-y_global_orig + loser_output_16)\r\n",
        "regret_winner_16 = np.log(-y_global_orig + winner_output_16)\r\n",
        "\r\n",
        "train_regret_loser_16 = min_max_array(regret_loser_16)\r\n",
        "train_regret_winner_16 = min_max_array(regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16 = min(train_regret_loser_16)\r\n",
        "min_train_regret_winner_16 = min(train_regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16, min_train_regret_winner_16"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyyMg-bFGWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8ef7027-29bd-4b2c-e886-5331aa9b3fea"
      },
      "source": [
        "### Training regret minimization: run number = 17\r\n",
        "\r\n",
        "loser_output_17 = np.append(np.max(loser_17.GP.y[0:n_init]),loser_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_17 = np.append(np.max(winner_17.GP.y[0:n_init]),winner_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_17 = np.log(-y_global_orig + loser_output_17)\r\n",
        "regret_winner_17 = np.log(-y_global_orig + winner_output_17)\r\n",
        "\r\n",
        "train_regret_loser_17 = min_max_array(regret_loser_17)\r\n",
        "train_regret_winner_17 = min_max_array(regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17 = min(train_regret_loser_17)\r\n",
        "min_train_regret_winner_17 = min(train_regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17, min_train_regret_winner_17"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WS6hJYuFGa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36140fa7-b95c-4377-9819-5197f1b8e245"
      },
      "source": [
        "### Training regret minimization: run number = 18\r\n",
        "\r\n",
        "loser_output_18 = np.append(np.max(loser_18.GP.y[0:n_init]),loser_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_18 = np.append(np.max(winner_18.GP.y[0:n_init]),winner_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_18 = np.log(-y_global_orig + loser_output_18)\r\n",
        "regret_winner_18 = np.log(-y_global_orig + winner_output_18)\r\n",
        "\r\n",
        "train_regret_loser_18 = min_max_array(regret_loser_18)\r\n",
        "train_regret_winner_18 = min_max_array(regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18 = min(train_regret_loser_18)\r\n",
        "min_train_regret_winner_18 = min(train_regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18, min_train_regret_winner_18"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErcIOoOXFGgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1725c50c-86db-4e35-dc37-884b2a8aae3d"
      },
      "source": [
        "### Training regret minimization: run number = 19\r\n",
        "\r\n",
        "loser_output_19 = np.append(np.max(loser_19.GP.y[0:n_init]),loser_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_19 = np.append(np.max(winner_19.GP.y[0:n_init]),winner_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_19 = np.log(-y_global_orig + loser_output_19)\r\n",
        "regret_winner_19 = np.log(-y_global_orig + winner_output_19)\r\n",
        "\r\n",
        "train_regret_loser_19 = min_max_array(regret_loser_19)\r\n",
        "train_regret_winner_19 = min_max_array(regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19 = min(train_regret_loser_19)\r\n",
        "min_train_regret_winner_19 = min(train_regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19, min_train_regret_winner_19"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbOsumB6FGlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b714535-aee1-4fa7-b8a0-c3fed55b4e0d"
      },
      "source": [
        "### Training regret minimization: run number = 20\r\n",
        "\r\n",
        "loser_output_20 = np.append(np.max(loser_20.GP.y[0:n_init]),loser_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_20 = np.append(np.max(winner_20.GP.y[0:n_init]),winner_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_20 = np.log(-y_global_orig + loser_output_20)\r\n",
        "regret_winner_20 = np.log(-y_global_orig + winner_output_20)\r\n",
        "\r\n",
        "train_regret_loser_20 = min_max_array(regret_loser_20)\r\n",
        "train_regret_winner_20 = min_max_array(regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20 = min(train_regret_loser_20)\r\n",
        "min_train_regret_winner_20 = min(train_regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20, min_train_regret_winner_20"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.32259705432185, 9.32259705432185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89S668T8GSeJ"
      },
      "source": [
        "# Iteration1 :\r\n",
        "\r\n",
        "slice1 = 0\r\n",
        "\r\n",
        "loser1 = [train_regret_loser_1[slice1],\r\n",
        "       train_regret_loser_2[slice1],\r\n",
        "       train_regret_loser_3[slice1],\r\n",
        "       train_regret_loser_4[slice1],\r\n",
        "       train_regret_loser_5[slice1],\r\n",
        "       train_regret_loser_6[slice1],\r\n",
        "       train_regret_loser_7[slice1],\r\n",
        "       train_regret_loser_8[slice1],\r\n",
        "       train_regret_loser_9[slice1],\r\n",
        "       train_regret_loser_10[slice1],\r\n",
        "       train_regret_loser_11[slice1],\r\n",
        "       train_regret_loser_12[slice1],\r\n",
        "       train_regret_loser_13[slice1],\r\n",
        "       train_regret_loser_14[slice1],\r\n",
        "       train_regret_loser_15[slice1],\r\n",
        "       train_regret_loser_16[slice1],\r\n",
        "       train_regret_loser_17[slice1],\r\n",
        "       train_regret_loser_18[slice1],\r\n",
        "       train_regret_loser_19[slice1],\r\n",
        "       train_regret_loser_20[slice1]]\r\n",
        "\r\n",
        "winner1 = [train_regret_winner_1[slice1],\r\n",
        "       train_regret_winner_2[slice1],\r\n",
        "       train_regret_winner_3[slice1],\r\n",
        "       train_regret_winner_4[slice1],\r\n",
        "       train_regret_winner_5[slice1],\r\n",
        "       train_regret_winner_6[slice1],\r\n",
        "       train_regret_winner_7[slice1],\r\n",
        "       train_regret_winner_8[slice1],\r\n",
        "       train_regret_winner_9[slice1],\r\n",
        "       train_regret_winner_10[slice1],\r\n",
        "       train_regret_winner_11[slice1],\r\n",
        "       train_regret_winner_12[slice1],\r\n",
        "       train_regret_winner_13[slice1],\r\n",
        "       train_regret_winner_14[slice1],\r\n",
        "       train_regret_winner_15[slice1],\r\n",
        "       train_regret_winner_16[slice1],\r\n",
        "       train_regret_winner_17[slice1],\r\n",
        "       train_regret_winner_18[slice1],\r\n",
        "       train_regret_winner_19[slice1],\r\n",
        "       train_regret_winner_20[slice1]]\r\n",
        "\r\n",
        "loser1_results = pd.DataFrame(loser1).sort_values(by=[0], ascending=False)\r\n",
        "winner1_results = pd.DataFrame(winner1).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser1 = np.asarray(loser1_results[4:5][0])[0]\r\n",
        "median_loser1 = np.asarray(loser1_results[9:10][0])[0]\r\n",
        "upper_loser1 = np.asarray(loser1_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner1 = np.asarray(winner1_results[4:5][0])[0]\r\n",
        "median_winner1 = np.asarray(winner1_results[9:10][0])[0]\r\n",
        "upper_winner1 = np.asarray(winner1_results[14:15][0])[0]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CbMKkbYGSmk"
      },
      "source": [
        "# Iteration11 :\r\n",
        "\r\n",
        "slice11 = 10\r\n",
        "\r\n",
        "loser11 = [train_regret_loser_1[slice11],\r\n",
        "       train_regret_loser_2[slice11],\r\n",
        "       train_regret_loser_3[slice11],\r\n",
        "       train_regret_loser_4[slice11],\r\n",
        "       train_regret_loser_5[slice11],\r\n",
        "       train_regret_loser_6[slice11],\r\n",
        "       train_regret_loser_7[slice11],\r\n",
        "       train_regret_loser_8[slice11],\r\n",
        "       train_regret_loser_9[slice11],\r\n",
        "       train_regret_loser_10[slice11],\r\n",
        "       train_regret_loser_11[slice11],\r\n",
        "       train_regret_loser_12[slice11],\r\n",
        "       train_regret_loser_13[slice11],\r\n",
        "       train_regret_loser_14[slice11],\r\n",
        "       train_regret_loser_15[slice11],\r\n",
        "       train_regret_loser_16[slice11],\r\n",
        "       train_regret_loser_17[slice11],\r\n",
        "       train_regret_loser_18[slice11],\r\n",
        "       train_regret_loser_19[slice11],\r\n",
        "       train_regret_loser_20[slice11]]\r\n",
        "\r\n",
        "winner11 = [train_regret_winner_1[slice11],\r\n",
        "       train_regret_winner_2[slice11],\r\n",
        "       train_regret_winner_3[slice11],\r\n",
        "       train_regret_winner_4[slice11],\r\n",
        "       train_regret_winner_5[slice11],\r\n",
        "       train_regret_winner_6[slice11],\r\n",
        "       train_regret_winner_7[slice11],\r\n",
        "       train_regret_winner_8[slice11],\r\n",
        "       train_regret_winner_9[slice11],\r\n",
        "       train_regret_winner_10[slice11],\r\n",
        "       train_regret_winner_11[slice11],\r\n",
        "       train_regret_winner_12[slice11],\r\n",
        "       train_regret_winner_13[slice11],\r\n",
        "       train_regret_winner_14[slice11],\r\n",
        "       train_regret_winner_15[slice11],\r\n",
        "       train_regret_winner_16[slice11],\r\n",
        "       train_regret_winner_17[slice11],\r\n",
        "       train_regret_winner_18[slice11],\r\n",
        "       train_regret_winner_19[slice11],\r\n",
        "       train_regret_winner_20[slice11]]\r\n",
        "\r\n",
        "loser11_results = pd.DataFrame(loser11).sort_values(by=[0], ascending=False)\r\n",
        "winner11_results = pd.DataFrame(winner11).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser11 = np.asarray(loser11_results[4:5][0])[0]\r\n",
        "median_loser11 = np.asarray(loser11_results[9:10][0])[0]\r\n",
        "upper_loser11 = np.asarray(loser11_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner11 = np.asarray(winner11_results[4:5][0])[0]\r\n",
        "median_winner11 = np.asarray(winner11_results[9:10][0])[0]\r\n",
        "upper_winner11 = np.asarray(winner11_results[14:15][0])[0]"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dqqsAbZGSto"
      },
      "source": [
        "# Iteration2 :\r\n",
        "\r\n",
        "slice2 = 1\r\n",
        "\r\n",
        "loser2 = [train_regret_loser_1[slice2],\r\n",
        "       train_regret_loser_2[slice2],\r\n",
        "       train_regret_loser_3[slice2],\r\n",
        "       train_regret_loser_4[slice2],\r\n",
        "       train_regret_loser_5[slice2],\r\n",
        "       train_regret_loser_6[slice2],\r\n",
        "       train_regret_loser_7[slice2],\r\n",
        "       train_regret_loser_8[slice2],\r\n",
        "       train_regret_loser_9[slice2],\r\n",
        "       train_regret_loser_10[slice2],\r\n",
        "       train_regret_loser_11[slice2],\r\n",
        "       train_regret_loser_12[slice2],\r\n",
        "       train_regret_loser_13[slice2],\r\n",
        "       train_regret_loser_14[slice2],\r\n",
        "       train_regret_loser_15[slice2],\r\n",
        "       train_regret_loser_16[slice2],\r\n",
        "       train_regret_loser_17[slice2],\r\n",
        "       train_regret_loser_18[slice2],\r\n",
        "       train_regret_loser_19[slice2],\r\n",
        "       train_regret_loser_20[slice2]]\r\n",
        "\r\n",
        "winner2 = [train_regret_winner_1[slice2],\r\n",
        "       train_regret_winner_2[slice2],\r\n",
        "       train_regret_winner_3[slice2],\r\n",
        "       train_regret_winner_4[slice2],\r\n",
        "       train_regret_winner_5[slice2],\r\n",
        "       train_regret_winner_6[slice2],\r\n",
        "       train_regret_winner_7[slice2],\r\n",
        "       train_regret_winner_8[slice2],\r\n",
        "       train_regret_winner_9[slice2],\r\n",
        "       train_regret_winner_10[slice2],\r\n",
        "       train_regret_winner_11[slice2],\r\n",
        "       train_regret_winner_12[slice2],\r\n",
        "       train_regret_winner_13[slice2],\r\n",
        "       train_regret_winner_14[slice2],\r\n",
        "       train_regret_winner_15[slice2],\r\n",
        "       train_regret_winner_16[slice2],\r\n",
        "       train_regret_winner_17[slice2],\r\n",
        "       train_regret_winner_18[slice2],\r\n",
        "       train_regret_winner_19[slice2],\r\n",
        "       train_regret_winner_20[slice2]]\r\n",
        "\r\n",
        "loser2_results = pd.DataFrame(loser2).sort_values(by=[0], ascending=False)\r\n",
        "winner2_results = pd.DataFrame(winner2).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser2 = np.asarray(loser2_results[4:5][0])[0]\r\n",
        "median_loser2 = np.asarray(loser2_results[9:10][0])[0]\r\n",
        "upper_loser2 = np.asarray(loser2_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner2 = np.asarray(winner2_results[4:5][0])[0]\r\n",
        "median_winner2 = np.asarray(winner2_results[9:10][0])[0]\r\n",
        "upper_winner2 = np.asarray(winner2_results[14:15][0])[0]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT1vdmweGSza"
      },
      "source": [
        "# Iteration3 :\r\n",
        "\r\n",
        "slice3 = 2\r\n",
        "\r\n",
        "loser3 = [train_regret_loser_1[slice3],\r\n",
        "       train_regret_loser_2[slice3],\r\n",
        "       train_regret_loser_3[slice3],\r\n",
        "       train_regret_loser_4[slice3],\r\n",
        "       train_regret_loser_5[slice3],\r\n",
        "       train_regret_loser_6[slice3],\r\n",
        "       train_regret_loser_7[slice3],\r\n",
        "       train_regret_loser_8[slice3],\r\n",
        "       train_regret_loser_9[slice3],\r\n",
        "       train_regret_loser_10[slice3],\r\n",
        "       train_regret_loser_11[slice3],\r\n",
        "       train_regret_loser_12[slice3],\r\n",
        "       train_regret_loser_13[slice3],\r\n",
        "       train_regret_loser_14[slice3],\r\n",
        "       train_regret_loser_15[slice3],\r\n",
        "       train_regret_loser_16[slice3],\r\n",
        "       train_regret_loser_17[slice3],\r\n",
        "       train_regret_loser_18[slice3],\r\n",
        "       train_regret_loser_19[slice3],\r\n",
        "       train_regret_loser_20[slice3]]\r\n",
        "\r\n",
        "winner3 = [train_regret_winner_1[slice3],\r\n",
        "       train_regret_winner_2[slice3],\r\n",
        "       train_regret_winner_3[slice3],\r\n",
        "       train_regret_winner_4[slice3],\r\n",
        "       train_regret_winner_5[slice3],\r\n",
        "       train_regret_winner_6[slice3],\r\n",
        "       train_regret_winner_7[slice3],\r\n",
        "       train_regret_winner_8[slice3],\r\n",
        "       train_regret_winner_9[slice3],\r\n",
        "       train_regret_winner_10[slice3],\r\n",
        "       train_regret_winner_11[slice3],\r\n",
        "       train_regret_winner_12[slice3],\r\n",
        "       train_regret_winner_13[slice3],\r\n",
        "       train_regret_winner_14[slice3],\r\n",
        "       train_regret_winner_15[slice3],\r\n",
        "       train_regret_winner_16[slice3],\r\n",
        "       train_regret_winner_17[slice3],\r\n",
        "       train_regret_winner_18[slice3],\r\n",
        "       train_regret_winner_19[slice3],\r\n",
        "       train_regret_winner_20[slice3]]\r\n",
        "\r\n",
        "loser3_results = pd.DataFrame(loser3).sort_values(by=[0], ascending=False)\r\n",
        "winner3_results = pd.DataFrame(winner3).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser3 = np.asarray(loser3_results[4:5][0])[0]\r\n",
        "median_loser3 = np.asarray(loser3_results[9:10][0])[0]\r\n",
        "upper_loser3 = np.asarray(loser3_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner3 = np.asarray(winner3_results[4:5][0])[0]\r\n",
        "median_winner3 = np.asarray(winner3_results[9:10][0])[0]\r\n",
        "upper_winner3 = np.asarray(winner3_results[14:15][0])[0]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXZrawn0GS4Z"
      },
      "source": [
        "# Iteration4 :\r\n",
        "\r\n",
        "slice4 = 3\r\n",
        "\r\n",
        "loser4 = [train_regret_loser_1[slice4],\r\n",
        "       train_regret_loser_2[slice4],\r\n",
        "       train_regret_loser_3[slice4],\r\n",
        "       train_regret_loser_4[slice4],\r\n",
        "       train_regret_loser_5[slice4],\r\n",
        "       train_regret_loser_6[slice4],\r\n",
        "       train_regret_loser_7[slice4],\r\n",
        "       train_regret_loser_8[slice4],\r\n",
        "       train_regret_loser_9[slice4],\r\n",
        "       train_regret_loser_10[slice4],\r\n",
        "       train_regret_loser_11[slice4],\r\n",
        "       train_regret_loser_12[slice4],\r\n",
        "       train_regret_loser_13[slice4],\r\n",
        "       train_regret_loser_14[slice4],\r\n",
        "       train_regret_loser_15[slice4],\r\n",
        "       train_regret_loser_16[slice4],\r\n",
        "       train_regret_loser_17[slice4],\r\n",
        "       train_regret_loser_18[slice4],\r\n",
        "       train_regret_loser_19[slice4],\r\n",
        "       train_regret_loser_20[slice4]]\r\n",
        "\r\n",
        "winner4 = [train_regret_winner_1[slice4],\r\n",
        "       train_regret_winner_2[slice4],\r\n",
        "       train_regret_winner_3[slice4],\r\n",
        "       train_regret_winner_4[slice4],\r\n",
        "       train_regret_winner_5[slice4],\r\n",
        "       train_regret_winner_6[slice4],\r\n",
        "       train_regret_winner_7[slice4],\r\n",
        "       train_regret_winner_8[slice4],\r\n",
        "       train_regret_winner_9[slice4],\r\n",
        "       train_regret_winner_10[slice4],\r\n",
        "       train_regret_winner_11[slice4],\r\n",
        "       train_regret_winner_12[slice4],\r\n",
        "       train_regret_winner_13[slice4],\r\n",
        "       train_regret_winner_14[slice4],\r\n",
        "       train_regret_winner_15[slice4],\r\n",
        "       train_regret_winner_16[slice4],\r\n",
        "       train_regret_winner_17[slice4],\r\n",
        "       train_regret_winner_18[slice4],\r\n",
        "       train_regret_winner_19[slice4],\r\n",
        "       train_regret_winner_20[slice4]]\r\n",
        "\r\n",
        "loser4_results = pd.DataFrame(loser4).sort_values(by=[0], ascending=False)\r\n",
        "winner4_results = pd.DataFrame(winner4).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser4 = np.asarray(loser4_results[4:5][0])[0]\r\n",
        "median_loser4 = np.asarray(loser4_results[9:10][0])[0]\r\n",
        "upper_loser4 = np.asarray(loser4_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner4 = np.asarray(winner4_results[4:5][0])[0]\r\n",
        "median_winner4 = np.asarray(winner4_results[9:10][0])[0]\r\n",
        "upper_winner4 = np.asarray(winner4_results[14:15][0])[0]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN6pn6cNGyGZ"
      },
      "source": [
        "# Iteration5 :\r\n",
        "\r\n",
        "slice5 = 4\r\n",
        "\r\n",
        "loser5 = [train_regret_loser_1[slice5],\r\n",
        "       train_regret_loser_2[slice5],\r\n",
        "       train_regret_loser_3[slice5],\r\n",
        "       train_regret_loser_4[slice5],\r\n",
        "       train_regret_loser_5[slice5],\r\n",
        "       train_regret_loser_6[slice5],\r\n",
        "       train_regret_loser_7[slice5],\r\n",
        "       train_regret_loser_8[slice5],\r\n",
        "       train_regret_loser_9[slice5],\r\n",
        "       train_regret_loser_10[slice5],\r\n",
        "       train_regret_loser_11[slice5],\r\n",
        "       train_regret_loser_12[slice5],\r\n",
        "       train_regret_loser_13[slice5],\r\n",
        "       train_regret_loser_14[slice5],\r\n",
        "       train_regret_loser_15[slice5],\r\n",
        "       train_regret_loser_16[slice5],\r\n",
        "       train_regret_loser_17[slice5],\r\n",
        "       train_regret_loser_18[slice5],\r\n",
        "       train_regret_loser_19[slice5],\r\n",
        "       train_regret_loser_20[slice5]]\r\n",
        "\r\n",
        "winner5 = [train_regret_winner_1[slice5],\r\n",
        "       train_regret_winner_2[slice5],\r\n",
        "       train_regret_winner_3[slice5],\r\n",
        "       train_regret_winner_4[slice5],\r\n",
        "       train_regret_winner_5[slice5],\r\n",
        "       train_regret_winner_6[slice5],\r\n",
        "       train_regret_winner_7[slice5],\r\n",
        "       train_regret_winner_8[slice5],\r\n",
        "       train_regret_winner_9[slice5],\r\n",
        "       train_regret_winner_10[slice5],\r\n",
        "       train_regret_winner_11[slice5],\r\n",
        "       train_regret_winner_12[slice5],\r\n",
        "       train_regret_winner_13[slice5],\r\n",
        "       train_regret_winner_14[slice5],\r\n",
        "       train_regret_winner_15[slice5],\r\n",
        "       train_regret_winner_16[slice5],\r\n",
        "       train_regret_winner_17[slice5],\r\n",
        "       train_regret_winner_18[slice5],\r\n",
        "       train_regret_winner_19[slice5],\r\n",
        "       train_regret_winner_20[slice5]]\r\n",
        "\r\n",
        "loser5_results = pd.DataFrame(loser5).sort_values(by=[0], ascending=False)\r\n",
        "winner5_results = pd.DataFrame(winner5).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser5 = np.asarray(loser5_results[4:5][0])[0]\r\n",
        "median_loser5 = np.asarray(loser5_results[9:10][0])[0]\r\n",
        "upper_loser5 = np.asarray(loser5_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner5 = np.asarray(winner5_results[4:5][0])[0]\r\n",
        "median_winner5 = np.asarray(winner5_results[9:10][0])[0]\r\n",
        "upper_winner5 = np.asarray(winner5_results[14:15][0])[0]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urt-8ta6GyYX"
      },
      "source": [
        "# Iteration6 :\r\n",
        "\r\n",
        "slice6 = 5\r\n",
        "\r\n",
        "loser6 = [train_regret_loser_1[slice6],\r\n",
        "       train_regret_loser_2[slice6],\r\n",
        "       train_regret_loser_3[slice6],\r\n",
        "       train_regret_loser_4[slice6],\r\n",
        "       train_regret_loser_5[slice6],\r\n",
        "       train_regret_loser_6[slice6],\r\n",
        "       train_regret_loser_7[slice6],\r\n",
        "       train_regret_loser_8[slice6],\r\n",
        "       train_regret_loser_9[slice6],\r\n",
        "       train_regret_loser_10[slice6],\r\n",
        "       train_regret_loser_11[slice6],\r\n",
        "       train_regret_loser_12[slice6],\r\n",
        "       train_regret_loser_13[slice6],\r\n",
        "       train_regret_loser_14[slice6],\r\n",
        "       train_regret_loser_15[slice6],\r\n",
        "       train_regret_loser_16[slice6],\r\n",
        "       train_regret_loser_17[slice6],\r\n",
        "       train_regret_loser_18[slice6],\r\n",
        "       train_regret_loser_19[slice6],\r\n",
        "       train_regret_loser_20[slice6]]\r\n",
        "\r\n",
        "winner6 = [train_regret_winner_1[slice6],\r\n",
        "       train_regret_winner_2[slice6],\r\n",
        "       train_regret_winner_3[slice6],\r\n",
        "       train_regret_winner_4[slice6],\r\n",
        "       train_regret_winner_5[slice6],\r\n",
        "       train_regret_winner_6[slice6],\r\n",
        "       train_regret_winner_7[slice6],\r\n",
        "       train_regret_winner_8[slice6],\r\n",
        "       train_regret_winner_9[slice6],\r\n",
        "       train_regret_winner_10[slice6],\r\n",
        "       train_regret_winner_11[slice6],\r\n",
        "       train_regret_winner_12[slice6],\r\n",
        "       train_regret_winner_13[slice6],\r\n",
        "       train_regret_winner_14[slice6],\r\n",
        "       train_regret_winner_15[slice6],\r\n",
        "       train_regret_winner_16[slice6],\r\n",
        "       train_regret_winner_17[slice6],\r\n",
        "       train_regret_winner_18[slice6],\r\n",
        "       train_regret_winner_19[slice6],\r\n",
        "       train_regret_winner_20[slice6]]\r\n",
        "\r\n",
        "loser6_results = pd.DataFrame(loser6).sort_values(by=[0], ascending=False)\r\n",
        "winner6_results = pd.DataFrame(winner6).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser6 = np.asarray(loser6_results[4:5][0])[0]\r\n",
        "median_loser6 = np.asarray(loser6_results[9:10][0])[0]\r\n",
        "upper_loser6 = np.asarray(loser6_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner6 = np.asarray(winner6_results[4:5][0])[0]\r\n",
        "median_winner6 = np.asarray(winner6_results[9:10][0])[0]\r\n",
        "upper_winner6 = np.asarray(winner6_results[14:15][0])[0]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJb0cU0GybL"
      },
      "source": [
        "# Iteration7 :\r\n",
        "\r\n",
        "slice7 = 6\r\n",
        "\r\n",
        "loser7 = [train_regret_loser_1[slice7],\r\n",
        "       train_regret_loser_2[slice7],\r\n",
        "       train_regret_loser_3[slice7],\r\n",
        "       train_regret_loser_4[slice7],\r\n",
        "       train_regret_loser_5[slice7],\r\n",
        "       train_regret_loser_6[slice7],\r\n",
        "       train_regret_loser_7[slice7],\r\n",
        "       train_regret_loser_8[slice7],\r\n",
        "       train_regret_loser_9[slice7],\r\n",
        "       train_regret_loser_10[slice7],\r\n",
        "       train_regret_loser_11[slice7],\r\n",
        "       train_regret_loser_12[slice7],\r\n",
        "       train_regret_loser_13[slice7],\r\n",
        "       train_regret_loser_14[slice7],\r\n",
        "       train_regret_loser_15[slice7],\r\n",
        "       train_regret_loser_16[slice7],\r\n",
        "       train_regret_loser_17[slice7],\r\n",
        "       train_regret_loser_18[slice7],\r\n",
        "       train_regret_loser_19[slice7],\r\n",
        "       train_regret_loser_20[slice7]]\r\n",
        "\r\n",
        "winner7 = [train_regret_winner_1[slice7],\r\n",
        "       train_regret_winner_2[slice7],\r\n",
        "       train_regret_winner_3[slice7],\r\n",
        "       train_regret_winner_4[slice7],\r\n",
        "       train_regret_winner_5[slice7],\r\n",
        "       train_regret_winner_6[slice7],\r\n",
        "       train_regret_winner_7[slice7],\r\n",
        "       train_regret_winner_8[slice7],\r\n",
        "       train_regret_winner_9[slice7],\r\n",
        "       train_regret_winner_10[slice7],\r\n",
        "       train_regret_winner_11[slice7],\r\n",
        "       train_regret_winner_12[slice7],\r\n",
        "       train_regret_winner_13[slice7],\r\n",
        "       train_regret_winner_14[slice7],\r\n",
        "       train_regret_winner_15[slice7],\r\n",
        "       train_regret_winner_16[slice7],\r\n",
        "       train_regret_winner_17[slice7],\r\n",
        "       train_regret_winner_18[slice7],\r\n",
        "       train_regret_winner_19[slice7],\r\n",
        "       train_regret_winner_20[slice7]]\r\n",
        "\r\n",
        "loser7_results = pd.DataFrame(loser7).sort_values(by=[0], ascending=False)\r\n",
        "winner7_results = pd.DataFrame(winner7).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser7 = np.asarray(loser7_results[4:5][0])[0]\r\n",
        "median_loser7 = np.asarray(loser7_results[9:10][0])[0]\r\n",
        "upper_loser7 = np.asarray(loser7_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner7 = np.asarray(winner7_results[4:5][0])[0]\r\n",
        "median_winner7 = np.asarray(winner7_results[9:10][0])[0]\r\n",
        "upper_winner7 = np.asarray(winner7_results[14:15][0])[0]"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O8pwUkWGyeD"
      },
      "source": [
        "# Iteration8 :\r\n",
        "\r\n",
        "slice8 = 7\r\n",
        "\r\n",
        "loser8 = [train_regret_loser_1[slice8],\r\n",
        "       train_regret_loser_2[slice8],\r\n",
        "       train_regret_loser_3[slice8],\r\n",
        "       train_regret_loser_4[slice8],\r\n",
        "       train_regret_loser_5[slice8],\r\n",
        "       train_regret_loser_6[slice8],\r\n",
        "       train_regret_loser_7[slice8],\r\n",
        "       train_regret_loser_8[slice8],\r\n",
        "       train_regret_loser_9[slice8],\r\n",
        "       train_regret_loser_10[slice8],\r\n",
        "       train_regret_loser_11[slice8],\r\n",
        "       train_regret_loser_12[slice8],\r\n",
        "       train_regret_loser_13[slice8],\r\n",
        "       train_regret_loser_14[slice8],\r\n",
        "       train_regret_loser_15[slice8],\r\n",
        "       train_regret_loser_16[slice8],\r\n",
        "       train_regret_loser_17[slice8],\r\n",
        "       train_regret_loser_18[slice8],\r\n",
        "       train_regret_loser_19[slice8],\r\n",
        "       train_regret_loser_20[slice8]]\r\n",
        "\r\n",
        "winner8 = [train_regret_winner_1[slice8],\r\n",
        "       train_regret_winner_2[slice8],\r\n",
        "       train_regret_winner_3[slice8],\r\n",
        "       train_regret_winner_4[slice8],\r\n",
        "       train_regret_winner_5[slice8],\r\n",
        "       train_regret_winner_6[slice8],\r\n",
        "       train_regret_winner_7[slice8],\r\n",
        "       train_regret_winner_8[slice8],\r\n",
        "       train_regret_winner_9[slice8],\r\n",
        "       train_regret_winner_10[slice8],\r\n",
        "       train_regret_winner_11[slice8],\r\n",
        "       train_regret_winner_12[slice8],\r\n",
        "       train_regret_winner_13[slice8],\r\n",
        "       train_regret_winner_14[slice8],\r\n",
        "       train_regret_winner_15[slice8],\r\n",
        "       train_regret_winner_16[slice8],\r\n",
        "       train_regret_winner_17[slice8],\r\n",
        "       train_regret_winner_18[slice8],\r\n",
        "       train_regret_winner_19[slice8],\r\n",
        "       train_regret_winner_20[slice8]]\r\n",
        "\r\n",
        "loser8_results = pd.DataFrame(loser8).sort_values(by=[0], ascending=False)\r\n",
        "winner8_results = pd.DataFrame(winner8).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser8 = np.asarray(loser8_results[4:5][0])[0]\r\n",
        "median_loser8 = np.asarray(loser8_results[9:10][0])[0]\r\n",
        "upper_loser8 = np.asarray(loser8_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner8 = np.asarray(winner8_results[4:5][0])[0]\r\n",
        "median_winner8 = np.asarray(winner8_results[9:10][0])[0]\r\n",
        "upper_winner8 = np.asarray(winner8_results[14:15][0])[0]\r\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74IRSixNGyg5"
      },
      "source": [
        "# Iteration9 :\r\n",
        "\r\n",
        "slice9 = 8\r\n",
        "\r\n",
        "loser9 = [train_regret_loser_1[slice9],\r\n",
        "       train_regret_loser_2[slice9],\r\n",
        "       train_regret_loser_3[slice9],\r\n",
        "       train_regret_loser_4[slice9],\r\n",
        "       train_regret_loser_5[slice9],\r\n",
        "       train_regret_loser_6[slice9],\r\n",
        "       train_regret_loser_7[slice9],\r\n",
        "       train_regret_loser_8[slice9],\r\n",
        "       train_regret_loser_9[slice9],\r\n",
        "       train_regret_loser_10[slice9],\r\n",
        "       train_regret_loser_11[slice9],\r\n",
        "       train_regret_loser_12[slice9],\r\n",
        "       train_regret_loser_13[slice9],\r\n",
        "       train_regret_loser_14[slice9],\r\n",
        "       train_regret_loser_15[slice9],\r\n",
        "       train_regret_loser_16[slice9],\r\n",
        "       train_regret_loser_17[slice9],\r\n",
        "       train_regret_loser_18[slice9],\r\n",
        "       train_regret_loser_19[slice9],\r\n",
        "       train_regret_loser_20[slice9]]\r\n",
        "\r\n",
        "winner9 = [train_regret_winner_1[slice9],\r\n",
        "       train_regret_winner_2[slice9],\r\n",
        "       train_regret_winner_3[slice9],\r\n",
        "       train_regret_winner_4[slice9],\r\n",
        "       train_regret_winner_5[slice9],\r\n",
        "       train_regret_winner_6[slice9],\r\n",
        "       train_regret_winner_7[slice9],\r\n",
        "       train_regret_winner_8[slice9],\r\n",
        "       train_regret_winner_9[slice9],\r\n",
        "       train_regret_winner_10[slice9],\r\n",
        "       train_regret_winner_11[slice9],\r\n",
        "       train_regret_winner_12[slice9],\r\n",
        "       train_regret_winner_13[slice9],\r\n",
        "       train_regret_winner_14[slice9],\r\n",
        "       train_regret_winner_15[slice9],\r\n",
        "       train_regret_winner_16[slice9],\r\n",
        "       train_regret_winner_17[slice9],\r\n",
        "       train_regret_winner_18[slice9],\r\n",
        "       train_regret_winner_19[slice9],\r\n",
        "       train_regret_winner_20[slice9]]\r\n",
        "\r\n",
        "loser9_results = pd.DataFrame(loser9).sort_values(by=[0], ascending=False)\r\n",
        "winner9_results = pd.DataFrame(winner9).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser9 = np.asarray(loser9_results[4:5][0])[0]\r\n",
        "median_loser9 = np.asarray(loser9_results[9:10][0])[0]\r\n",
        "upper_loser9 = np.asarray(loser9_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner9 = np.asarray(winner9_results[4:5][0])[0]\r\n",
        "median_winner9 = np.asarray(winner9_results[9:10][0])[0]\r\n",
        "upper_winner9 = np.asarray(winner9_results[14:15][0])[0]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDnAlE4Gyjt"
      },
      "source": [
        "# Iteration10 :\r\n",
        "\r\n",
        "slice10 = 9\r\n",
        "\r\n",
        "loser10 = [train_regret_loser_1[slice10],\r\n",
        "       train_regret_loser_2[slice10],\r\n",
        "       train_regret_loser_3[slice10],\r\n",
        "       train_regret_loser_4[slice10],\r\n",
        "       train_regret_loser_5[slice10],\r\n",
        "       train_regret_loser_6[slice10],\r\n",
        "       train_regret_loser_7[slice10],\r\n",
        "       train_regret_loser_8[slice10],\r\n",
        "       train_regret_loser_9[slice10],\r\n",
        "       train_regret_loser_10[slice10],\r\n",
        "       train_regret_loser_11[slice10],\r\n",
        "       train_regret_loser_12[slice10],\r\n",
        "       train_regret_loser_13[slice10],\r\n",
        "       train_regret_loser_14[slice10],\r\n",
        "       train_regret_loser_15[slice10],\r\n",
        "       train_regret_loser_16[slice10],\r\n",
        "       train_regret_loser_17[slice10],\r\n",
        "       train_regret_loser_18[slice10],\r\n",
        "       train_regret_loser_19[slice10],\r\n",
        "       train_regret_loser_20[slice10]]\r\n",
        "\r\n",
        "winner10 = [train_regret_winner_1[slice10],\r\n",
        "       train_regret_winner_2[slice10],\r\n",
        "       train_regret_winner_3[slice10],\r\n",
        "       train_regret_winner_4[slice10],\r\n",
        "       train_regret_winner_5[slice10],\r\n",
        "       train_regret_winner_6[slice10],\r\n",
        "       train_regret_winner_7[slice10],\r\n",
        "       train_regret_winner_8[slice10],\r\n",
        "       train_regret_winner_9[slice10],\r\n",
        "       train_regret_winner_10[slice10],\r\n",
        "       train_regret_winner_11[slice10],\r\n",
        "       train_regret_winner_12[slice10],\r\n",
        "       train_regret_winner_13[slice10],\r\n",
        "       train_regret_winner_14[slice10],\r\n",
        "       train_regret_winner_15[slice10],\r\n",
        "       train_regret_winner_16[slice10],\r\n",
        "       train_regret_winner_17[slice10],\r\n",
        "       train_regret_winner_18[slice10],\r\n",
        "       train_regret_winner_19[slice10],\r\n",
        "       train_regret_winner_20[slice10]]\r\n",
        "\r\n",
        "loser10_results = pd.DataFrame(loser10).sort_values(by=[0], ascending=False)\r\n",
        "winner10_results = pd.DataFrame(winner10).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser10 = np.asarray(loser10_results[4:5][0])[0]\r\n",
        "median_loser10 = np.asarray(loser10_results[9:10][0])[0]\r\n",
        "upper_loser10 = np.asarray(loser10_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner10 = np.asarray(winner10_results[4:5][0])[0]\r\n",
        "median_winner10 = np.asarray(winner10_results[9:10][0])[0]\r\n",
        "upper_winner10 = np.asarray(winner10_results[14:15][0])[0]"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGDzLGoCGyl7"
      },
      "source": [
        "### Summarize arrays: 'Loser'\r\n",
        "\r\n",
        "lower_loser = [lower_loser1,\r\n",
        "            lower_loser2,\r\n",
        "            lower_loser3,\r\n",
        "            lower_loser4,\r\n",
        "            lower_loser5,\r\n",
        "            lower_loser6,\r\n",
        "            lower_loser7,\r\n",
        "            lower_loser8,\r\n",
        "            lower_loser9,\r\n",
        "            lower_loser10,\r\n",
        "            lower_loser11]\r\n",
        "\r\n",
        "median_loser = [median_loser1,\r\n",
        "            median_loser2,\r\n",
        "            median_loser3,\r\n",
        "            median_loser4,\r\n",
        "            median_loser5,\r\n",
        "            median_loser6,\r\n",
        "            median_loser7,\r\n",
        "            median_loser8,\r\n",
        "            median_loser9,\r\n",
        "            median_loser10,\r\n",
        "            median_loser11]\r\n",
        "\r\n",
        "upper_loser = [upper_loser1,\r\n",
        "            upper_loser2,\r\n",
        "            upper_loser3,\r\n",
        "            upper_loser4,\r\n",
        "            upper_loser5,\r\n",
        "            upper_loser6,\r\n",
        "            upper_loser7,\r\n",
        "            upper_loser8,\r\n",
        "            upper_loser9,\r\n",
        "            upper_loser10,\r\n",
        "            upper_loser11]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0FWrtVXGyov"
      },
      "source": [
        "### Summarize arrays: 'Winner'\r\n",
        "\r\n",
        "lower_winner = [lower_winner1,\r\n",
        "            lower_winner2,\r\n",
        "            lower_winner3,\r\n",
        "            lower_winner4,\r\n",
        "            lower_winner5,\r\n",
        "            lower_winner6,\r\n",
        "            lower_winner7,\r\n",
        "            lower_winner8,\r\n",
        "            lower_winner9,\r\n",
        "            lower_winner10,\r\n",
        "            lower_winner11]\r\n",
        "\r\n",
        "median_winner = [median_winner1,\r\n",
        "            median_winner2,\r\n",
        "            median_winner3,\r\n",
        "            median_winner4,\r\n",
        "            median_winner5,\r\n",
        "            median_winner6,\r\n",
        "            median_winner7,\r\n",
        "            median_winner8,\r\n",
        "            median_winner9,\r\n",
        "            median_winner10,\r\n",
        "            median_winner11]\r\n",
        "\r\n",
        "upper_winner = [upper_winner1,\r\n",
        "            upper_winner2,\r\n",
        "            upper_winner3,\r\n",
        "            upper_winner4,\r\n",
        "            upper_winner5,\r\n",
        "            upper_winner6,\r\n",
        "            upper_winner7,\r\n",
        "            upper_winner8,\r\n",
        "            upper_winner9,\r\n",
        "            upper_winner10,\r\n",
        "            upper_winner11]"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1CIOmuxGyq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "c5472304-3da2-4554-8095-201957904d59"
      },
      "source": [
        "### Visualize!\r\n",
        "\r\n",
        "title = obj_func\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(median_loser, color = 'Red')\r\n",
        "plt.plot(median_winner, color = 'Yellow')\r\n",
        "\r\n",
        "xstar = np.arange(0, max_iter+1, step=1)\r\n",
        "plt.fill_between(xstar, lower_winner, upper_winner, facecolor = 'Yellow', alpha=0.4, label='GP EI Regret IQR: L-BFGS-B')\r\n",
        "plt.fill_between(xstar, lower_loser, upper_loser, facecolor = 'Red', alpha=0.4, label='GP EI Regret IQR: Newton-CG with GP d$^{2}$EI')\r\n",
        "\r\n",
        "plt.title(title, weight = 'bold')\r\n",
        "plt.xlabel('(Post-initialization) iteration $\\it{k}$', weight = 'bold', family = 'Arial') # x-axis label\r\n",
        "plt.ylabel('log(Regret)', weight = 'bold', family = 'Arial') # y-axis label\r\n",
        "plt.legend(loc=1) # add plot legend\r\n",
        "\r\n",
        "plt.show() #visualize"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id2Uf2m8KF4T"
      },
      "source": [
        "## 'Loser' and 'Winner' are terms used to differentiate between the 1st surrogate vs. 2nd surrogate \r\n",
        "\r\n",
        "## In this example the 'Loser' surrogate i.e. Newton-CG + Exact Hessian minimizes training regret IQR versus the 'winner' i.e. L-BFGS-B"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyLOs-MGytY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a4af901-570e-4e1c-cedb-1328e994ad1f"
      },
      "source": [
        "lower_winner11, median_winner11, upper_winner11"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.955060950631902, 8.878776071707552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJk2ehuJobR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc08657-1d7f-475e-fc27-1caac647606e"
      },
      "source": [
        "y_low_win = np.exp(lower_winner11)\r\n",
        "y_median_win = np.exp(median_winner11)\r\n",
        "y_upper_win = np.exp(upper_winner11)\r\n",
        "\r\n",
        "y_low_win, y_median_win, y_upper_win"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7888.000000000001, 7746.999999999994, 7177.999999999996)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPGhgpdkfwZw",
        "outputId": "83dee3fc-1c86-4839-9a5e-791ab0f5de7e"
      },
      "source": [
        "f_syn_polarity(0.5683654)\r\n",
        "\r\n",
        "## x = 56.84 days corresponds to the median training regret of y = 7,747 daily cases"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Yk6XJAIoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c7e469-2e01-4e7d-cdb4-b51fa7c4df59"
      },
      "source": [
        "lower_loser11, median_loser11, upper_loser11"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.955060950631902, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOrmWNtROQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45355d56-3505-4e0e-f2d6-2f575e28ed8d"
      },
      "source": [
        "y_low_lose = np.exp(lower_loser11)\r\n",
        "y_median_lose = np.exp(median_loser11)\r\n",
        "y_upper_lose = np.exp(upper_loser11)\r\n",
        "\r\n",
        "y_low_lose, y_median_lose, y_upper_lose"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7888.000000000001, 7746.999999999994, 6992.000000000001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSmOe-ZFgWDx",
        "outputId": "6932021e-c54f-4e3c-f424-956f51768660"
      },
      "source": [
        "f_syn_polarity(0.5683654)\r\n",
        "\r\n",
        "## x = 56.84 days corresponds to the median training regret of y = 7,747 daily cases"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbXDCg4So7bO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1421ded9-38ce-449e-8ca7-354eb60eb16a"
      },
      "source": [
        "time_lose, time_win"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1389.1392784118652, 1219.2191252708435)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTz953WagdoM"
      },
      "source": [
        ""
      ],
      "execution_count": 98,
      "outputs": []
    }
  ]
}