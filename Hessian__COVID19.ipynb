{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hessian__COVID19.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rCIMJJrJ9Co"
      },
      "source": [
        "COVID-19 Lockdown Modelling: multi-objective Bayesian optimization using ESOP)\r\n",
        "\r\n",
        "GP EI: Newton-CG (exact GP EI gradients + Hessian) vs. L-BFGS-B (approx. GP EI gradients, without Hessian)\r\n",
        "\r\n",
        "https://github.com/purushottamkar/esop\r\n",
        "\r\n",
        "https://arxiv.org/abs/2005.11257\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUs0l8uQL534",
        "outputId": "785365f7-a333-4f78-fbce-011c33781fd3"
      },
      "source": [
        "!pip install pyGPGO"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyGPGO in /usr/local/lib/python3.6/dist-packages (0.4.0.dev1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.4.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (0.17.0)\n",
            "Requirement already satisfied: pyMC3 in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (3.7)\n",
            "Requirement already satisfied: theano in /usr/local/lib/python3.6/dist-packages (from pyGPGO) (1.0.5)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (0.5.1)\n",
            "Requirement already satisfied: h5py>=2.7.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (2.10.0)\n",
            "Requirement already satisfied: pandas>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (1.1.5)\n",
            "Requirement already satisfied: tqdm>=4.8.4 in /usr/local/lib/python3.6/dist-packages (from pyMC3->pyGPGO) (4.41.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from theano->pyGPGO) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.18.0->pyMC3->pyGPGO) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-VEXg5Jy_1"
      },
      "source": [
        "## Import modules\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import scipy\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pickle\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import time\r\n",
        "\r\n",
        "from pyGPGO.logger import EventLogger\r\n",
        "from pyGPGO.GPGO import GPGO\r\n",
        "from pyGPGO.surrogates.GaussianProcess import GaussianProcess\r\n",
        "from pyGPGO.acquisition import Acquisition\r\n",
        "from pyGPGO.covfunc import squaredExponential, matern52\r\n",
        "\r\n",
        "from collections import OrderedDict\r\n",
        "from joblib import Parallel, delayed\r\n",
        "from numpy.linalg import slogdet, inv, cholesky, solve\r\n",
        "from scipy.optimize import minimize\r\n",
        "from scipy.spatial.distance import cdist\r\n",
        "from scipy.stats import norm, binned_statistic as binStat\r\n",
        "from matplotlib.pyplot import rc\r\n",
        "rc('text', usetex=False)\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\r\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\r\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFYrttVTMVVE"
      },
      "source": [
        "### https://github.com/purushottamkar/esop/utils.py\r\n",
        "\r\n",
        "### https://arxiv.org/abs/2005.11257\r\n",
        "\r\n",
        "### VIPER Model\r\n",
        "\r\n",
        "# Convenient named constants for indices for various parameters pertaining to an individual in the VIPER model\r\n",
        "IDX_SUS = 0 # Susceptibility\r\n",
        "IDX_VLD = 1 # Viral load\r\n",
        "IDX_RLD = 2 # Recovery load\r\n",
        "IDX_RST = 3 # Resistance (never changed - intrinsic to the individual)\r\n",
        "IDX_X = 4   # X coordinate (only changed if the individual is travelling)\r\n",
        "IDX_Y = 5   # Y coordinate (only changed if the individual is travelling)\r\n",
        "IDX_STA = 6 # State\r\n",
        "IDX_QRN = 7 # Is this individual quarantined or not\r\n",
        "IDX_DPR = 8 # Disease progression rate\r\n",
        "IDX_TI = 9  # Timestamp of infection (only changed at time of infection)\r\n",
        "IDX_TQ = 10 # Timestamp of quarantine\r\n",
        "IDX_TR = 11 # Timestamp of recovery/expiry (only changed at time of recovery/expiry)\r\n",
        "\r\n",
        "nParams = 12\r\n",
        "\r\n",
        "sqrt2 = np.sqrt(2)\r\n",
        "\r\n",
        "# Convenient named constants for various states of an individual\r\n",
        "# Being quarantined is not a medical state and so it is tracked\r\n",
        "# separately (see IDX_QRN above) -- this allows VIPER to quarantine\r\n",
        "ST_S = 0\t# Susceptible\r\n",
        "ST_E = 1\t# Exposed\r\n",
        "ST_I = 2\t# Infectious\r\n",
        "ST_R = 3\t# Recovered\r\n",
        "ST_X = 4\t# Expired\r\n",
        "\r\n",
        "nStates = 5\r\n",
        "\r\n",
        "# Convenient named constants useful for reporting stats\r\n",
        "SIDX_S = 0\t# Number of susceptible but non-recovered individuals\r\n",
        "SIDX_E = 1\t# Number of exposed individuals\r\n",
        "SIDX_I = 2\t# Number of infectious individuals\r\n",
        "SIDX_Q = 3\t# Number of quarantined individuals\r\n",
        "SIDX_R = 4\t# Number of recovered individuals\r\n",
        "SIDX_X = 5\t# Number of expired individuals\r\n",
        "SIDX_V = 6\t# Average virulence of the viral strains in E and I populations\r\n",
        "SIDX_EI = 7\t# Number of infected individuals\r\n",
        "SIDX_D = 8\t# Number of individuals infected each day\r\n",
        "\r\n",
        "nStats = 9\r\n",
        "\r\n",
        "# This class provides an encapsulation for the VIPER model as well as methods\r\n",
        "# to perform epidemiological simulations under lock-down, quarantining etc\r\n",
        "class Population:\r\n",
        "\t# The base constructor -- almost never used directly\r\n",
        "\tdef __init__( self, N, BIR, BCR, INC, BVL, VMR, QTH, BQP, XTH, BXP, BTR, BTD, BDPR, alphaInit, popIdx, ind, SUS, RST, X, Y ):\r\n",
        "\t\tself.N = N\r\n",
        "\t\tself.BIR = BIR\r\n",
        "\t\tself.BCR = BCR\r\n",
        "\t\tself.INC = INC\r\n",
        "\t\tself.BVL = BVL\r\n",
        "\t\tself.VMR = VMR\r\n",
        "\t\tself.QTH = QTH\r\n",
        "\t\tself.BQP = BQP\r\n",
        "\t\tself.XTH = XTH\r\n",
        "\t\tself.BXP = BXP\r\n",
        "\t\tself.BTR = BTR\r\n",
        "\t\tself.BTD = BTD\r\n",
        "\t\tself.BDPR = BDPR\r\n",
        "\t\tself.alphaInit = alphaInit\r\n",
        "\t\t\r\n",
        "\t\tself.popIdx = popIdx\r\n",
        "\t\tself.ind = ind\r\n",
        "\t\tself.SUS = SUS\r\n",
        "\t\tself.RST = RST\r\n",
        "\t\tself.X = X\r\n",
        "\t\tself.Y = Y\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using scalar values alone\r\n",
        "\t# This provides a generic population with location, SUS, RST values\r\n",
        "\t# set uniformly randomly. To use India-specific initialization, use\r\n",
        "\t# the patch provided by the class Demographics (see below and setup.py)\r\n",
        "\t\r\n",
        "\t# N: the size of the population before the pandemic began\r\n",
        "\t# BIR: the (base) probability that a contact event will lead to a successful infection\r\n",
        "\t# BCR: the (base) contact radius\r\n",
        "\t# INC: the incubation period for the virus\r\n",
        "\t# BVL: the base viral load presented in individuals at the end of the exposed period\r\n",
        "\t# VMR: the rate at which the DPR mutates upon contact\r\n",
        "\t# QTH: the viral load over which an individual's chances of getting quarantined increase linearly\r\n",
        "\t# BQP: the (base) quarantining probability for a person with viral load at the QTH threshold\r\n",
        "\t# XTH: the viral load over which an individual's chances of getting expired increase linearly\r\n",
        "\t# BXP: the (base) expiry probability for a person with viral load at the XTH threshold\r\n",
        "\t# BTR: the (base) fraction of population that travels at any time instant\r\n",
        "\t# BTD: the (base) distance to which people travel\r\n",
        "\t# BDPR: the (base) disease progression rate for the initial strain of the virus\r\n",
        "\t# alphaInit: the initial fraction of population that is infected with the virus\r\n",
        "\t@classmethod\r\n",
        "\tdef valInit( cls, N, BIR = 0.5, BCR = 0.25, INC = 3, BVL = 0.05, VMR = 0.0, QTH = 0.3, BQP = 0.0, XTH = 0.7, BXP = 0.0, BTR = 0.01, BTD = 1.0, BDPR = 0.1, alphaInit = 0.01 ):\r\n",
        "\t\t# Give the individuals unique identifiers\r\n",
        "\t\tpopIdx = np.arange(N)\r\n",
        "\t\t\r\n",
        "\t\t# Initialize the individuals\r\n",
        "\t\tind = np.zeros( (N, nParams) )\r\n",
        "\r\n",
        "\t\t# Initially no one is infected or quarantined\r\n",
        "\t\tind[ :, IDX_VLD ] = 0\r\n",
        "\t\tind[ :, IDX_RLD ] = 0\r\n",
        "\t\tind[ :, IDX_STA ] = ST_S\r\n",
        "\t\tind[ :, IDX_DPR ] = 0\r\n",
        "\t\tind[ :, IDX_QRN ] = 0\r\n",
        "\t\t\r\n",
        "\t\t# People have susceptibilities uniformly in a range\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tSUS = np.random.uniform( 0.01, 0.99, (N,) )\r\n",
        "\t\tind[ :, IDX_SUS ] = SUS\r\n",
        "\t\t\r\n",
        "\t\t# People have resistances uniformly in a range\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tRST = 0.1 * np.random.uniform( 0.01, 0.99, (N,) )\r\n",
        "\t\tind[ :, IDX_RST ] = RST\r\n",
        "\r\n",
        "\t\t# Set their locations uniformly at random within the [0,1] x [0,1] square\r\n",
        "\t\t# The patch offered by the Demographics class allows this to be changed\r\n",
        "\t\tX = np.random.uniform( 0, 1, (N,) )\r\n",
        "\t\tind[ :, IDX_X ] = X\r\n",
        "\t\tY = np.random.uniform( 0, 1, (N,) )\r\n",
        "\t\tind[ :, IDX_Y ] = Y\r\n",
        "\t\t\r\n",
        "\t\t# Set the timers to invalid values since nothing has happened yet\r\n",
        "\t\tind[ :, IDX_TI ] = 0\r\n",
        "\t\tind[ :, IDX_TQ ] = 0\r\n",
        "\t\tind[ :, IDX_TR ] = 0\r\n",
        "\t\t\r\n",
        "\t\treturn cls( N, BIR, BCR, INC, BVL, VMR, QTH, BQP, XTH, BXP, BTR, BTD, BDPR, alphaInit, popIdx, ind, SUS, RST, X, Y )\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using data loaded from file\r\n",
        "\t@classmethod\r\n",
        "\tdef fileInit( cls, filename ):\r\n",
        "\t\t# Get data from the file\r\n",
        "\t\twith open( filename, 'rb' ) as file:\r\n",
        "\t\t\tdata = pickle.load( file )\r\n",
        "\t\t\r\n",
        "\t\t# Create an object out of this data and return it\r\n",
        "\t\treturn cls( *data )\r\n",
        "\t\t\r\n",
        "\t# Save a copy of this object to a file\r\n",
        "\tdef dump( self, filename ):\r\n",
        "\t\tdata = ( self.N, self.BIR, self.BCR, self.INC, self.BVL, self.VMR, self.QTH, self.BQP, self.XTH, self.BXP, self.BTR, self.BTD, self.BDPR, self.alphaInit, self.popIdx, self.ind, self.SUS, self.RST, self.X, self.Y )\r\n",
        "\t\twith open( filename, 'wb' ) as file:\r\n",
        "\t\t\tpickle.dump( data, file )\r\n",
        "\t\t\t\r\n",
        "\t# Turn the clock back to before the pandemic started\r\n",
        "\tdef reset( self ):\r\n",
        "\t\t# Reinitialize the individuals\r\n",
        "\t\tself.ind.fill(0)\r\n",
        "\t\t\r\n",
        "\t\t# Reset their susceptibilities to their original values (they do change for recovered and expired individuals)\r\n",
        "\t\tself.ind[ :, IDX_SUS ] = self.SUS\r\n",
        "\t\t\t\t\t\t\t \r\n",
        "\t\t# Initially no one is infected or quarantined\r\n",
        "\t\tself.ind[ :, IDX_VLD ] = 0\r\n",
        "\t\tself.ind[ :, IDX_RLD ] = 0\r\n",
        "\t\tself.ind[ :, IDX_STA ] = ST_S\r\n",
        "\t\tself.ind[ :, IDX_DPR ] = 0\r\n",
        "\t\tself.ind[ :, IDX_QRN ] = 0\r\n",
        "\t\t\t\t\t\t\t \r\n",
        "\t\t# Reset their resistances to their original value (although they should not have changed)\r\n",
        "\t\tself.ind[ :, IDX_RST ] = self.RST\r\n",
        "\t\t\t\t  \r\n",
        "\t\t# Reset their locations\r\n",
        "\t\tself.ind[ :, IDX_X ] = self.X\r\n",
        "\t\tself.ind[ :, IDX_Y ] = self.Y\r\n",
        "\t\t\t\t  \r\n",
        "\t\t# Reset the timers to a happier time before the pandemic began\r\n",
        "\t\tself.ind[ :, IDX_TI ] = 0\r\n",
        "\t\tself.ind[ :, IDX_TQ ] = 0\r\n",
        "\t\tself.ind[ :, IDX_TR ] = 0\r\n",
        "\t\t\r\n",
        "\t# T: the number of time steps for which to run the simulation\r\n",
        "\t# LKP: the lock-down policy\r\n",
        "\tdef simulate( self, T, LKP, minimal = False, checkSanity = False ):\r\n",
        "\t\tnumInfInit = int( self.alphaInit * self.N )\r\n",
        "\t\t\r\n",
        "\t\t# Randomly select the unfortunate souls who are going to get infected initially\r\n",
        "\t\tidxInit = np.random.permutation( self.N )[ : numInfInit ]\r\n",
        "\t\t\r\n",
        "\t\t# Infect them!\r\n",
        "\t\tself.ind[ idxInit, IDX_STA ] = ST_E\t\t\t# These individuals are incubating right now\r\n",
        "\t\tself.ind[ idxInit, IDX_DPR ] = self.BDPR\t# The virus has not mutated yet\r\n",
        "\t\tself.ind[ idxInit, IDX_TI ] = 1\t\t\t\t# They got infected at t = 1\r\n",
        "\t\t\r\n",
        "\t\t# Store the intial stats\r\n",
        "\t\tstats = np.zeros( (nStats, T+1) )\r\n",
        "\t\tstats[ :, 0 ] = np.array( [ self.N - numInfInit, numInfInit, 0, 0, 0, 0, self.BDPR, numInfInit, numInfInit ] )\r\n",
        "\t\t\r\n",
        "\t\tfor t in range(T):\r\n",
        "\t\t\tif checkSanity:\r\n",
        "\t\t\t\tself.doSanityChecks()\r\n",
        "\t\t\t# Track the progress of disease in infected + exposed individuals\r\n",
        "\t\t\tself.letDiseaseProgress( t+2 )\r\n",
        "\t\t\t# As much as permitted by the lock-down level at this time instant, allow individuals to travel\r\n",
        "\t\t\tself.letIndividualsTravel( LKP[t] )\r\n",
        "\t\t\t# Allow interactions and fresh infections and get a daily count\r\n",
        "\t\t\tdaily = self.letIndividualsInfect( LKP[t], t+2 )\r\n",
        "\t\t\t# As dictated by the quarantine policy, catch and quarantine individuals\r\n",
        "\t\t\tself.applyQuarantinePolicy( t+2 )\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Compute essential statistics\r\n",
        "\t\t\tidxEorI = (self.ind[ :, IDX_STA ].astype( int ) == ST_E) | (self.ind[ :, IDX_STA ].astype( int ) == ST_I)\r\n",
        "\t\t\tstats[ SIDX_EI, t+1 ] = np.count_nonzero( idxEorI )\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Compute optional statistics\r\n",
        "\t\t\tif not minimal:\r\n",
        "\t\t\t\tstats[ SIDX_S, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_S )\r\n",
        "\t\t\t\tstats[ SIDX_E, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_E )\r\n",
        "\t\t\t\tstats[ SIDX_I, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_I )\r\n",
        "\t\t\t\tstats[ SIDX_Q, t+1 ] = np.count_nonzero( self.ind[ :, IDX_QRN ].astype( int ) == 1 )\r\n",
        "\t\t\t\tstats[ SIDX_R, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_R )\r\n",
        "\t\t\t\tstats[ SIDX_X, t+1 ] = np.count_nonzero( self.ind[ :, IDX_STA ].astype( int ) == ST_X )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tstats[ SIDX_D, t+1 ] = daily\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\tif len(idxEorI) == 0:\r\n",
        "\t\t\t\t\tstats[ SIDX_V, t+1 ] = 0\r\n",
        "\t\t\t\telse:\r\n",
        "\t\t\t\t\tstats[ SIDX_V, t+1 ] = np.mean( self.ind[ idxEorI, IDX_DPR ] )\r\n",
        "\t\t\r\n",
        "\t\t# Simulation over!!\r\n",
        "\t\t\r\n",
        "\t\t# Compute disease progression statistics and return final results of the simulation\r\n",
        "\t\tif minimal:\r\n",
        "\t\t\treturn stats\r\n",
        "\t\telse:\r\n",
        "\t\t\tidxEverInfected = self.ind[ :, IDX_TI ].astype( int ) > 0\r\n",
        "\t\t\ttInfect = self.ind[ idxEverInfected, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxQuarantined = self.ind[ :, IDX_TQ ].astype( int ) > 0\r\n",
        "\t\t\ttQuarantine = self.ind[ idxQuarantined, IDX_TQ ] - self.ind[ idxQuarantined, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxRecovered = self.ind[ :, IDX_STA ].astype( int ) == ST_R\r\n",
        "\t\t\ttRecovery = self.ind[ idxRecovered, IDX_TR ] - self.ind[ idxRecovered, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tidxExpired = self.ind[ :, IDX_STA ].astype( int ) == ST_X\r\n",
        "\t\t\ttExpiry = self.ind[ idxExpired, IDX_TR ] - self.ind[ idxExpired, IDX_TI ]\r\n",
        "\t\t\t\r\n",
        "\t\t\treturn ( stats, tInfect, tQuarantine, tRecovery, tExpiry )\r\n",
        "\t\t\t\r\n",
        "\t\r\n",
        "\t# Simulate incubation period, update viral and recovery loads, and process expiries and recoveries\r\n",
        "\tdef letDiseaseProgress( self, t ):\r\n",
        "\t\t# Process recoveries of infectious individuals\r\n",
        "\t\t# TODO: recovery does not necessarily grant immunity: high levels of immunity may\r\n",
        "\t\t# only be available to those in whom the disease did progress sufficiently\r\n",
        "\t\tidxRecovered = ((self.ind[ :, IDX_STA ].astype( int ) == ST_I) & (self.ind[ :, IDX_VLD ] < self.BVL))\r\n",
        "\t\tif len(idxRecovered) > 0:\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_TR ] = t\t\t# These people recovered at time t\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_SUS ] = 0\t\t# They are now immune from the disease\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_VLD ] = 0\t\t# Their remaining viral load vanishes in an instant\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_RLD ] = 0\t\t# Their recovery load is made good instantly\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_STA ] = ST_R\t# They are now recovered\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_DPR ] = 0\t\t# They are free of the virus\r\n",
        "\t\t\tself.ind[ idxRecovered, IDX_QRN ] = 0\t\t# They are released from any quarantine in which they may have been\r\n",
        "\t\t\r\n",
        "\t\t# Process expiries of infectious individuals\r\n",
        "\t\t# If expiry threshold is too high, assume no one is going to get expired!\r\n",
        "\t\tif self.XTH < 1 - 1e-6:\r\n",
        "\t\t\tidxExpiryRisk = self.popIdx[ (self.ind[ :, IDX_STA ].astype( int ) == ST_I) & (self.ind[ :, IDX_VLD ] > self.XTH) ]\r\n",
        "\t\t\tif len(idxExpiryRisk) > 0:\r\n",
        "\t\t\t\texpiryProb = self.BXP + ( 1 - self.BXP ) * (self.ind[ idxExpiryRisk, IDX_VLD ] - self.XTH)/(1 - self.XTH)\r\n",
        "\t\t\t\ttosses = np.random.uniform( 0, 1, ( len(expiryProb), ) )\r\n",
        "\t\t\t\tidxExpired = idxExpiryRisk[ tosses < expiryProb ]\r\n",
        "\t\t\t\tif len(idxExpired) > 0:\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_TR ] = t\t\t# These people expired at time t\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_SUS ] = 0\t\t# Either way, they are now immune from the disease\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_VLD ] = 0\t\t# Their remaining viral load vanishes in an instant\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_RLD ] = 0\t\t# Their recovery load does not matter any more\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_STA ] = ST_X\t# They are removed from the population\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_DPR ] = 0\t\t# Either way, they are now free of the virus\r\n",
        "\t\t\t\t\tself.ind[ idxExpired, IDX_QRN ] = 0\t\t# They are released from any quarantine in which they may have been\r\n",
        "\t\t\r\n",
        "\t\t# Update viral and recovery loads\r\n",
        "\t\tidxInfected = self.popIdx[ self.ind[ :, IDX_STA ].astype( int ) == ST_I ]\r\n",
        "\t\tif len(idxInfected) > 0:\r\n",
        "\t\t\t# Some of the viral load is shed into recovery load, depending on the resistance of the person\r\n",
        "\t\t\tVLD_DeltaNeg = self.ind[ idxInfected, IDX_RST ] * self.ind[ idxInfected, IDX_VLD ]\r\n",
        "\t\t\t# The viral load also goes up, depending on the disease progression rate\r\n",
        "\t\t\tNormalLoad = 1 - self.ind[ idxInfected, IDX_VLD ] - self.ind[ idxInfected, IDX_RLD ]\r\n",
        "\t\t\tVLD_DeltaPos = NormalLoad * self.ind[ idxInfected, IDX_DPR ]\r\n",
        "\t\t\t\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_RLD ] += VLD_DeltaNeg\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_VLD ] += (VLD_DeltaPos - VLD_DeltaNeg)\r\n",
        "\t\t\r\n",
        "\t\t# Process incubation maturity cases\r\n",
        "\t\tidxExposed = self.popIdx[ self.ind[ :, IDX_STA ].astype( int ) == ST_E ]\r\n",
        "\t\tif len(idxExposed) > 0:\r\n",
        "\t\t\ttExposed = self.ind[ idxExposed, IDX_TI ].astype( int )\r\n",
        "\t\t\tidxMatured = idxExposed[ tExposed == t - self.INC ]\r\n",
        "\t\t\tif len(idxMatured) > 0:\r\n",
        "\t\t\t\tself.ind[ idxMatured, IDX_VLD ] = self.BVL\t# These people now have a base viral load\r\n",
        "\t\t\t\tself.ind[ idxMatured, IDX_STA ] = ST_I\t# They are now infectious\r\n",
        "\t\t\t\t\r\n",
        "\t# Let individuals travel according to the current lock-down level\r\n",
        "\tdef letIndividualsTravel( self, level ):\r\n",
        "\t\t# Only non-quarantined and non-expired individuals can travel\r\n",
        "\t\tidxTravelAllowed = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 0) & (self.ind[ :, IDX_STA ].astype( int ) != ST_X) ]\r\n",
        "\t\tif len(idxTravelAllowed) > 0:\r\n",
        "\t\t\tnTravelAllowed = len(idxTravelAllowed)\r\n",
        "\t\t\tnTravellers = int( nTravelAllowed * self.BTR )\r\n",
        "\t\t\tif nTravellers > 0:\r\n",
        "\t\t\t\t# Allow a random set of people who are allowed to travel, to do so\r\n",
        "\t\t\t\tidxTravellers = idxTravelAllowed[ np.random.permutation( nTravelAllowed )[ :nTravellers ] ]\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# The travel distance is limited by the lock-down level\r\n",
        "\t\t\t\ttDist = self.BTD * np.exp( -level )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# Dividing by sqrt2 since perturbations are made to two dimensions\r\n",
        "\t\t\t\ttravelX = tDist / sqrt2 * np.random.uniform( -1, 1, (nTravellers,) )\r\n",
        "\t\t\t\ttravelY = tDist / sqrt2 * np.random.uniform( -1, 1, (nTravellers,) )\r\n",
        "\t\t\t\t\r\n",
        "\t\t\t\t# Make sure individuals do not travel to another planet or something\r\n",
        "\t\t\t\tself.ind[ idxTravellers, IDX_X ] = ( self.ind[ idxTravellers, IDX_X ] + travelX ) % 1\r\n",
        "\t\t\t\tself.ind[ idxTravellers, IDX_Y ] = ( self.ind[ idxTravellers, IDX_Y ] + travelY ) % 1\r\n",
        "\t\t\r\n",
        "\t# Let individuals infect each other based on the current lock-down level\r\n",
        "\tdef letIndividualsInfect( self, level, t ):\r\n",
        "\t\t# All non-quarantined non-expired individuals can participate in interactions\r\n",
        "\t\t# Individuals going through the incubation period do participate but neither infect nor can be infected\r\n",
        "\t\tidxParticipants = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 0) & (self.ind[ :, IDX_STA ].astype( int ) != ST_X) ]\r\n",
        "\t\t# Find a mask for the (non-quarantined) infectious participants\r\n",
        "\t\tmaskInfectious = self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_I\r\n",
        "\t\t# Find a mask for non-immune susceptible/recovered individuals\r\n",
        "\t\tmaskSusceptible = (self.ind[ idxParticipants, IDX_SUS ] > 0) & ( (self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_S) | (self.ind[ idxParticipants, IDX_STA ].astype( int ) == ST_R) )\r\n",
        "\t\t\r\n",
        "\t\t# If there is either no one infecting or else no one to infect, nothing left to do\r\n",
        "\t\tif ( np.count_nonzero( maskInfectious ) == 0 ) | ( np.count_nonzero( maskSusceptible ) == 0 ):\r\n",
        "\t\t\treturn 0\r\n",
        "\t\t\r\n",
        "\t\t# Jiggle the coordinates pf the participants a bit to simulate random interactions\r\n",
        "\t\t# The jiggle dies down with lock-down level\r\n",
        "\t\tXParticipants = self.ind[ idxParticipants, IDX_X:IDX_Y + 1 ]\r\n",
        "\t\tjitter = self.BCR * np.exp( -level ) / sqrt2 * np.random.uniform( 0, 1, (2,) )\r\n",
        "\t\tXParticipants += jitter\r\n",
        "\t\t\r\n",
        "\t\t# Create interaction bins out of these jittered coordinates\r\n",
        "\t\t# The jitter added earlier allows individuals to fall into potentially different bins each time\r\n",
        "\t\t# TODO: this is slow at the moment, especially at high lock-down levels when number of bins\r\n",
        "\t\t# skyrockets since everyone is trapped inside their virtual houses. Speed this up by using a\r\n",
        "\t\t# reverse hash to iterate only over non-empty bins (there can be at most N such bins)\r\n",
        "\t\trContact = self.BCR * np.exp( -level ) / sqrt2\r\n",
        "\t\tXParticipants = np.floor( XParticipants / rContact )\r\n",
        "\t\tnBinsPerCoord = np.max( XParticipants ) + 1\r\n",
        "\t\tBParticipants = ( XParticipants[:, 0] * nBinsPerCoord + XParticipants[:, 1] ).astype( int )\r\n",
        "\t\t\r\n",
        "\t\t# Find the bins for infectious and susceptible individuals\r\n",
        "\t\tBInfectious = BParticipants[ maskInfectious ]\r\n",
        "\t\tBSusceptible = BParticipants[ maskSusceptible ]\r\n",
        "\t\t\r\n",
        "\t\t# Find the infection probabilities in each bin\r\n",
        "\t\tbins = np.arange( np.max(BParticipants) + 2 )\r\n",
        "\t\t# print( \"At time %d, we have jitter (%f, %f) and %d bins\" % ( t, jitter[0], jitter[1], len(bins) ) )\r\n",
        "\t\tbinParticipantCount = np.histogram( BParticipants, bins )[0]\r\n",
        "\t\tbinParticipantCount[ binParticipantCount < 1 ] = 1 # Avoid a divide-by-zero error\r\n",
        "\t\tbinInfectiousCount = np.histogram( BInfectious, bins )[0]\r\n",
        "\t\tbinInfectionProb = binInfectiousCount / binParticipantCount * self.BIR\r\n",
        "\t\t\r\n",
        "\t\t# Find the mean DPR within each bin -- this will be used to decide the DPR for newly infected people\r\n",
        "\t\tidxInfectious = idxParticipants[maskInfectious]\r\n",
        "\t\tbinDPR = binStat( BInfectious, self.ind[ idxInfectious, IDX_DPR ], statistic = \"mean\", bins = bins )[0]\r\n",
        "\t\tbinDPR[ np.isnan( binDPR ) ] = 0 # Fix values for bins where there were no infectious people\r\n",
        "\t\t\r\n",
        "\t\t# Find the infection probabilities for each susceptible individual\r\n",
        "\t\tidxSusceptible = idxParticipants[maskSusceptible]\r\n",
        "\t\tinfectionProb = binInfectionProb[BSusceptible] * self.ind[ idxSusceptible, IDX_SUS ]\r\n",
        "\t\t\r\n",
        "\t\t# Find new DPRs for the mutated viruses for the susceptible individuals\r\n",
        "\t\t# Currently this bit of code has been inactivated since we have set VMR = 0.0\r\n",
        "\t\tnewDPR = binDPR[BSusceptible] * ( 1 + self.VMR * ( 2 * np.random.randint( 0, 2, ( len(BSusceptible), ) ) - 1 ) )\r\n",
        "\t\tnewDPR[ newDPR < 0.001 ] = 0.001 # Make sure DPR never dips too low\r\n",
        "\t\tnewDPR[ newDPR > 0.999 ] = 0.999 # Make sure DPR never goes too high\r\n",
        "\t\t\r\n",
        "\t\t# Get some random bits to decide who gets infected among the susceptible\r\n",
        "\t\ttosses = np.random.uniform( 0, 1, ( len(infectionProb), ) )\r\n",
        "\t\tmaskInfected = tosses < infectionProb\r\n",
        "\t\tidxInfected = idxSusceptible[maskInfected]\r\n",
        "\t\tif len(idxInfected) > 0:\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_STA ] = ST_E\t\t\t\t\t\t# These individuals are incubating right now\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_DPR ] = newDPR[maskInfected]\t\t# These individuals get the mutated version\r\n",
        "\t\t\tself.ind[ idxInfected, IDX_TI ] = t\t\t\t\t\t\t\t# They got infected at t = t\r\n",
        "\t\t\t\r\n",
        "\t\treturn len(idxInfected)\r\n",
        "\t\t\r\n",
        "\t# Quarantine individuals based on quarantine policy\r\n",
        "\tdef applyQuarantinePolicy( self, t ):\r\n",
        "\t\t# If quarantine threshold is too high, assume no one is going to get quarantined!\r\n",
        "\t\tif self.QTH > 1 - 1e-6:\r\n",
        "\t\t\treturn\r\n",
        "\t\t\t\r\n",
        "\t\t# Only non-quarantined and non-expired individuals with viral loads above the quarantine threshold can be quarantined\r\n",
        "\t\tidxPotential = self.popIdx[ ( self.ind[ :, IDX_QRN ].astype( int ) == 0 ) & ( self.ind[ :, IDX_STA ].astype( int ) != ST_X ) & ( self.ind[ :, IDX_VLD ] > self.QTH ) ]\r\n",
        "\t\tif len(idxPotential) > 0:\r\n",
        "\t\t\tquarantineProb = self.BQP + ( 1 - self.BQP ) * ( self.ind[ idxPotential, IDX_VLD ] - self.QTH ) / ( 1 - self.QTH )\r\n",
        "\t\t\ttosses = np.random.uniform( 0, 1, ( len(quarantineProb), ) )\r\n",
        "\t\t\tidxQuarantined = idxPotential[ tosses < quarantineProb ]\r\n",
        "\t\t\tif len(idxQuarantined) > 0:\r\n",
        "\t\t\t\tself.ind[ idxQuarantined, IDX_QRN ] = 1\t\t# Put them in quarantine\r\n",
        "\t\t\t\tself.ind[ idxQuarantined, IDX_TQ ] = t\t\t# Note down the time of quarantining\r\n",
        "\t\t\t\t\r\n",
        "\t# Do sanity checks to make sure there are no anomalies\r\n",
        "\tdef doSanityChecks( self ):\r\n",
        "\t\t# Make sure there are no negative values anywhere\r\n",
        "\t\tminVal = np.min( self.ind )\r\n",
        "\t\tassert minVal >= 0, \"Negative values detected in the parameter values: %f\" % minVal\r\n",
        "\t\r\n",
        "\t\t# Make sure everyone is in one of the five states S, E, I, R, X\r\n",
        "\t\tstates = set( np.unique( self.ind[ :, IDX_STA ] ).astype( int ) )\r\n",
        "\t\tgold = set( np.arange( nStates ) )\r\n",
        "\t\tassert len( states - gold ) == 0, \"Invalid states detected %\" % \"\".join([str(i)+\", \" for i in states])\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one except those in I state have a non-zero viral and recovery load\r\n",
        "\t\tidxNonInfected = (self.ind[ :, IDX_STA ].astype( int ) != ST_I)\r\n",
        "\t\tassert max( self.ind[ idxNonInfected, IDX_VLD ] ) < 1e-6, \"Non-infectious individuals with non-zero viral load detected\"\r\n",
        "\t\tassert max( self.ind[ idxNonInfected, IDX_RLD ] ) < 1e-6, \"Non-infectious individuals with non-zero recovery load detected\"\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one other than those in state I are in quarantine\r\n",
        "\t\t# This may have to be modified if VIPER is extended to enable false positives in quarantining\r\n",
        "\t\tidxInvalidQuarantine = self.popIdx[ (self.ind[ :, IDX_QRN ].astype( int ) == 1) & (self.ind[ :, IDX_STA ].astype( int ) != ST_I) ]\r\n",
        "\t\tassert len(idxInvalidQuarantine) == 0, \"Non-infectious individuals quarantined\"\r\n",
        "\t\t\r\n",
        "\t\t# Make sure all individual locations are within bounds\r\n",
        "\t\tminX = np.min( self.ind[ :, IDX_X ] )\r\n",
        "\t\tassert minX >= 0, \"Negative values detected in X coordinates %f\" % minX\r\n",
        "\t\tminY = np.min( self.ind[ :, IDX_Y ] )\r\n",
        "\t\tassert minY >= 0, \"Negative values detected in Y coordinates %f\" % minY\r\n",
        "\t\tmaxX = np.max( self.ind[ :, IDX_X ] )\r\n",
        "\t\tassert maxX <= 1, \"Large values detected in X coordinates %f\" % maxX\r\n",
        "\t\tmaxY = np.max( self.ind[ :, IDX_Y ] )\r\n",
        "\t\tassert maxY <= 1, \"Large values detected in Y coordinates %f\" % maxY\r\n",
        "\t\t\r\n",
        "# This class provides patches to the SUS, RST and location parameters for an object of the\r\n",
        "# Population class. RST and SUS values are fitted to Indian statistics and locations are\r\n",
        "# clustered into cities for a certain fraction of the population.\r\n",
        "class Demographics:\r\n",
        "\t# The base constructor -- almost never used directly\r\n",
        "\tdef __init__( self, N, urbanRatio, numCities, cityRadius, loc, isUrban, cityCenters, cityIdx, demoData ):\r\n",
        "\t\tself.N = N\r\n",
        "\t\tself.urbanRatio = urbanRatio\r\n",
        "\t\tself.numCities = numCities\r\n",
        "\t\tself.cityRadius = cityRadius\r\n",
        "\t\tself.loc = loc\r\n",
        "\t\tself.isUrban = isUrban\r\n",
        "\t\tself.cityCenters = cityCenters\r\n",
        "\t\tself.cityIdx = cityIdx\r\n",
        "\t\tself.demoData = demoData\r\n",
        "\t\r\n",
        "\t# Constructor that initializes using scalar values for various parameters\r\n",
        "\t# This provides a patch to the generic population generated using the class\r\n",
        "\t# Population (see above and setup.py) with a certain fraction living in cities\r\n",
        "\t# and RST and SUS values distributed to fit India statistics\r\n",
        "\t\r\n",
        "\t# N: the size of the population before the pandemic began\r\n",
        "\t# urbanRatio: what fraction of this population lives in cities?\r\n",
        "\t# numCities: how many cities do we have\r\n",
        "\t# cityRadius: the soft geographical extent of each city. ~99.7 of the population\r\n",
        "\t# of any city should live within 3 x cityRadius distance of the city center\r\n",
        "\t@classmethod\r\n",
        "\tdef valInit( cls, N, urbanRatio = 0.34, numCities = 4, cityRadius = 0.1 ):\r\n",
        "\t\t( loc, isUrban, cityCenters, cityIdx ) = cls.getInitLocations( N, urbanRatio, numCities, cityRadius )\r\n",
        "\t\tdemoData = cls.getDemographics(N)\r\n",
        "\t\treturn cls( N, urbanRatio, numCities, cityRadius, loc, isUrban, cityCenters, cityIdx, demoData )\r\n",
        "\t\t\r\n",
        "\t# Constructor that initializes using data loaded from file\r\n",
        "\t@classmethod\r\n",
        "\tdef fileInit( cls, filename ):\r\n",
        "\t\t# Get data from the file\r\n",
        "\t\twith open( filename, 'rb' ) as file:\r\n",
        "\t\t\tdata = pickle.load( file )\r\n",
        "\t\t\r\n",
        "\t\t# Create an object out of this data and return it\r\n",
        "\t\treturn cls( *data )\r\n",
        "\t\t\r\n",
        "\t# Save a copy of this object to a file\r\n",
        "\tdef dump( self, filename ):\r\n",
        "\t\tdata = ( self.N, self.urbanRatio, self.numCities, self.cityRadius, self.loc, self.isUrban, self.cityCenters, self.cityIdx, self.demoData )\r\n",
        "\t\twith open( filename, 'wb' ) as file:\r\n",
        "\t\t\tpickle.dump( data, file )\r\n",
        "\t\t\t\r\n",
        "\t# Distribute people into cities and non-urban areas randomly as requested\r\n",
        "\t@classmethod\r\n",
        "\tdef getInitLocations( cls, N, urbanRatio, numCities, cityRadius ):\r\n",
        "\t\tloc = np.zeros( (N, 2) )\r\n",
        "\t\tisUrban = np.zeros( (N,) )\r\n",
        "\t\t\r\n",
        "\t\t# Find out who all is living in the cities\r\n",
        "\t\tnumUrban = int( N * urbanRatio )\r\n",
        "\t\tpermLoc = np.random.permutation( N )\r\n",
        "\t\tisUrban[ permLoc[ : numUrban ] ] = 1\r\n",
        "\t\t\r\n",
        "\t\t# Non-urban populations are distributed uniformly randomly\r\n",
        "\t\tloc[ permLoc[ numUrban : ], : ] = np.random.uniform( 0, 1, ( N - numUrban, 2 ) )\r\n",
        "\t\t\r\n",
        "\t\t# Urban populations are distributed in clusters around city centers\r\n",
        "\t\t# First, let us find the city centers\r\n",
        "\t\tcityCenters = np.random.uniform( 0, 1, ( numCities, 2 ) )\r\n",
        "\t\t# Next, assign each city dweller, a city uniformly randomly\r\n",
        "\t\tcityIdx = np.random.randint( 0, numCities, (numUrban,) )\r\n",
        "\t\t# Finally, set the location of each city dweller as a jitter around their respective city centers\r\n",
        "\t\tloc[ permLoc[ : numUrban ], : ] = cityCenters[ cityIdx, : ]\r\n",
        "\t\tloc[ permLoc[ : numUrban ], : ] += np.random.normal( 0, cityRadius / sqrt2, ( numUrban, 2 ) )\r\n",
        "\t\t\r\n",
        "\t\t# Make sure no one leaves the planet!\r\n",
        "\t\tloc[ loc < 0 ] = 0\r\n",
        "\t\tloc[ loc > 1 ] = 1\r\n",
        "\t\t\r\n",
        "\t\treturn ( loc, isUrban, cityCenters, cityIdx )\r\n",
        "\t\r\n",
        "\t# Get RST and SUS values for the population that are derived from India statistics. For references\r\n",
        "\t# mentioned below e.g. (Ramakrishnan et al. 2019), please refer to the ESOP paper\r\n",
        "\t# https://arxiv.org/abs/2005.11257\r\n",
        "\t\r\n",
        "\t# Age groups are 0-20, 20-30, 30-40, 40-45, 45-50, 50-55, 55-60, 60-65, 65-70, 70-75, 75-80, 80+\r\n",
        "\t# There are 12 age groups that are indexed 0 through 11\r\n",
        "\t# This funny splitting of groups is due to the way in which various papers report their statistics\r\n",
        "\t# Whereas (Group 2003, Table 2) uses age intervals such as 20-30 years, 30-40 years, on the other\r\n",
        "\t# hand, (Ramakrishnan et al. 2019, Table 1) uses 45-55 years, 55-65 years as intervals instead\r\n",
        "\t\r\n",
        "\t# Genders are Female, Male -- these are indexed as Female = 0, Male = 1\r\n",
        "\t# The above convention is chosen to simplfy the susceptibility calculations\r\n",
        "\t# In all tables below, the first column is for the female gender and the second column for males\r\n",
        "\t@classmethod\r\n",
        "\tdef getDemographics( cls, N ):\r\n",
        "\t\t# Taken from (Ministry Home Affairs India 2016, Detailed Tables)\r\n",
        "\t\tageSplitbyGender = np.array([\r\n",
        "\t\t\t[ 0.363, 0.380 ],\r\n",
        "\t\t\t[ 0.205, 0.197 ],\r\n",
        "\t\t\t[ 0.152, 0.151 ],\r\n",
        "\t\t\t[ 0.061, 0.061 ],\r\n",
        "\t\t\t[ 0.054, 0.053 ],\r\n",
        "\t\t\t[ 0.043, 0.044 ],\r\n",
        "\t\t\t[ 0.037, 0.035 ],\r\n",
        "\t\t\t[ 0.031, 0.030 ],\r\n",
        "\t\t\t[ 0.022, 0.021 ],\r\n",
        "\t\t\t[ 0.015, 0.014 ],\r\n",
        "\t\t\t[ 0.009, 0.008 ], \r\n",
        "\t\t\t[ 0.008, 0.006 ]\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\tcumSplitbyGender = np.cumsum( ageSplitbyGender, axis = 0 )\r\n",
        "\t\t\r\n",
        "\t\t# According to the 2011 census, India's gender ratio is 51.5% males to 48.5% females\r\n",
        "\t\tgenderSplit = 0.515\r\n",
        "\t\t\r\n",
        "\t\t# Taken from (Group 2003, Table 2)\r\n",
        "\t\tdiabetesSplit = np.array([\r\n",
        "\t\t\t[ 0.000, 0.000 ],\r\n",
        "\t\t\t[ 0.000, 0.000 ],\r\n",
        "\t\t\t[ 0.125, 0.114 ],\r\n",
        "\t\t\t[ 0.227, 0.218 ],\r\n",
        "\t\t\t[ 0.227, 0.218 ],\r\n",
        "\t\t\t[ 0.326, 0.330 ],\r\n",
        "\t\t\t[ 0.326, 0.330 ],\r\n",
        "\t\t\t[ 0.346, 0.410 ],\r\n",
        "\t\t\t[ 0.346, 0.410 ],\r\n",
        "\t\t\t[ 0.330, 0.326 ],\r\n",
        "\t\t\t[ 0.330, 0.326 ],\r\n",
        "\t\t\t[ 0.177, 0.242 ]\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\t# Taken from (Ramakrishnan et al. 2019, Table 1)\r\n",
        "\t\thypertensionSplit = np.array([\r\n",
        "\t\t\t[ 0.062, 0.161 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.140, 0.267 ],\r\n",
        "\t\t\t[ 0.346, 0.424 ],\r\n",
        "\t\t\t[ 0.346, 0.424 ],\r\n",
        "\t\t\t[ 0.454, 0.490 ],\r\n",
        "\t\t\t[ 0.454, 0.490 ],\r\n",
        "\t\t\t[ 0.514, 0.515 ],\r\n",
        "\t\t\t[ 0.514, 0.515 ],\r\n",
        "\t\t\t[ 0.513, 0.522 ],\r\n",
        "\t\t\t[ 0.513, 0.522 ],\r\n",
        "\t\t])\r\n",
        "\t\t\r\n",
        "\t\tdemoData = np.zeros( ( N, 5 ) )\r\n",
        "\t\t# Sample random numbers in bulk for speed\r\n",
        "\t\trandomCoins = np.random.uniform( 0, 1, ( N, 4 ) )\r\n",
        "\t\t\r\n",
        "\t\tIDX_AGE = 0\t\t# The age group of the person\r\n",
        "\t\tIDX_SEN = 1\t\t# The seniority of the person\r\n",
        "\t\tIDX_GEN = 2\t\t# The gender of the person\r\n",
        "\t\tIDX_DBT = 3\t\t# The diabetic status of the person\r\n",
        "\t\tIDX_HTN = 4\t\t# The hypertensive status of the person\r\n",
        "\t\t\r\n",
        "\t\t# TODO: The below for loop can surely be sped-up using vectorization/broadcasting techniques\r\n",
        "\t\tfor i in range( N ):\r\n",
        "\t\t\t# Since our primary data only gives us conditional statistics e.g. gender ratio, age split by gender\r\n",
        "\t\t\t# and not joint statistics, we should not sample individual attributes jointly but rather sequentially\r\n",
        "\t\t\t\r\n",
        "\t\t\tthisGender = 0\r\n",
        "\t\t\t# First sample the gender of the person\r\n",
        "\t\t\tif randomCoins[ i, 0 ] <= genderSplit:\r\n",
        "\t\t\t\tthisGender = 1\t\t\t\t\t\t\t# Its a boy!\r\n",
        "\t\t\tdemoData[ i, IDX_GEN ] = thisGender\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, sample the age-group of the person - use fresh randomness\r\n",
        "\t\t\tthisAgeGroup = np.digitize( randomCoins[ i, 1 ], cumSplitbyGender[ :, thisGender ], right = True )\r\n",
        "\t\t\tdemoData[ i, IDX_AGE ] = thisAgeGroup\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, decide the seniority of the person\r\n",
        "\t\t\tthisSeniority = 0\r\n",
        "\t\t\t# Persons above 55 years of age are classified as senior according to (Joshi 2020, Table 1)\r\n",
        "\t\t\tif thisAgeGroup > 5:\r\n",
        "\t\t\t\tthisSeniority = 1\r\n",
        "\t\t\tdemoData[ i, IDX_SEN ] = thisSeniority\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Next, decide the diabetic status of the person - use fresh randomness\r\n",
        "\t\t\tthisDiabetic = 0\r\n",
        "\t\t\tif randomCoins[ i, 2 ] <= diabetesSplit[ thisAgeGroup, thisGender ]:\r\n",
        "\t\t\t\tthisDiabetic = 1\r\n",
        "\t\t\tdemoData[ i, IDX_DBT ] = thisDiabetic\r\n",
        "\t\t\t\r\n",
        "\t\t\t# Finally, decide the hypertensive status of the person - use fresh randomness\r\n",
        "\t\t\tthisHypertensive = 0\r\n",
        "\t\t\tif randomCoins[ i, 3 ] <= hypertensionSplit[ thisAgeGroup, thisGender ]:\r\n",
        "\t\t\t\tthisHypertensive = 1\r\n",
        "\t\t\tdemoData[ i, IDX_HTN ] = thisHypertensive\r\n",
        "\t\t\t\r\n",
        "\t\treturn demoData\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB9oG9icO595"
      },
      "source": [
        "## Inputs:\r\n",
        "\r\n",
        "obj_func = 'Optimizing COVID-19 Lockdown'\r\n",
        "n_test = 100\r\n",
        "\r\n",
        "util_loser = 'dEI_GP'\r\n",
        "util_winner = 'EI_GP'\r\n",
        "n_init = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmTRQrOAPQ5R"
      },
      "source": [
        "## Cumulative Regret Calculator:\r\n",
        "\r\n",
        "def min_max_array(x):\r\n",
        "  new_list = []\r\n",
        "  for i, num in enumerate(x):\r\n",
        "    new_list.append(np.min(x[0:i+1]))\r\n",
        "  return new_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPWUiXbEPbxv"
      },
      "source": [
        "## Derivatives: squared-exponential kernel:\r\n",
        "\r\n",
        "def l2norm_(X, Xstar):\r\n",
        "    return cdist(X, Xstar)\r\n",
        "\r\n",
        "def kronDelta(X, Xstar):\r\n",
        "    return cdist(X, Xstar) < np.finfo(np.float32).eps\r\n",
        "\r\n",
        "class squaredExponentialDeriv(squaredExponential):\r\n",
        "\r\n",
        "  def K(self, X, Xstar):  \r\n",
        "    r = l2norm_(X, Xstar)/self.l\r\n",
        "    K = self.sigmaf * np.exp(-0.5 * r ** 2) + self.sigman * kronDelta(X, Xstar)\r\n",
        "    return K\r\n",
        "\r\n",
        "  def dK(self, X, Xstar):\r\n",
        "    r = l2norm_(X, Xstar)/self.l\r\n",
        "    dK = self.sigmaf/(self.l ** 2) * np.exp(-0.5 * r ** 2) * l2norm_(X, Xstar)\r\n",
        "    return dK\r\n",
        "\r\n",
        "  def d2K(self, X, Xstar):\r\n",
        "    r = l2norm_(X, Xstar)/self.l\r\n",
        "    d2K = self.sigmaf/(self.l ** 2) * np.exp(-0.5 * r ** 2) * (r ** 2 - 1)\r\n",
        "    return d2K\r\n",
        "\r\n",
        "cov_func = squaredExponential()\r\n",
        "d_cov_func = squaredExponentialDeriv()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YwnaFDUQPXv"
      },
      "source": [
        "### Acquisition function derivatives:\r\n",
        "\r\n",
        "class Acquisition_new(Acquisition):    \r\n",
        "    def __init__(self, mode, eps=1e-06, **params):\r\n",
        "        \r\n",
        "        self.params = params\r\n",
        "        self.eps = eps\r\n",
        "\r\n",
        "        mode_dict = {\r\n",
        "            'EI_GP': self.EI_GP,\r\n",
        "            'dEI_GP': self.dEI_GP\r\n",
        "        }\r\n",
        "\r\n",
        "        self.f = mode_dict[mode]\r\n",
        "    \r\n",
        "    def EI_GP(self, tau, mean, std):\r\n",
        "        \r\n",
        "        z = -1 * (mean - tau - self.eps) / (std + self.eps)\r\n",
        "        return z * (std + self.eps) * norm.cdf(z) + (std + self.eps) * norm.pdf(z)[0]\r\n",
        "    \r\n",
        "    def dEI_GP(self, tau, mean, std, ds, dm, dvdv, d2s, d2m):\r\n",
        "    \r\n",
        "        z = -1 * (mean - tau - self.eps) / (std + self.eps)\r\n",
        "        \r\n",
        "        dsdx = ds / (std + self.eps)\r\n",
        "        d2sdx = -dsdx**2 / ((std + self.eps)) - (dvdv + d2s) / (std + self.eps)\r\n",
        "        dmdx = (dm - z * dsdx) / (std + self.eps)\r\n",
        "        d2mdx = (d2m -(z * d2sdx + 2 * dmdx * dsdx)) / (std + self.eps)\r\n",
        "        \r\n",
        "        f = (std + self.eps) * (z * norm.cdf(z) + norm.pdf(z)[0])\r\n",
        "        df = (z * norm.cdf(z) + norm.pdf(z)[0]) * dsdx + (std + self.eps) * norm.cdf(z) * dmdx\r\n",
        "        d2f = (z * norm.cdf(z) + norm.pdf(z)[0]) * d2sdx + dsdx * dmdx * norm.cdf(z) \\\r\n",
        "            + d2mdx * (std + self.eps) * norm.cdf(z) + dsdx * norm.cdf(z) * dmdx \\\r\n",
        "            + norm.pdf(z)[0] * (std + self.eps) * dmdx\r\n",
        "            \r\n",
        "        return f, df, d2f\r\n",
        "    \r\n",
        "    def _eval(self, tau, mean, std):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, **self.params)\r\n",
        "    \r\n",
        "    def d_eval(self, tau, mean, std, ds, dm, dvdv, d2s, d2m):\r\n",
        "    \r\n",
        "        return self.f(tau, mean, std, ds, dm, dvdv, d2s, d2m, **self.params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWiJocDIUTBa"
      },
      "source": [
        "### Surrogate derivatives: \r\n",
        "\r\n",
        "class dGaussianProcess(GaussianProcess):\r\n",
        "    sigmaf = 1\r\n",
        "    l = 1e-4\r\n",
        "    sigman = 1e-6\r\n",
        "    \r\n",
        "    def AcqGrad(self, Xstar, return_std=False):\r\n",
        "        Xstar = np.atleast_2d(Xstar)\r\n",
        "        Kstar = squaredExponentialDeriv.K(self, self.X, Xstar).T\r\n",
        "        dKstar = squaredExponentialDeriv.dK(self, self.X, Xstar).T\r\n",
        "        d2Kstar = squaredExponentialDeriv.d2K(self, self.X, Xstar).T\r\n",
        "        v = solve(self.L, Kstar.T)\r\n",
        "        dv = solve(self.L, dKstar.T)\r\n",
        "        d2v = solve(self.L, d2Kstar.T)\r\n",
        "        \r\n",
        "        ds = -np.dot(dv.T, v)\r\n",
        "        d2s = np.dot(d2v.T, v)\r\n",
        "        dvdv = np.dot(dv.T, dv)\r\n",
        "        \r\n",
        "        dm = np.dot(dKstar, self.alpha)\r\n",
        "        d2m = np.dot(d2Kstar, self.alpha)\r\n",
        "        return ds, dm, dvdv, d2s, d2m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV2Zg7B9U_YT"
      },
      "source": [
        "class d2GPGO(GPGO):  \r\n",
        "    n_start = 100\r\n",
        "    p = np.full((n_start,1),1)\r\n",
        "    \r\n",
        "    def func(self, xnew):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        f  = np.empty((self.n_start,))\r\n",
        "        df = np.empty((self.n_start,))\r\n",
        "        f  = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[0]\r\n",
        "        df = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[1]\r\n",
        "        df_array = np.full((len(xnew),),df)\r\n",
        "        return f, df_array\r\n",
        "    \r\n",
        "    def hessp_nonzero(self, xnew, p):\r\n",
        "        new_mean, new_var = self.GP.predict(xnew, return_std=True)\r\n",
        "        new_std = np.sqrt(new_var + 1e-6)\r\n",
        "        ds, dm, dvdv, d2s, d2m = self.GP.AcqGrad(xnew, return_std=True)\r\n",
        "        df2 = np.empty((self.n_start,))\r\n",
        "        df2 = -self.A.d_eval(self.tau, new_mean, new_std, ds=ds, dm=dm, dvdv=dvdv, d2s=d2s, d2m=d2m)[2]\r\n",
        "        H2 = np.empty((self.n_start,))\r\n",
        "        df2 = np.asarray(df2)\r\n",
        "        p = np.asarray(p)\r\n",
        "        H2 = np.multiply(df2,p)\r\n",
        "        return H2\r\n",
        "    \r\n",
        "    def d_optimizeAcq(self, method='Newton-CG', n_start=n_start):\r\n",
        "        start_points_dict = [self._sampleParam() for i in range(n_start)]\r\n",
        "        start_points_arr = np.array([list(s.values())\r\n",
        "                                     for s in start_points_dict])\r\n",
        "        x_best = np.empty((n_start, len(self.parameter_key)))\r\n",
        "        f_best = np.empty((n_start,))\r\n",
        "        opt = Parallel(n_jobs=self.n_jobs)(delayed(minimize)(self.func,\r\n",
        "                                                                 x0=start_point,\r\n",
        "                                                                 method=method,\r\n",
        "                                                                 jac = True,\r\n",
        "                                                                 hessp = self.hessp_nonzero,\r\n",
        "                                                                 bounds=self.parameter_range) for start_point in\r\n",
        "                                               start_points_arr)\r\n",
        "        \r\n",
        "        x_best = np.array([res.x for res in opt])\r\n",
        "        f_best = np.array([np.atleast_1d(res.fun)[0] for res in opt])\r\n",
        "\r\n",
        "        self.best = x_best[np.argmin(f_best)]     \r\n",
        "    \r\n",
        "    def run(self, max_iter=10, init_evals=3, resume=False):\r\n",
        "        \r\n",
        "        if not resume:\r\n",
        "            self.init_evals = init_evals\r\n",
        "            self._firstRun(self.init_evals)\r\n",
        "            self.logger._printInit(self)\r\n",
        "        for iteration in range(max_iter):\r\n",
        "            self.d_optimizeAcq()\r\n",
        "            #self.updateGP()\r\n",
        "            self.updateGP_min()\r\n",
        "            self.logger._printCurrent(self)\r\n",
        "\r\n",
        "    def updateGP_min(self):\r\n",
        "\r\n",
        "        kw = {param: self.best[i]\r\n",
        "              for i, param in enumerate(self.parameter_key)}\r\n",
        "        f_new = self.f(**kw)\r\n",
        "        self.GP.update(np.atleast_2d(self.best), np.atleast_1d(f_new))\r\n",
        "        self.tau = np.min(self.GP.y)\r\n",
        "        self.history.append(self.tau)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dH1y-f17VGEu"
      },
      "source": [
        "class GPGO_min(GPGO):\r\n",
        "\r\n",
        "  def updateGP(self):\r\n",
        "\r\n",
        "        kw = {param: self.best[i]\r\n",
        "              for i, param in enumerate(self.parameter_key)}\r\n",
        "        f_new = self.f(**kw)\r\n",
        "        self.GP.update(np.atleast_2d(self.best), np.atleast_1d(f_new))\r\n",
        "        self.tau = np.min(self.GP.y)\r\n",
        "        self.history.append(self.tau)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8-7_K9cVCis",
        "outputId": "8782765b-1f59-47b3-db10-32a4a0836df2"
      },
      "source": [
        "start_lose = time.time()\r\n",
        "start_lose"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1607690894.7997904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Llhv7cLGpw7H",
        "outputId": "aa67b481-912f-48dc-c0a0-359d9b19b8a7"
      },
      "source": [
        "## url = 'https://github.com/purushottamkar/esop/blob/master/pop_generic'\r\n",
        "\r\n",
        "from google.colab import files #pop_generic file is saved to the same Google Colab folder as this workbook\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "## Defines new data object as pop_generic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ad41a040-39f3-4058-af3f-81d1c48c8cdc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ad41a040-39f3-4058-af3f-81d1c48c8cdc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving pop_generic to pop_generic (1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt7XzVypVHmy"
      },
      "source": [
        "### Objective Function\r\n",
        "\r\n",
        "if obj_func == 'Optimizing COVID-19 Lockdown':\r\n",
        "\r\n",
        "  # Constraints:\r\n",
        "  param_lb_uniform = 0\r\n",
        "  param_ub_uniform = 1\r\n",
        "\r\n",
        "  # 1-D inputs' parameter bounds:\r\n",
        "  param = {'x': ('cont', (param_lb_uniform, param_ub_uniform))}\r\n",
        "\r\n",
        "  pop = Population.fileInit(\"pop_generic\")\r\n",
        "  pop.INC = 10\r\n",
        "  N = pop.N\r\n",
        "  T = 500\r\n",
        "  P0 = 30\r\n",
        "  L0 = 5\r\n",
        "\r\n",
        "  SIDX_S = 0  # Number of individuals: susceptible & non-recovered\r\n",
        "  SIDX_E = 1  # Number of individuals: exposed\r\n",
        "  SIDX_I = 2  # Number of individuals: infectious\r\n",
        "  SIDX_Q = 3  # Number of individuals: quarantined\r\n",
        "  SIDX_R = 4  # Number of individuals: recovered\r\n",
        "  SIDX_X = 5  # Number of individuals: expired\r\n",
        "  SIDX_V = 6  # Average virulence of viral strains\r\n",
        "  SIDX_EI = 7 # Number of individuals: infected\r\n",
        "  SIDX_D = 8  # Number of individuals: daily infections\r\n",
        "\r\n",
        "  I0c = 50\r\n",
        "  I0w = 50\r\n",
        "  evalCount = 0\r\n",
        "  globalDict = {}\r\n",
        "  freshMask = []\r\n",
        "  # Upper and lower bounds on legal values of lock-down intialization points:\r\n",
        "  ul = 100\r\n",
        "  ll = 0\r\n",
        "\r\n",
        "  def getI0( x ): \r\n",
        "    global I0c, I0w, ul, ll\r\n",
        "    SVal = int( np.floor( I0c + (x - 0.5) / 0.5 * I0w ) )\r\n",
        "    # Make sure that the recovered value is a legal one\r\n",
        "    correctedSVal = min( max( SVal, ll ), ul )\r\n",
        "    return correctedSVal\r\n",
        "\r\n",
        "  # Get a lockdown schedule corresponding to a certain I0 value\r\n",
        "  def getLKP( I0 ):\r\n",
        "    LKP = np.zeros((T,))\r\n",
        "    LKP[I0:I0+P0] = L0\r\n",
        "    return LKP\r\n",
        "\r\n",
        "  # Find out the objective value corresponding to the stats sent as input\r\n",
        "  # For this experiment, the objective value is simply f_epi since f_eco is\r\n",
        "  # already decided since the duration of the lock-down is fixed at P0 = 30\r\n",
        "  def obj( stats ):\r\n",
        "    global SIDX_EI\r\n",
        "    fEpi = np.max( stats[ SIDX_EI, : ] )\r\n",
        "    return fEpi\r\n",
        "\r\n",
        "  # Ask the VIPER simulator what does it think will happen if lock-down is\r\n",
        "  # initiated as specified in the normalized parameter x\r\n",
        "  def f_syn_polarity( x ):\r\n",
        "    global I0c, I0w, evalCount, globalDict, freshMask\r\n",
        "    # Before starting a simulation, turn back time to reset everything\r\n",
        "    pop.reset()\r\n",
        "    # Replicable simulations\r\n",
        "    np.random.seed(0)\r\n",
        "    I0 = getI0(x)\r\n",
        "    # Avoid re-sampling the same points\r\n",
        "    #if I0 in globalDict:\r\n",
        "    #  freshMask.append(False)\r\n",
        "    #  return globalDict[I0]\r\n",
        "    LKP = getLKP( I0 )\r\n",
        "    stats = pop.simulate( T = T, LKP = LKP, minimal = True )\r\n",
        "    globalDict[I0] = obj( stats )\r\n",
        "    freshMask.append( True )\r\n",
        "    evalCount += 1\r\n",
        "    return obj( stats )\r\n",
        "\r\n",
        "  # Once ESOP is done, find out which parameter, i.e. which value of I0 won!\r\n",
        "  def getWinner():\r\n",
        "    global globalDict\r\n",
        "    keys = np.array( list( globalDict.keys() ) )\r\n",
        "    vals = np.array( list( globalDict.values() ) )\r\n",
        "    winnerIdx = np.argmin( vals )\r\n",
        "    winner = keys[ winnerIdx ]\r\n",
        "    return winner\r\n",
        "\r\n",
        "  max_iter = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULjUdz_VVMhi"
      },
      "source": [
        "### Set-seeds:\r\n",
        "\r\n",
        "run_num_1 = 1\r\n",
        "run_num_2 = 2\r\n",
        "run_num_3 = 3333\r\n",
        "run_num_4 = 4\r\n",
        "run_num_5 = 555\r\n",
        "run_num_6 = 6\r\n",
        "run_num_7 = 7\r\n",
        "run_num_8 = 88\r\n",
        "run_num_9 = 99999\r\n",
        "run_num_10 = 1000\r\n",
        "run_num_11 = 11\r\n",
        "run_num_12 = 1222\r\n",
        "run_num_13 = 13\r\n",
        "run_num_14 = 14\r\n",
        "run_num_15 = 155\r\n",
        "run_num_16 = 1667\r\n",
        "run_num_17 = 1777\r\n",
        "run_num_18 = 188\r\n",
        "run_num_19 = 19\r\n",
        "run_num_20 = 20\r\n",
        "\r\n",
        "y_global_orig = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D17KR38gYRE6",
        "outputId": "2237443d-a0fe-4227-b027-06302cdbe034"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 1\r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_loser_1 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_1 = d2GPGO(surrogate_loser_1, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.417022]. \t  11254.0 \t 12696.0\n",
            "init   \t [0.68467162]. \t  8453.0 \t 12696.0\n",
            "init   \t [0.24385644]. \t  12696.0 \t 12696.0\n",
            "init   \t [0.52583438]. \t  9416.0 \t 12696.0\n",
            "1      \t [0.67289702]. \t  \u001b[92m8173.0\u001b[0m \t 8173.0\n",
            "2      \t [0.00847621]. \t  \u001b[92m13577.0\u001b[0m \t 8173.0\n",
            "3      \t [0.73759115]. \t  \u001b[92m9869.0\u001b[0m \t 8173.0\n",
            "4      \t [0.11344079]. \t  \u001b[92m13409.0\u001b[0m \t 8173.0\n",
            "5      \t [0.34658064]. \t  \u001b[92m12158.0\u001b[0m \t 8173.0\n",
            "6      \t [0.25357886]. \t  \u001b[92m12681.0\u001b[0m \t 8173.0\n",
            "7      \t [0.262744]. \t  \u001b[92m12765.0\u001b[0m \t 8173.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VrYi8mQSwUaj",
        "outputId": "8ccf2d39-2327-46e1-a1de-11e29cfea3a2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 2\r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_loser_2 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_2 = d2GPGO(surrogate_loser_2, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.4359949]. \t  11013.0 \t 13577.0\n",
            "init   \t [0.27990374]. \t  12840.0 \t 13577.0\n",
            "init   \t [0.74772621]. \t  10110.0 \t 13577.0\n",
            "init   \t [0.007856]. \t  13577.0 \t 13577.0\n",
            "1      \t [0.62355804]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "2      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "3      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "4      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "5      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "6      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "7      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "8      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n",
            "9      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 6672.0\n",
            "10     \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NsIJB6Bws4q",
        "outputId": "8b2ddc65-3caa-490b-d97a-08e5e1f967ec"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 3\r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_loser_3 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_3 = d2GPGO(surrogate_loser_3, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.75157561]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "init   \t [0.51198591]. \t  9464.0 \t 14019.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 14019.0\n",
            "1      \t [0.5561781]. \t  \u001b[92m8554.0\u001b[0m \t 8554.0\n",
            "2      \t [0.44732037]. \t  \u001b[92m10874.0\u001b[0m \t 8554.0\n",
            "3      \t [0.19297376]. \t  \u001b[92m13101.0\u001b[0m \t 8554.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 8554.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 8554.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 8554.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 8554.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 8554.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8554.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8554.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AW-ZhjzxC7S",
        "outputId": "5ec69fd5-6c38-40b4-c4a7-7679b177cd1a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 4\r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_loser_4 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_4 = d2GPGO(surrogate_loser_4, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.96702984]. \t  13962.0 \t 14019.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 14019.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "1      \t [0.00949436]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.58873335]. \t  \u001b[92m7940.0\u001b[0m \t 7940.0\n",
            "4      \t [0.90925644]. \t  \u001b[92m13431.0\u001b[0m \t 7940.0\n",
            "5      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7940.0\n",
            "6      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7940.0\n",
            "7      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7940.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_362CbCxTja",
        "outputId": "d9d44a7f-4024-4139-e074-0a24f12a8ef4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 5\r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_loser_5 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_5 = d2GPGO(surrogate_loser_5, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.71783409]. \t  9343.0 \t 13169.0\n",
            "init   \t [0.21573829]. \t  13169.0 \t 13169.0\n",
            "init   \t [0.88513393]. \t  13154.0 \t 13169.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13169.0\n",
            "1      \t [0.50046669]. \t  \u001b[92m9472.0\u001b[0m \t 9343.0\n",
            "2      \t [0.60739275]. \t  \u001b[92m7178.0\u001b[0m \t 7178.0\n",
            "3      \t [0.56613346]. \t  \u001b[92m7747.0\u001b[0m \t 7178.0\n",
            "4      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7178.0\n",
            "5      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7178.0\n",
            "6      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7178.0\n",
            "7      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7178.0\n",
            "8      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7178.0\n",
            "9      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7178.0\n",
            "10     \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7178.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq1gQLFgxbhj",
        "outputId": "242b18ed-2bf7-4450-8849-e59010d6dcb3"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 6\r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_loser_6 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_6 = d2GPGO(surrogate_loser_6, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89286015]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50038269]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.00757141]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blHM3jnYxpVL",
        "outputId": "3c2a5c41-61a3-45ef-d401-2f1a4fd8c0aa"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 7\r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_loser_7 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_7 = d2GPGO(surrogate_loser_7, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.07630829]. \t  13442.0 \t 13503.0\n",
            "init   \t [0.3076631]. \t  12533.0 \t 13503.0\n",
            "init   \t [0.06469076]. \t  13503.0 \t 13503.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13503.0\n",
            "1      \t [0.98036145]. \t  \u001b[92m14019.0\u001b[0m \t 9464.0\n",
            "2      \t [0.68720353]. \t  \u001b[92m8453.0\u001b[0m \t 8453.0\n",
            "3      \t [0.67392032]. \t  \u001b[92m8173.0\u001b[0m \t 8173.0\n",
            "4      \t [0.87162387]. \t  \u001b[92m13019.0\u001b[0m \t 8173.0\n",
            "5      \t [0.00538944]. \t  \u001b[92m13577.0\u001b[0m \t 8173.0\n",
            "6      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8173.0\n",
            "7      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8173.0\n",
            "8      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 8173.0\n",
            "9      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 8173.0\n",
            "10     \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 8173.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV5G9m-5x2Br",
        "outputId": "b0753fe4-5013-49a6-c855-7716b876cb03"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 8\r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_loser_8 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_8 = d2GPGO(surrogate_loser_8, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.64755105]. \t  7277.0 \t 13962.0\n",
            "init   \t [0.93600076]. \t  13728.0 \t 13962.0\n",
            "init   \t [0.96051377]. \t  13962.0 \t 13962.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 13962.0\n",
            "1      \t [0.01382912]. \t  \u001b[92m13603.0\u001b[0m \t 7277.0\n",
            "2      \t [0.37401417]. \t  \u001b[92m11677.0\u001b[0m \t 7277.0\n",
            "3      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7277.0\n",
            "4      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7277.0\n",
            "5      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7277.0\n",
            "6      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7277.0\n",
            "7      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7277.0\n",
            "8      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7277.0\n",
            "9      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "10     \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18hoXfzQzcF6",
        "outputId": "2464800f-ce56-4231-d0d3-4d77c82aa83a"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 9\r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_loser_9 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_9 = d2GPGO(surrogate_loser_9, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.20706637]. \t  13263.0 \t 13685.0\n",
            "init   \t [0.72910832]. \t  9585.0 \t 13685.0\n",
            "init   \t [0.80093216]. \t  11701.0 \t 13685.0\n",
            "init   \t [0.04439363]. \t  13685.0 \t 13685.0\n",
            "1      \t [0.59904747]. \t  \u001b[92m7210.0\u001b[0m \t 7210.0\n",
            "2      \t [0.47931887]. \t  \u001b[92m10418.0\u001b[0m \t 7210.0\n",
            "3      \t [0.90715029]. \t  \u001b[92m13431.0\u001b[0m \t 7210.0\n",
            "4      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7210.0\n",
            "5      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7210.0\n",
            "6      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7210.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wrqaX_EzcXC",
        "outputId": "a08f84ab-cf80-4d12-b7e1-fedae9ba471b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 10\r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_loser_10 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_10 = d2GPGO(surrogate_loser_10, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65358959]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [0.9795807]. \t  \u001b[92m13990.0\u001b[0m \t 7572.0\n",
            "2      \t [0.71272955]. \t  \u001b[92m9343.0\u001b[0m \t 7572.0\n",
            "3      \t [0.21573829]. \t  \u001b[92m13169.0\u001b[0m \t 7572.0\n",
            "4      \t [0.88513393]. \t  \u001b[92m13154.0\u001b[0m \t 7572.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7572.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7572.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7572.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7572.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7572.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soFmsoi9zcdB",
        "outputId": "a25a2311-f01d-4917-be54-62b992f5d1a6"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 11\r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_loser_11 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_11 = d2GPGO(surrogate_loser_11, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.18026969]. \t  13281.0 \t 13281.0\n",
            "init   \t [0.61298159]. \t  7424.0 \t 13281.0\n",
            "init   \t [0.29368678]. \t  12546.0 \t 13281.0\n",
            "init   \t [0.29132308]. \t  12546.0 \t 13281.0\n",
            "1      \t [0.99379924]. \t  \u001b[92m14063.0\u001b[0m \t 7424.0\n",
            "2      \t [0.70345528]. \t  \u001b[92m9060.0\u001b[0m \t 7424.0\n",
            "3      \t [0.0740075]. \t  \u001b[92m13442.0\u001b[0m \t 7424.0\n",
            "4      \t [0.3076631]. \t  \u001b[92m12533.0\u001b[0m \t 7424.0\n",
            "5      \t [0.06469076]. \t  \u001b[92m13503.0\u001b[0m \t 7424.0\n",
            "6      \t [0.51622115]. \t  \u001b[92m9464.0\u001b[0m \t 7424.0\n",
            "7      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7424.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7424.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7424.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7424.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CONGlWtUzciA",
        "outputId": "91bbe049-55f3-4abf-d375-0feccb21a46b"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 12\r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_loser_12 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_12 = d2GPGO(surrogate_loser_12, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.06748528]. \t  13503.0 \t 13505.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "1      \t [0.99080111]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.70345528]. \t  \u001b[92m9060.0\u001b[0m \t 9060.0\n",
            "3      \t [0.65817875]. \t  \u001b[92m7572.0\u001b[0m \t 7572.0\n",
            "4      \t [0.42232996]. \t  \u001b[92m11151.0\u001b[0m \t 7572.0\n",
            "5      \t [0.05316146]. \t  \u001b[92m13656.0\u001b[0m \t 7572.0\n",
            "6      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7572.0\n",
            "7      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7572.0\n",
            "8      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "9      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 7572.0\n",
            "10     \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vR9WC6s8zcm9",
        "outputId": "e17d6faf-ef40-4ed8-8ee2-6cac406c5d01"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 13\r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_loser_13 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_13 = d2GPGO(surrogate_loser_13, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.77770241]. \t  10939.0 \t 13619.0\n",
            "init   \t [0.92603084]. \t  13619.0 \t 13619.0\n",
            "init   \t [0.88451529]. \t  13154.0 \t 13619.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13619.0\n",
            "1      \t [0.00250195]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.62660258]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "4      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "5      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "6      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDfu9f9PzcsN",
        "outputId": "424cfc62-7dc5-490f-82e4-3ec4510111ea"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 14\r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_loser_14 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_14 = d2GPGO(surrogate_loser_14, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51394334]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rxpin3Fzcxp",
        "outputId": "1cab02c3-ea1a-478c-dec0-0da78b81c37c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 15\r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_loser_15 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_15 = d2GPGO(surrogate_loser_15, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65232633]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [0.9795807]. \t  \u001b[92m13990.0\u001b[0m \t 7572.0\n",
            "2      \t [0.71272955]. \t  \u001b[92m9343.0\u001b[0m \t 7572.0\n",
            "3      \t [0.21573829]. \t  \u001b[92m13169.0\u001b[0m \t 7572.0\n",
            "4      \t [0.88513393]. \t  \u001b[92m13154.0\u001b[0m \t 7572.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7572.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7572.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7572.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7572.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7572.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXp3WoVTzc22",
        "outputId": "80bc57ee-e2af-44f1-afe2-f91ceef5804c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 16\r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_loser_16 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_16 = d2GPGO(surrogate_loser_16, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89472424]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.50038269]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.00757141]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGQANct4zc8j",
        "outputId": "2c58bbea-1135-48db-e9a4-9c3f9f33b803"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 17\r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_loser_17 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_17 = d2GPGO(surrogate_loser_17, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.03062042]. \t  13305.0 \t 13505.0\n",
            "init   \t [0.08122315]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tJrFjh5zdDN",
        "outputId": "b0ac7885-126c-4b1e-c80a-4bf024757250"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 18\r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_loser_18 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_18 = d2GPGO(surrogate_loser_18, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51197762]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [0.98091914]. \t  \u001b[92m14019.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72476009]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2cJMYL8zdMB",
        "outputId": "6d5d16e1-ef48-42b6-c13b-3a35b4d58434"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 19\r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_loser_19 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_19 = d2GPGO(surrogate_loser_19, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.0975336]. \t  13585.0 \t 13585.0\n",
            "init   \t [0.40764505]. \t  11522.0 \t 13585.0\n",
            "init   \t [0.26268]. \t  12765.0 \t 13585.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13585.0\n",
            "1      \t [0.9950895]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "2      \t [0.74013984]. \t  \u001b[92m10110.0\u001b[0m \t 6992.0\n",
            "3      \t [0.007856]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "4      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "5      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "6      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "7      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "8      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0JmbY_6zdTQ",
        "outputId": "d0cc1030-af51-453c-a7a0-5ce32881f79c"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Loser' Acquisition Function run number = 20\r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_loser_20 = dGaussianProcess(d_cov_func)\r\n",
        "\r\n",
        "loser_20 = d2GPGO(surrogate_loser_20, Acquisition_new(util_loser), f_syn_polarity, param, n_jobs = -1) # define BayesOpt\r\n",
        "loser_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.5881308]. \t  7940.0 \t 13914.0\n",
            "init   \t [0.90925644]. \t  13431.0 \t 13914.0\n",
            "init   \t [0.89555325]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "1      \t [0.00214044]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "2      \t [0.36474576]. \t  \u001b[92m12051.0\u001b[0m \t 7940.0\n",
            "3      \t [0.1964637]. \t  \u001b[92m13101.0\u001b[0m \t 7940.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7940.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7940.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7940.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7940.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7940.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7940.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se976GulzdZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e552a5e7-881c-4181-f1d3-eac67feded0a"
      },
      "source": [
        "end_lose = time.time()\r\n",
        "end_lose\r\n",
        "\r\n",
        "time_lose = end_lose - start_lose\r\n",
        "time_lose\r\n",
        "\r\n",
        "start_win = time.time()\r\n",
        "start_win"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1607692211.4997432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VEx2XiTi13jM",
        "outputId": "02089ae4-b0ef-401d-c54e-69c3e142347d"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 1 \r\n",
        "\r\n",
        "np.random.seed(run_num_1)\r\n",
        "surrogate_winner_1 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_1 = GPGO_min(surrogate_winner_1, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_1.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.417022]. \t  11254.0 \t 12696.0\n",
            "init   \t [0.68467162]. \t  8453.0 \t 12696.0\n",
            "init   \t [0.24385644]. \t  12696.0 \t 12696.0\n",
            "init   \t [0.52583438]. \t  9416.0 \t 12696.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 8453.0\n",
            "2      \t [0.73022565]. \t  \u001b[92m9869.0\u001b[0m \t 8453.0\n",
            "3      \t [0.11344079]. \t  \u001b[92m13409.0\u001b[0m \t 8453.0\n",
            "4      \t [0.34658064]. \t  \u001b[92m12158.0\u001b[0m \t 8453.0\n",
            "5      \t [0.25357886]. \t  \u001b[92m12681.0\u001b[0m \t 8453.0\n",
            "6      \t [0.262744]. \t  \u001b[92m12765.0\u001b[0m \t 8453.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zugirIgK14Oy",
        "outputId": "9b0656ea-a0d6-41e8-df29-3242e4d757f1"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 2 \r\n",
        "\r\n",
        "np.random.seed(run_num_2)\r\n",
        "surrogate_winner_2 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_2 = GPGO_min(surrogate_winner_2, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_2.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.4359949]. \t  11013.0 \t 13577.0\n",
            "init   \t [0.27990374]. \t  12840.0 \t 13577.0\n",
            "init   \t [0.74772621]. \t  10110.0 \t 13577.0\n",
            "init   \t [0.007856]. \t  13577.0 \t 13577.0\n",
            "1      \t [0.64511479]. \t  \u001b[92m7277.0\u001b[0m \t 7277.0\n",
            "2      \t [0.93600076]. \t  \u001b[92m13728.0\u001b[0m \t 7277.0\n",
            "3      \t [0.96051377]. \t  \u001b[92m13962.0\u001b[0m \t 7277.0\n",
            "4      \t [0.88857941]. \t  \u001b[92m13154.0\u001b[0m \t 7277.0\n",
            "5      \t [0.75514332]. \t  \u001b[92m10387.0\u001b[0m \t 7277.0\n",
            "6      \t [0.98028867]. \t  \u001b[92m14019.0\u001b[0m \t 7277.0\n",
            "7      \t [0.51198591]. \t  \u001b[92m9464.0\u001b[0m \t 7277.0\n",
            "8      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7277.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7277.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7277.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mzHrT7j14Yi",
        "outputId": "51161081-d8d5-46dc-c014-782d5fa61135"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 3 \r\n",
        "\r\n",
        "np.random.seed(run_num_3)\r\n",
        "surrogate_winner_3 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_3 = GPGO_min(surrogate_winner_3, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_3.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.75157561]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "init   \t [0.51198591]. \t  9464.0 \t 14019.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 14019.0\n",
            "1      \t [0.55679392]. \t  \u001b[92m8554.0\u001b[0m \t 8554.0\n",
            "2      \t [0.44732037]. \t  \u001b[92m10874.0\u001b[0m \t 8554.0\n",
            "3      \t [0.19297376]. \t  \u001b[92m13101.0\u001b[0m \t 8554.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 8554.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 8554.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 8554.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 8554.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 8554.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 8554.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 8554.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWCaOA0q14cC",
        "outputId": "8864bc10-ae69-49f0-f5d4-a7982456aa40"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 4 \r\n",
        "\r\n",
        "np.random.seed(run_num_4)\r\n",
        "surrogate_winner_4 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_4 = GPGO_min(surrogate_winner_4, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_4.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.96702984]. \t  13962.0 \t 14019.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 14019.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 14019.0\n",
            "init   \t [0.98028867]. \t  14019.0 \t 14019.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.35712696]. \t  \u001b[92m12143.0\u001b[0m \t 10387.0\n",
            "3      \t [0.60419659]. \t  \u001b[92m7178.0\u001b[0m \t 7178.0\n",
            "4      \t [0.56613346]. \t  \u001b[92m7747.0\u001b[0m \t 7178.0\n",
            "5      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7178.0\n",
            "6      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7178.0\n",
            "7      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7178.0\n",
            "8      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7178.0\n",
            "9      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7178.0\n",
            "10     \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7178.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk_ztlly14lC",
        "outputId": "bcf6c117-4063-448e-ff74-29546ad50513"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 5 \r\n",
        "\r\n",
        "np.random.seed(run_num_5)\r\n",
        "surrogate_winner_5 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_5 = GPGO_min(surrogate_winner_5, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_5.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.71783409]. \t  9343.0 \t 13169.0\n",
            "init   \t [0.21573829]. \t  13169.0 \t 13169.0\n",
            "init   \t [0.88513393]. \t  13154.0 \t 13169.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13169.0\n",
            "1      \t [0.4999115]. \t  \u001b[92m9953.0\u001b[0m \t 9343.0\n",
            "2      \t [0.6286447]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "3      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "4      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "5      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "6      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "7      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "8      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "9      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n",
            "10     \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKgBRmWy14-C",
        "outputId": "0c3487de-64f1-4636-b926-091335c50d71"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 6 \r\n",
        "\r\n",
        "np.random.seed(run_num_6)\r\n",
        "surrogate_winner_6 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_6 = GPGO_min(surrogate_winner_6, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_6.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89286015]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.5011062]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdqhsfhQ15C_",
        "outputId": "4e11dccb-2e80-494f-b8c8-f3cd30e673db"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 7 \r\n",
        "\r\n",
        "np.random.seed(run_num_7)\r\n",
        "surrogate_winner_7 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_7 = GPGO_min(surrogate_winner_7, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_7.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.07630829]. \t  13442.0 \t 13503.0\n",
            "init   \t [0.3076631]. \t  12533.0 \t 13503.0\n",
            "init   \t [0.06469076]. \t  13503.0 \t 13503.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13503.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.69643828]. \t  \u001b[92m8731.0\u001b[0m \t 8731.0\n",
            "3      \t [0.66735346]. \t  \u001b[92m7888.0\u001b[0m \t 7888.0\n",
            "4      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7888.0\n",
            "5      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7888.0\n",
            "6      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7888.0\n",
            "7      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7888.0\n",
            "8      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "9      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "10     \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mS2c3bY15HS",
        "outputId": "bcb4e845-c7c3-475d-ef19-652ae5ff60e7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 8 \r\n",
        "\r\n",
        "np.random.seed(run_num_8)\r\n",
        "surrogate_winner_8 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_8 = GPGO_min(surrogate_winner_8, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_8.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.64755105]. \t  7277.0 \t 13962.0\n",
            "init   \t [0.93600076]. \t  13728.0 \t 13962.0\n",
            "init   \t [0.96051377]. \t  13962.0 \t 13962.0\n",
            "init   \t [0.88857941]. \t  13154.0 \t 13962.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 7277.0\n",
            "2      \t [0.35392395]. \t  \u001b[92m12143.0\u001b[0m \t 7277.0\n",
            "3      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7277.0\n",
            "4      \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7277.0\n",
            "5      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7277.0\n",
            "6      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7277.0\n",
            "7      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7277.0\n",
            "8      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7277.0\n",
            "9      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7277.0\n",
            "10     \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7277.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWr4DqE615LK",
        "outputId": "6a5a1d2d-5fe3-402b-966c-dcb19236fc95"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 9 \r\n",
        "\r\n",
        "np.random.seed(run_num_9)\r\n",
        "surrogate_winner_9 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_9 = GPGO_min(surrogate_winner_9, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_9.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.20706637]. \t  13263.0 \t 13685.0\n",
            "init   \t [0.72910832]. \t  9585.0 \t 13685.0\n",
            "init   \t [0.80093216]. \t  11701.0 \t 13685.0\n",
            "init   \t [0.04439363]. \t  13685.0 \t 13685.0\n",
            "1      \t [0.59602268]. \t  \u001b[92m7210.0\u001b[0m \t 7210.0\n",
            "2      \t [0.47931887]. \t  \u001b[92m10418.0\u001b[0m \t 7210.0\n",
            "3      \t [0.90715029]. \t  \u001b[92m13431.0\u001b[0m \t 7210.0\n",
            "4      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7210.0\n",
            "5      \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7210.0\n",
            "6      \t [0.26221209]. \t  \u001b[92m12765.0\u001b[0m \t 7210.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6992.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6992.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6992.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgON7wCa15Px",
        "outputId": "f6481866-c56f-401f-a046-96fdfcb3acaf"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 10 \r\n",
        "\r\n",
        "np.random.seed(run_num_10)\r\n",
        "surrogate_winner_10 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_10 = GPGO_min(surrogate_winner_10, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_10.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65358959]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "2      \t [0.72737423]. \t  \u001b[92m9585.0\u001b[0m \t 7572.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7572.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7572.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7572.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7572.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7572.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7572.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7572.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ss_C7dO615UP",
        "outputId": "302509fa-2768-4eb1-adba-1e0f977c2474"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 11 \r\n",
        "\r\n",
        "np.random.seed(run_num_11)\r\n",
        "surrogate_winner_11 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_11 = GPGO_min(surrogate_winner_11, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_11.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.18026969]. \t  13281.0 \t 13281.0\n",
            "init   \t [0.61298159]. \t  7424.0 \t 13281.0\n",
            "init   \t [0.29368678]. \t  12546.0 \t 13281.0\n",
            "init   \t [0.29132308]. \t  12546.0 \t 13281.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7424.0\n",
            "2      \t [0.70556689]. \t  \u001b[92m9060.0\u001b[0m \t 7424.0\n",
            "3      \t [0.0740075]. \t  \u001b[92m13442.0\u001b[0m \t 7424.0\n",
            "4      \t [0.3076631]. \t  \u001b[92m12533.0\u001b[0m \t 7424.0\n",
            "5      \t [0.06469076]. \t  \u001b[92m13503.0\u001b[0m \t 7424.0\n",
            "6      \t [0.51622115]. \t  \u001b[92m9464.0\u001b[0m \t 7424.0\n",
            "7      \t [0.0813946]. \t  \u001b[92m13505.0\u001b[0m \t 7424.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 7424.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 7424.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 7424.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVqYzvY315Y9",
        "outputId": "c4e113b9-1e1e-4509-ad0a-4e955b440d9f"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 12 \r\n",
        "\r\n",
        "np.random.seed(run_num_12)\r\n",
        "surrogate_winner_12 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_12 = GPGO_min(surrogate_winner_12, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_12.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.06748528]. \t  13503.0 \t 13505.0\n",
            "init   \t [0.51622115]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 9464.0\n",
            "2      \t [0.70526526]. \t  \u001b[92m9060.0\u001b[0m \t 9060.0\n",
            "3      \t [0.65613238]. \t  \u001b[92m7572.0\u001b[0m \t 7572.0\n",
            "4      \t [0.42232996]. \t  \u001b[92m11151.0\u001b[0m \t 7572.0\n",
            "5      \t [0.05316146]. \t  \u001b[92m13656.0\u001b[0m \t 7572.0\n",
            "6      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7572.0\n",
            "7      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7572.0\n",
            "8      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "9      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 7572.0\n",
            "10     \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAwtYRMv15d2",
        "outputId": "52ab7f14-b033-4dc3-9797-1662ab9bb2a0"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 13 \r\n",
        "\r\n",
        "np.random.seed(run_num_13)\r\n",
        "surrogate_winner_13 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_13 = GPGO_min(surrogate_winner_13, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_13.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.77770241]. \t  10939.0 \t 13619.0\n",
            "init   \t [0.92603084]. \t  13619.0 \t 13619.0\n",
            "init   \t [0.88451529]. \t  13154.0 \t 13619.0\n",
            "init   \t [0.75514332]. \t  10387.0 \t 13619.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 10387.0\n",
            "2      \t [0.36128066]. \t  \u001b[92m12051.0\u001b[0m \t 10387.0\n",
            "3      \t [0.62379799]. \t  \u001b[92m6672.0\u001b[0m \t 6672.0\n",
            "4      \t [0.09102036]. \t  \u001b[92m13585.0\u001b[0m \t 6672.0\n",
            "5      \t [0.40764505]. \t  \u001b[92m11522.0\u001b[0m \t 6672.0\n",
            "6      \t [0.26268]. \t  \u001b[92m12765.0\u001b[0m \t 6672.0\n",
            "7      \t [0.63250607]. \t  \u001b[92m6992.0\u001b[0m \t 6672.0\n",
            "8      \t [0.79839917]. \t  \u001b[92m11433.0\u001b[0m \t 6672.0\n",
            "9      \t [0.22388772]. \t  \u001b[92m13155.0\u001b[0m \t 6672.0\n",
            "10     \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 6672.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz33Woa215is",
        "outputId": "d92c6352-4ede-491d-8702-d22b580545c4"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 14 \r\n",
        "\r\n",
        "np.random.seed(run_num_14)\r\n",
        "surrogate_winner_14 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_14 = GPGO_min(surrogate_winner_14, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_14.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51394334]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72684521]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwyuIc115oH",
        "outputId": "db469043-d699-4c6d-ef9e-8363410faca7"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 15 \r\n",
        "\r\n",
        "np.random.seed(run_num_15)\r\n",
        "surrogate_winner_15 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_15 = GPGO_min(surrogate_winner_15, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_15.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.65232633]. \t  7572.0 \t 13656.0\n",
            "init   \t [0.42232996]. \t  11151.0 \t 13656.0\n",
            "init   \t [0.05316146]. \t  13656.0 \t 13656.0\n",
            "init   \t [0.00983665]. \t  13577.0 \t 13656.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7572.0\n",
            "2      \t [0.72750067]. \t  \u001b[92m9585.0\u001b[0m \t 7572.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7572.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7572.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7572.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7572.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7572.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7572.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7572.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7572.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRLyr5cS15t3",
        "outputId": "88de7e12-107a-4598-a545-728866b879c9"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 16 \r\n",
        "\r\n",
        "np.random.seed(run_num_16)\r\n",
        "surrogate_winner_16 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_16 = GPGO_min(surrogate_winner_16, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_16.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.89472424]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "init   \t [0.26221209]. \t  12765.0 \t 13914.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13914.0\n",
            "1      \t [0.5022778]. \t  \u001b[92m9472.0\u001b[0m \t 6992.0\n",
            "2      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "3      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "4      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "5      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "6      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "7      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "8      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "9      \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n",
            "10     \t [0.19598388]. \t  \u001b[92m13101.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFnuBlG515zz",
        "outputId": "60237bf7-5b13-491d-fd59-2f9f76d176ea"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 17 \r\n",
        "\r\n",
        "np.random.seed(run_num_17)\r\n",
        "surrogate_winner_17 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_17 = GPGO_min(surrogate_winner_17, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_17.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.03062042]. \t  13305.0 \t 13505.0\n",
            "init   \t [0.08122315]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72740116]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWK-H-6Y157M",
        "outputId": "0c298d63-536b-4d5b-d314-564da1a54ab2"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 18 \r\n",
        "\r\n",
        "np.random.seed(run_num_18)\r\n",
        "surrogate_winner_18 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_18 = GPGO_min(surrogate_winner_18, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_18.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.51197762]. \t  9464.0 \t 13505.0\n",
            "init   \t [0.0813946]. \t  13505.0 \t 13505.0\n",
            "init   \t [0.35308533]. \t  12143.0 \t 13505.0\n",
            "init   \t [0.5683654]. \t  7747.0 \t 13505.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 7747.0\n",
            "2      \t [0.72640932]. \t  \u001b[92m9585.0\u001b[0m \t 7747.0\n",
            "3      \t [0.80093216]. \t  \u001b[92m11701.0\u001b[0m \t 7747.0\n",
            "4      \t [0.04439363]. \t  \u001b[92m13685.0\u001b[0m \t 7747.0\n",
            "5      \t [0.3787406]. \t  \u001b[92m11677.0\u001b[0m \t 7747.0\n",
            "6      \t [0.22028271]. \t  \u001b[92m13155.0\u001b[0m \t 7747.0\n",
            "7      \t [0.6669629]. \t  \u001b[92m7888.0\u001b[0m \t 7747.0\n",
            "8      \t [0.9080847]. \t  \u001b[92m13431.0\u001b[0m \t 7747.0\n",
            "9      \t [0.89555325]. \t  \u001b[92m13282.0\u001b[0m \t 7747.0\n",
            "10     \t [0.95624005]. \t  \u001b[92m13914.0\u001b[0m \t 7747.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y924TuRx16Dm",
        "outputId": "b6486fc2-169a-48ee-f3ae-a3cc59d9a231"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 19 \r\n",
        "\r\n",
        "np.random.seed(run_num_19)\r\n",
        "surrogate_winner_19 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_19 = GPGO_min(surrogate_winner_19, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_19.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.0975336]. \t  13585.0 \t 13585.0\n",
            "init   \t [0.40764505]. \t  11522.0 \t 13585.0\n",
            "init   \t [0.26268]. \t  12765.0 \t 13585.0\n",
            "init   \t [0.63250607]. \t  6992.0 \t 13585.0\n",
            "1      \t [1.]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "2      \t [0.74411454]. \t  \u001b[92m10110.0\u001b[0m \t 6992.0\n",
            "3      \t [0.007856]. \t  \u001b[92m13577.0\u001b[0m \t 6992.0\n",
            "4      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 6992.0\n",
            "5      \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 6992.0\n",
            "6      \t [0.12625454]. \t  \u001b[92m13634.0\u001b[0m \t 6992.0\n",
            "7      \t [0.33439499]. \t  \u001b[92m12236.0\u001b[0m \t 6992.0\n",
            "8      \t [0.0828034]. \t  \u001b[92m13505.0\u001b[0m \t 6992.0\n",
            "9      \t [0.35308533]. \t  \u001b[92m12143.0\u001b[0m \t 6992.0\n",
            "10     \t [0.5683654]. \t  \u001b[92m7747.0\u001b[0m \t 6992.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONx9ETQg16KN",
        "outputId": "1d52f083-faad-490b-d225-f3da14194523"
      },
      "source": [
        "### Bayesian optimization runs (x20): 'Winner' Acquisition Function run number = 20 \r\n",
        "\r\n",
        "np.random.seed(run_num_20)\r\n",
        "surrogate_winner_20 = GaussianProcess(cov_func)\r\n",
        "\r\n",
        "winner_20 = GPGO_min(surrogate_winner_20, Acquisition_new(util_winner), f_syn_polarity, param, n_jobs = -1) # Define BayesOpt\r\n",
        "winner_20.run(max_iter = max_iter, init_evals = n_init) # run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluation \t Proposed point \t  Current eval. \t Best eval.\n",
            "init   \t [0.5881308]. \t  7940.0 \t 13914.0\n",
            "init   \t [0.90925644]. \t  13431.0 \t 13914.0\n",
            "init   \t [0.89555325]. \t  13282.0 \t 13914.0\n",
            "init   \t [0.95624005]. \t  13914.0 \t 13914.0\n",
            "1      \t [0.]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "2      \t [0.36456151]. \t  \u001b[92m12051.0\u001b[0m \t 7940.0\n",
            "3      \t [0.1964637]. \t  \u001b[92m13101.0\u001b[0m \t 7940.0\n",
            "4      \t [0.85203793]. \t  \u001b[92m12723.0\u001b[0m \t 7940.0\n",
            "5      \t [0.23097606]. \t  \u001b[92m13123.0\u001b[0m \t 7940.0\n",
            "6      \t [0.01896146]. \t  \u001b[92m13603.0\u001b[0m \t 7940.0\n",
            "7      \t [0.05398736]. \t  \u001b[92m13656.0\u001b[0m \t 7940.0\n",
            "8      \t [0.00983665]. \t  \u001b[92m13577.0\u001b[0m \t 7940.0\n",
            "9      \t [0.78146712]. \t  \u001b[92m11188.0\u001b[0m \t 7940.0\n",
            "10     \t [0.99072932]. \t  \u001b[92m14063.0\u001b[0m \t 7940.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qfV1wj83xw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b09464c-b9d7-481f-eb2e-0907b245ba39"
      },
      "source": [
        "end_win = time.time()\r\n",
        "end_win\r\n",
        "\r\n",
        "time_win = end_win - start_win\r\n",
        "time_win"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1125.9287152290344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj_BXyha3yPO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c026fb6c-34a1-406f-c43c-062dd542bb21"
      },
      "source": [
        "### Training regret minimization: run number = 1\r\n",
        "\r\n",
        "loser_output_1 = np.append(np.max(loser_1.GP.y[0:n_init]),loser_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_1 = np.append(np.max(winner_1.GP.y[0:n_init]),winner_1.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_1 = np.log(-y_global_orig + loser_output_1)\r\n",
        "regret_winner_1 = np.log(-y_global_orig + winner_output_1)\r\n",
        "\r\n",
        "train_regret_loser_1 = min_max_array(regret_loser_1)\r\n",
        "train_regret_winner_1 = min_max_array(regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1 = min(train_regret_loser_1)\r\n",
        "min_train_regret_winner_1 = min(train_regret_winner_1)\r\n",
        "\r\n",
        "min_train_regret_loser_1, min_train_regret_winner_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Jzxu4qEgxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d671a9af-1e55-4a26-e47f-9d8306320b99"
      },
      "source": [
        "### Training regret minimization: run number = 2\r\n",
        "\r\n",
        "loser_output_2 = np.append(np.max(loser_2.GP.y[0:n_init]),loser_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_2 = np.append(np.max(winner_2.GP.y[0:n_init]),winner_2.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_2 = np.log(-y_global_orig + loser_output_2)\r\n",
        "regret_winner_2 = np.log(-y_global_orig + winner_output_2)\r\n",
        "\r\n",
        "train_regret_loser_2 = min_max_array(regret_loser_2)\r\n",
        "train_regret_winner_2 = min_max_array(regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2 = min(train_regret_loser_2)\r\n",
        "min_train_regret_winner_2 = min(train_regret_winner_2)\r\n",
        "\r\n",
        "min_train_regret_loser_2, min_train_regret_winner_2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.805674944038582, 8.892473968347087)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suF8efHHEg3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f8039b-f7d4-443a-cd1d-e0e5be4455d8"
      },
      "source": [
        "### Training regret minimization: run number = 3\r\n",
        "\r\n",
        "loser_output_3 = np.append(np.max(loser_3.GP.y[0:n_init]),loser_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_3 = np.append(np.max(winner_3.GP.y[0:n_init]),winner_3.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_3 = np.log(-y_global_orig + loser_output_3)\r\n",
        "regret_winner_3 = np.log(-y_global_orig + winner_output_3)\r\n",
        "\r\n",
        "train_regret_loser_3 = min_max_array(regret_loser_3)\r\n",
        "train_regret_winner_3 = min_max_array(regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3 = min(train_regret_loser_3)\r\n",
        "min_train_regret_winner_3 = min(train_regret_winner_3)\r\n",
        "\r\n",
        "min_train_regret_loser_3, min_train_regret_winner_3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.054154288786854, 9.054154288786854)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPemfBgeEg8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c53b5b01-2139-4103-ca07-b4210e8a87a7"
      },
      "source": [
        "### Training regret minimization: run number = 4\r\n",
        "\r\n",
        "loser_output_4 = np.append(np.max(loser_4.GP.y[0:n_init]),loser_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_4 = np.append(np.max(winner_4.GP.y[0:n_init]),winner_4.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_4 = np.log(-y_global_orig + loser_output_4)\r\n",
        "regret_winner_4 = np.log(-y_global_orig + winner_output_4)\r\n",
        "\r\n",
        "train_regret_loser_4 = min_max_array(regret_loser_4)\r\n",
        "train_regret_winner_4 = min_max_array(regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4 = min(train_regret_loser_4)\r\n",
        "min_train_regret_winner_4 = min(train_regret_winner_4)\r\n",
        "\r\n",
        "min_train_regret_loser_4, min_train_regret_winner_4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.878776071707552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5SRriB83yR9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a52e25a-7789-48ce-b558-032f58be9f50"
      },
      "source": [
        "### Training regret minimization: run number = 5\r\n",
        "\r\n",
        "loser_output_5 = np.append(np.max(loser_5.GP.y[0:n_init]),loser_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_5 = np.append(np.max(winner_5.GP.y[0:n_init]),winner_5.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_5 = np.log(-y_global_orig + loser_output_5)\r\n",
        "regret_winner_5 = np.log(-y_global_orig + winner_output_5)\r\n",
        "\r\n",
        "train_regret_loser_5 = min_max_array(regret_loser_5)\r\n",
        "train_regret_winner_5 = min_max_array(regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5 = min(train_regret_loser_5)\r\n",
        "min_train_regret_winner_5 = min(train_regret_winner_5)\r\n",
        "\r\n",
        "min_train_regret_loser_5, min_train_regret_winner_5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.878776071707552, 8.805674944038582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUVta_GJFFaW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b08acf9-884c-4e6c-a982-1e76510f7e31"
      },
      "source": [
        "### Training regret minimization: run number = 6\r\n",
        "\r\n",
        "loser_output_6 = np.append(np.max(loser_6.GP.y[0:n_init]),loser_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_6 = np.append(np.max(winner_6.GP.y[0:n_init]),winner_6.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_6 = np.log(-y_global_orig + loser_output_6)\r\n",
        "regret_winner_6 = np.log(-y_global_orig + winner_output_6)\r\n",
        "\r\n",
        "train_regret_loser_6 = min_max_array(regret_loser_6)\r\n",
        "train_regret_winner_6 = min_max_array(regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6 = min(train_regret_loser_6)\r\n",
        "min_train_regret_winner_6 = min(train_regret_winner_6)\r\n",
        "\r\n",
        "min_train_regret_loser_6, min_train_regret_winner_6"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7V7-xKKFFm_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5426985-1b46-4d0a-c0a8-eabb3799e341"
      },
      "source": [
        "### Training regret minimization: run number = 7\r\n",
        "\r\n",
        "loser_output_7 = np.append(np.max(loser_7.GP.y[0:n_init]),loser_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_7 = np.append(np.max(winner_7.GP.y[0:n_init]),winner_7.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_7 = np.log(-y_global_orig + loser_output_7)\r\n",
        "regret_winner_7 = np.log(-y_global_orig + winner_output_7)\r\n",
        "\r\n",
        "train_regret_loser_7 = min_max_array(regret_loser_7)\r\n",
        "train_regret_winner_7 = min_max_array(regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7 = min(train_regret_loser_7)\r\n",
        "min_train_regret_winner_7 = min(train_regret_winner_7)\r\n",
        "\r\n",
        "min_train_regret_loser_7, min_train_regret_winner_7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.00859131751613, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMQ0rwZoFFuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6f3a76-45cb-4d7d-cdb4-600becd275e0"
      },
      "source": [
        "### Training regret minimization: run number = 8\r\n",
        "\r\n",
        "loser_output_8 = np.append(np.max(loser_8.GP.y[0:n_init]),loser_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_8 = np.append(np.max(winner_8.GP.y[0:n_init]),winner_8.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_8 = np.log(-y_global_orig + loser_output_8)\r\n",
        "regret_winner_8 = np.log(-y_global_orig + winner_output_8)\r\n",
        "\r\n",
        "train_regret_loser_8 = min_max_array(regret_loser_8)\r\n",
        "train_regret_winner_8 = min_max_array(regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8 = min(train_regret_loser_8)\r\n",
        "min_train_regret_winner_8 = min(train_regret_winner_8)\r\n",
        "\r\n",
        "min_train_regret_loser_8, min_train_regret_winner_8"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW39Qs4ZFFzr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4cc02f-7c54-47d4-a674-a0d3c13bbc77"
      },
      "source": [
        "### Training regret minimization: run number = 9\r\n",
        "\r\n",
        "loser_output_9 = np.append(np.max(loser_9.GP.y[0:n_init]),loser_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_9 = np.append(np.max(winner_9.GP.y[0:n_init]),winner_9.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_9 = np.log(-y_global_orig + loser_output_9)\r\n",
        "regret_winner_9 = np.log(-y_global_orig + winner_output_9)\r\n",
        "\r\n",
        "train_regret_loser_9 = min_max_array(regret_loser_9)\r\n",
        "train_regret_winner_9 = min_max_array(regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9 = min(train_regret_loser_9)\r\n",
        "min_train_regret_winner_9 = min(train_regret_winner_9)\r\n",
        "\r\n",
        "min_train_regret_loser_9, min_train_regret_winner_9"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.852521917335372, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH5fvkDWFF4N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69ef24b-72fb-4172-f3d6-3d288b6abb21"
      },
      "source": [
        "### Training regret minimization: run number = 10\r\n",
        "\r\n",
        "loser_output_10 = np.append(np.max(loser_10.GP.y[0:n_init]),loser_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_10 = np.append(np.max(winner_10.GP.y[0:n_init]),winner_10.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_10 = np.log(-y_global_orig + loser_output_10)\r\n",
        "regret_winner_10 = np.log(-y_global_orig + winner_output_10)\r\n",
        "\r\n",
        "train_regret_loser_10 = min_max_array(regret_loser_10)\r\n",
        "train_regret_winner_10 = min_max_array(regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10 = min(train_regret_loser_10)\r\n",
        "min_train_regret_winner_10 = min(train_regret_winner_10)\r\n",
        "\r\n",
        "min_train_regret_loser_10, min_train_regret_winner_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdGgTNueFF8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc6612b7-5caf-4c1b-c7f3-96a1dd5338bb"
      },
      "source": [
        "### Training regret minimization: run number = 11\r\n",
        "\r\n",
        "loser_output_11 = np.append(np.max(loser_11.GP.y[0:n_init]),loser_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_11 = np.append(np.max(winner_11.GP.y[0:n_init]),winner_11.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_11 = np.log(-y_global_orig + loser_output_11)\r\n",
        "regret_winner_11 = np.log(-y_global_orig + winner_output_11)\r\n",
        "\r\n",
        "train_regret_loser_11 = min_max_array(regret_loser_11)\r\n",
        "train_regret_winner_11 = min_max_array(regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11 = min(train_regret_loser_11)\r\n",
        "min_train_regret_winner_11 = min(train_regret_winner_11)\r\n",
        "\r\n",
        "min_train_regret_loser_11, min_train_regret_winner_11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVeNgJSbFGAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a3f436b-4a86-493a-a151-943c13d843ce"
      },
      "source": [
        "### Training regret minimization: run number = 12\r\n",
        "\r\n",
        "loser_output_12 = np.append(np.max(loser_12.GP.y[0:n_init]),loser_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_12 = np.append(np.max(winner_12.GP.y[0:n_init]),winner_12.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_12 = np.log(-y_global_orig + loser_output_12)\r\n",
        "regret_winner_12 = np.log(-y_global_orig + winner_output_12)\r\n",
        "\r\n",
        "train_regret_loser_12 = min_max_array(regret_loser_12)\r\n",
        "train_regret_winner_12 = min_max_array(regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12 = min(train_regret_loser_12)\r\n",
        "min_train_regret_winner_12 = min(train_regret_winner_12)\r\n",
        "\r\n",
        "min_train_regret_loser_12, min_train_regret_winner_12"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.932212512329214, 8.932212512329214)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GIrEFAMFGD9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8049240-339f-448d-e7a8-b1a38a243318"
      },
      "source": [
        "### Training regret minimization: run number = 13\r\n",
        "\r\n",
        "loser_output_13 = np.append(np.max(loser_13.GP.y[0:n_init]),loser_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_13 = np.append(np.max(winner_13.GP.y[0:n_init]),winner_13.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_13 = np.log(-y_global_orig + loser_output_13)\r\n",
        "regret_winner_13 = np.log(-y_global_orig + winner_output_13)\r\n",
        "\r\n",
        "train_regret_loser_13 = min_max_array(regret_loser_13)\r\n",
        "train_regret_winner_13 = min_max_array(regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13 = min(train_regret_loser_13)\r\n",
        "min_train_regret_winner_13 = min(train_regret_winner_13)\r\n",
        "\r\n",
        "min_train_regret_loser_13, min_train_regret_winner_13"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.805674944038582, 8.805674944038582)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV0iCAUQFGIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a64a976d-4cf8-43f7-b7b9-e6d8edda2309"
      },
      "source": [
        "### Training regret minimization: run number = 14\r\n",
        "\r\n",
        "loser_output_14 = np.append(np.max(loser_14.GP.y[0:n_init]),loser_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_14 = np.append(np.max(winner_14.GP.y[0:n_init]),winner_14.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_14 = np.log(-y_global_orig + loser_output_14)\r\n",
        "regret_winner_14 = np.log(-y_global_orig + winner_output_14)\r\n",
        "\r\n",
        "train_regret_loser_14 = min_max_array(regret_loser_14)\r\n",
        "train_regret_winner_14 = min_max_array(regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14 = min(train_regret_loser_14)\r\n",
        "min_train_regret_winner_14 = min(train_regret_winner_14)\r\n",
        "\r\n",
        "min_train_regret_loser_14, min_train_regret_winner_14"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJqZhhnBFGMm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95dac8ee-85c6-447d-8cca-fd1b72d4fe93"
      },
      "source": [
        "### Training regret minimization: run number = 15\r\n",
        "\r\n",
        "loser_output_15 = np.append(np.max(loser_15.GP.y[0:n_init]),loser_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_15 = np.append(np.max(winner_15.GP.y[0:n_init]),winner_15.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_15 = np.log(-y_global_orig + loser_output_15)\r\n",
        "regret_winner_15 = np.log(-y_global_orig + winner_output_15)\r\n",
        "\r\n",
        "train_regret_loser_15 = min_max_array(regret_loser_15)\r\n",
        "train_regret_winner_15 = min_max_array(regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15 = min(train_regret_loser_15)\r\n",
        "min_train_regret_winner_15 = min(train_regret_winner_15)\r\n",
        "\r\n",
        "min_train_regret_loser_15, min_train_regret_winner_15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPmJ7j3RFGRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70d32ae-3c4d-4339-ebfd-2f9d2e74bfae"
      },
      "source": [
        "### Training regret minimization: run number = 16\r\n",
        "\r\n",
        "loser_output_16 = np.append(np.max(loser_16.GP.y[0:n_init]),loser_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_16 = np.append(np.max(winner_16.GP.y[0:n_init]),winner_16.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_16 = np.log(-y_global_orig + loser_output_16)\r\n",
        "regret_winner_16 = np.log(-y_global_orig + winner_output_16)\r\n",
        "\r\n",
        "train_regret_loser_16 = min_max_array(regret_loser_16)\r\n",
        "train_regret_winner_16 = min_max_array(regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16 = min(train_regret_loser_16)\r\n",
        "min_train_regret_winner_16 = min(train_regret_winner_16)\r\n",
        "\r\n",
        "min_train_regret_loser_16, min_train_regret_winner_16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfyyMg-bFGWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c28ee3e-af23-401d-fa7f-f69940e173b4"
      },
      "source": [
        "### Training regret minimization: run number = 17\r\n",
        "\r\n",
        "loser_output_17 = np.append(np.max(loser_17.GP.y[0:n_init]),loser_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_17 = np.append(np.max(winner_17.GP.y[0:n_init]),winner_17.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_17 = np.log(-y_global_orig + loser_output_17)\r\n",
        "regret_winner_17 = np.log(-y_global_orig + winner_output_17)\r\n",
        "\r\n",
        "train_regret_loser_17 = min_max_array(regret_loser_17)\r\n",
        "train_regret_winner_17 = min_max_array(regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17 = min(train_regret_loser_17)\r\n",
        "min_train_regret_winner_17 = min(train_regret_winner_17)\r\n",
        "\r\n",
        "min_train_regret_loser_17, min_train_regret_winner_17"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WS6hJYuFGa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9095df5-f837-429e-91a1-14bc5867423a"
      },
      "source": [
        "### Training regret minimization: run number = 18\r\n",
        "\r\n",
        "loser_output_18 = np.append(np.max(loser_18.GP.y[0:n_init]),loser_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_18 = np.append(np.max(winner_18.GP.y[0:n_init]),winner_18.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_18 = np.log(-y_global_orig + loser_output_18)\r\n",
        "regret_winner_18 = np.log(-y_global_orig + winner_output_18)\r\n",
        "\r\n",
        "train_regret_loser_18 = min_max_array(regret_loser_18)\r\n",
        "train_regret_winner_18 = min_max_array(regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18 = min(train_regret_loser_18)\r\n",
        "min_train_regret_winner_18 = min(train_regret_winner_18)\r\n",
        "\r\n",
        "min_train_regret_loser_18, min_train_regret_winner_18"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.973097896282471)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErcIOoOXFGgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcd6c460-2b59-4b01-a367-abd39ac8f109"
      },
      "source": [
        "### Training regret minimization: run number = 19\r\n",
        "\r\n",
        "loser_output_19 = np.append(np.max(loser_19.GP.y[0:n_init]),loser_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_19 = np.append(np.max(winner_19.GP.y[0:n_init]),winner_19.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_19 = np.log(-y_global_orig + loser_output_19)\r\n",
        "regret_winner_19 = np.log(-y_global_orig + winner_output_19)\r\n",
        "\r\n",
        "train_regret_loser_19 = min_max_array(regret_loser_19)\r\n",
        "train_regret_winner_19 = min_max_array(regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19 = min(train_regret_loser_19)\r\n",
        "min_train_regret_winner_19 = min(train_regret_winner_19)\r\n",
        "\r\n",
        "min_train_regret_loser_19, min_train_regret_winner_19"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.955060950631902, 8.955060950631902)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbOsumB6FGlD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d977ffe2-a3a5-4d5d-f443-e719d254656e"
      },
      "source": [
        "### Training regret minimization: run number = 20\r\n",
        "\r\n",
        "loser_output_20 = np.append(np.max(loser_20.GP.y[0:n_init]),loser_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "winner_output_20 = np.append(np.max(winner_20.GP.y[0:n_init]),winner_20.GP.y[n_init:(n_init+max_iter)]) \r\n",
        "\r\n",
        "regret_loser_20 = np.log(-y_global_orig + loser_output_20)\r\n",
        "regret_winner_20 = np.log(-y_global_orig + winner_output_20)\r\n",
        "\r\n",
        "train_regret_loser_20 = min_max_array(regret_loser_20)\r\n",
        "train_regret_winner_20 = min_max_array(regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20 = min(train_regret_loser_20)\r\n",
        "min_train_regret_winner_20 = min(train_regret_winner_20)\r\n",
        "\r\n",
        "min_train_regret_loser_20, min_train_regret_winner_20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.32259705432185, 9.32259705432185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89S668T8GSeJ"
      },
      "source": [
        "# Iteration1 :\r\n",
        "\r\n",
        "slice1 = 0\r\n",
        "\r\n",
        "loser1 = [train_regret_loser_1[slice1],\r\n",
        "       train_regret_loser_2[slice1],\r\n",
        "       train_regret_loser_3[slice1],\r\n",
        "       train_regret_loser_4[slice1],\r\n",
        "       train_regret_loser_5[slice1],\r\n",
        "       train_regret_loser_6[slice1],\r\n",
        "       train_regret_loser_7[slice1],\r\n",
        "       train_regret_loser_8[slice1],\r\n",
        "       train_regret_loser_9[slice1],\r\n",
        "       train_regret_loser_10[slice1],\r\n",
        "       train_regret_loser_11[slice1],\r\n",
        "       train_regret_loser_12[slice1],\r\n",
        "       train_regret_loser_13[slice1],\r\n",
        "       train_regret_loser_14[slice1],\r\n",
        "       train_regret_loser_15[slice1],\r\n",
        "       train_regret_loser_16[slice1],\r\n",
        "       train_regret_loser_17[slice1],\r\n",
        "       train_regret_loser_18[slice1],\r\n",
        "       train_regret_loser_19[slice1],\r\n",
        "       train_regret_loser_20[slice1]]\r\n",
        "\r\n",
        "winner1 = [train_regret_winner_1[slice1],\r\n",
        "       train_regret_winner_2[slice1],\r\n",
        "       train_regret_winner_3[slice1],\r\n",
        "       train_regret_winner_4[slice1],\r\n",
        "       train_regret_winner_5[slice1],\r\n",
        "       train_regret_winner_6[slice1],\r\n",
        "       train_regret_winner_7[slice1],\r\n",
        "       train_regret_winner_8[slice1],\r\n",
        "       train_regret_winner_9[slice1],\r\n",
        "       train_regret_winner_10[slice1],\r\n",
        "       train_regret_winner_11[slice1],\r\n",
        "       train_regret_winner_12[slice1],\r\n",
        "       train_regret_winner_13[slice1],\r\n",
        "       train_regret_winner_14[slice1],\r\n",
        "       train_regret_winner_15[slice1],\r\n",
        "       train_regret_winner_16[slice1],\r\n",
        "       train_regret_winner_17[slice1],\r\n",
        "       train_regret_winner_18[slice1],\r\n",
        "       train_regret_winner_19[slice1],\r\n",
        "       train_regret_winner_20[slice1]]\r\n",
        "\r\n",
        "loser1_results = pd.DataFrame(loser1).sort_values(by=[0], ascending=False)\r\n",
        "winner1_results = pd.DataFrame(winner1).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser1 = np.asarray(loser1_results[4:5][0])[0]\r\n",
        "median_loser1 = np.asarray(loser1_results[9:10][0])[0]\r\n",
        "upper_loser1 = np.asarray(loser1_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner1 = np.asarray(winner1_results[4:5][0])[0]\r\n",
        "median_winner1 = np.asarray(winner1_results[9:10][0])[0]\r\n",
        "upper_winner1 = np.asarray(winner1_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CbMKkbYGSmk"
      },
      "source": [
        "# Iteration11 :\r\n",
        "\r\n",
        "slice11 = 10\r\n",
        "\r\n",
        "loser11 = [train_regret_loser_1[slice11],\r\n",
        "       train_regret_loser_2[slice11],\r\n",
        "       train_regret_loser_3[slice11],\r\n",
        "       train_regret_loser_4[slice11],\r\n",
        "       train_regret_loser_5[slice11],\r\n",
        "       train_regret_loser_6[slice11],\r\n",
        "       train_regret_loser_7[slice11],\r\n",
        "       train_regret_loser_8[slice11],\r\n",
        "       train_regret_loser_9[slice11],\r\n",
        "       train_regret_loser_10[slice11],\r\n",
        "       train_regret_loser_11[slice11],\r\n",
        "       train_regret_loser_12[slice11],\r\n",
        "       train_regret_loser_13[slice11],\r\n",
        "       train_regret_loser_14[slice11],\r\n",
        "       train_regret_loser_15[slice11],\r\n",
        "       train_regret_loser_16[slice11],\r\n",
        "       train_regret_loser_17[slice11],\r\n",
        "       train_regret_loser_18[slice11],\r\n",
        "       train_regret_loser_19[slice11],\r\n",
        "       train_regret_loser_20[slice11]]\r\n",
        "\r\n",
        "winner11 = [train_regret_winner_1[slice11],\r\n",
        "       train_regret_winner_2[slice11],\r\n",
        "       train_regret_winner_3[slice11],\r\n",
        "       train_regret_winner_4[slice11],\r\n",
        "       train_regret_winner_5[slice11],\r\n",
        "       train_regret_winner_6[slice11],\r\n",
        "       train_regret_winner_7[slice11],\r\n",
        "       train_regret_winner_8[slice11],\r\n",
        "       train_regret_winner_9[slice11],\r\n",
        "       train_regret_winner_10[slice11],\r\n",
        "       train_regret_winner_11[slice11],\r\n",
        "       train_regret_winner_12[slice11],\r\n",
        "       train_regret_winner_13[slice11],\r\n",
        "       train_regret_winner_14[slice11],\r\n",
        "       train_regret_winner_15[slice11],\r\n",
        "       train_regret_winner_16[slice11],\r\n",
        "       train_regret_winner_17[slice11],\r\n",
        "       train_regret_winner_18[slice11],\r\n",
        "       train_regret_winner_19[slice11],\r\n",
        "       train_regret_winner_20[slice11]]\r\n",
        "\r\n",
        "loser11_results = pd.DataFrame(loser11).sort_values(by=[0], ascending=False)\r\n",
        "winner11_results = pd.DataFrame(winner11).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser11 = np.asarray(loser11_results[4:5][0])[0]\r\n",
        "median_loser11 = np.asarray(loser11_results[9:10][0])[0]\r\n",
        "upper_loser11 = np.asarray(loser11_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner11 = np.asarray(winner11_results[4:5][0])[0]\r\n",
        "median_winner11 = np.asarray(winner11_results[9:10][0])[0]\r\n",
        "upper_winner11 = np.asarray(winner11_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dqqsAbZGSto"
      },
      "source": [
        "# Iteration2 :\r\n",
        "\r\n",
        "slice2 = 1\r\n",
        "\r\n",
        "loser2 = [train_regret_loser_1[slice2],\r\n",
        "       train_regret_loser_2[slice2],\r\n",
        "       train_regret_loser_3[slice2],\r\n",
        "       train_regret_loser_4[slice2],\r\n",
        "       train_regret_loser_5[slice2],\r\n",
        "       train_regret_loser_6[slice2],\r\n",
        "       train_regret_loser_7[slice2],\r\n",
        "       train_regret_loser_8[slice2],\r\n",
        "       train_regret_loser_9[slice2],\r\n",
        "       train_regret_loser_10[slice2],\r\n",
        "       train_regret_loser_11[slice2],\r\n",
        "       train_regret_loser_12[slice2],\r\n",
        "       train_regret_loser_13[slice2],\r\n",
        "       train_regret_loser_14[slice2],\r\n",
        "       train_regret_loser_15[slice2],\r\n",
        "       train_regret_loser_16[slice2],\r\n",
        "       train_regret_loser_17[slice2],\r\n",
        "       train_regret_loser_18[slice2],\r\n",
        "       train_regret_loser_19[slice2],\r\n",
        "       train_regret_loser_20[slice2]]\r\n",
        "\r\n",
        "winner2 = [train_regret_winner_1[slice2],\r\n",
        "       train_regret_winner_2[slice2],\r\n",
        "       train_regret_winner_3[slice2],\r\n",
        "       train_regret_winner_4[slice2],\r\n",
        "       train_regret_winner_5[slice2],\r\n",
        "       train_regret_winner_6[slice2],\r\n",
        "       train_regret_winner_7[slice2],\r\n",
        "       train_regret_winner_8[slice2],\r\n",
        "       train_regret_winner_9[slice2],\r\n",
        "       train_regret_winner_10[slice2],\r\n",
        "       train_regret_winner_11[slice2],\r\n",
        "       train_regret_winner_12[slice2],\r\n",
        "       train_regret_winner_13[slice2],\r\n",
        "       train_regret_winner_14[slice2],\r\n",
        "       train_regret_winner_15[slice2],\r\n",
        "       train_regret_winner_16[slice2],\r\n",
        "       train_regret_winner_17[slice2],\r\n",
        "       train_regret_winner_18[slice2],\r\n",
        "       train_regret_winner_19[slice2],\r\n",
        "       train_regret_winner_20[slice2]]\r\n",
        "\r\n",
        "loser2_results = pd.DataFrame(loser2).sort_values(by=[0], ascending=False)\r\n",
        "winner2_results = pd.DataFrame(winner2).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser2 = np.asarray(loser2_results[4:5][0])[0]\r\n",
        "median_loser2 = np.asarray(loser2_results[9:10][0])[0]\r\n",
        "upper_loser2 = np.asarray(loser2_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner2 = np.asarray(winner2_results[4:5][0])[0]\r\n",
        "median_winner2 = np.asarray(winner2_results[9:10][0])[0]\r\n",
        "upper_winner2 = np.asarray(winner2_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QT1vdmweGSza"
      },
      "source": [
        "# Iteration3 :\r\n",
        "\r\n",
        "slice3 = 2\r\n",
        "\r\n",
        "loser3 = [train_regret_loser_1[slice3],\r\n",
        "       train_regret_loser_2[slice3],\r\n",
        "       train_regret_loser_3[slice3],\r\n",
        "       train_regret_loser_4[slice3],\r\n",
        "       train_regret_loser_5[slice3],\r\n",
        "       train_regret_loser_6[slice3],\r\n",
        "       train_regret_loser_7[slice3],\r\n",
        "       train_regret_loser_8[slice3],\r\n",
        "       train_regret_loser_9[slice3],\r\n",
        "       train_regret_loser_10[slice3],\r\n",
        "       train_regret_loser_11[slice3],\r\n",
        "       train_regret_loser_12[slice3],\r\n",
        "       train_regret_loser_13[slice3],\r\n",
        "       train_regret_loser_14[slice3],\r\n",
        "       train_regret_loser_15[slice3],\r\n",
        "       train_regret_loser_16[slice3],\r\n",
        "       train_regret_loser_17[slice3],\r\n",
        "       train_regret_loser_18[slice3],\r\n",
        "       train_regret_loser_19[slice3],\r\n",
        "       train_regret_loser_20[slice3]]\r\n",
        "\r\n",
        "winner3 = [train_regret_winner_1[slice3],\r\n",
        "       train_regret_winner_2[slice3],\r\n",
        "       train_regret_winner_3[slice3],\r\n",
        "       train_regret_winner_4[slice3],\r\n",
        "       train_regret_winner_5[slice3],\r\n",
        "       train_regret_winner_6[slice3],\r\n",
        "       train_regret_winner_7[slice3],\r\n",
        "       train_regret_winner_8[slice3],\r\n",
        "       train_regret_winner_9[slice3],\r\n",
        "       train_regret_winner_10[slice3],\r\n",
        "       train_regret_winner_11[slice3],\r\n",
        "       train_regret_winner_12[slice3],\r\n",
        "       train_regret_winner_13[slice3],\r\n",
        "       train_regret_winner_14[slice3],\r\n",
        "       train_regret_winner_15[slice3],\r\n",
        "       train_regret_winner_16[slice3],\r\n",
        "       train_regret_winner_17[slice3],\r\n",
        "       train_regret_winner_18[slice3],\r\n",
        "       train_regret_winner_19[slice3],\r\n",
        "       train_regret_winner_20[slice3]]\r\n",
        "\r\n",
        "loser3_results = pd.DataFrame(loser3).sort_values(by=[0], ascending=False)\r\n",
        "winner3_results = pd.DataFrame(winner3).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser3 = np.asarray(loser3_results[4:5][0])[0]\r\n",
        "median_loser3 = np.asarray(loser3_results[9:10][0])[0]\r\n",
        "upper_loser3 = np.asarray(loser3_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner3 = np.asarray(winner3_results[4:5][0])[0]\r\n",
        "median_winner3 = np.asarray(winner3_results[9:10][0])[0]\r\n",
        "upper_winner3 = np.asarray(winner3_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXZrawn0GS4Z"
      },
      "source": [
        "# Iteration4 :\r\n",
        "\r\n",
        "slice4 = 3\r\n",
        "\r\n",
        "loser4 = [train_regret_loser_1[slice4],\r\n",
        "       train_regret_loser_2[slice4],\r\n",
        "       train_regret_loser_3[slice4],\r\n",
        "       train_regret_loser_4[slice4],\r\n",
        "       train_regret_loser_5[slice4],\r\n",
        "       train_regret_loser_6[slice4],\r\n",
        "       train_regret_loser_7[slice4],\r\n",
        "       train_regret_loser_8[slice4],\r\n",
        "       train_regret_loser_9[slice4],\r\n",
        "       train_regret_loser_10[slice4],\r\n",
        "       train_regret_loser_11[slice4],\r\n",
        "       train_regret_loser_12[slice4],\r\n",
        "       train_regret_loser_13[slice4],\r\n",
        "       train_regret_loser_14[slice4],\r\n",
        "       train_regret_loser_15[slice4],\r\n",
        "       train_regret_loser_16[slice4],\r\n",
        "       train_regret_loser_17[slice4],\r\n",
        "       train_regret_loser_18[slice4],\r\n",
        "       train_regret_loser_19[slice4],\r\n",
        "       train_regret_loser_20[slice4]]\r\n",
        "\r\n",
        "winner4 = [train_regret_winner_1[slice4],\r\n",
        "       train_regret_winner_2[slice4],\r\n",
        "       train_regret_winner_3[slice4],\r\n",
        "       train_regret_winner_4[slice4],\r\n",
        "       train_regret_winner_5[slice4],\r\n",
        "       train_regret_winner_6[slice4],\r\n",
        "       train_regret_winner_7[slice4],\r\n",
        "       train_regret_winner_8[slice4],\r\n",
        "       train_regret_winner_9[slice4],\r\n",
        "       train_regret_winner_10[slice4],\r\n",
        "       train_regret_winner_11[slice4],\r\n",
        "       train_regret_winner_12[slice4],\r\n",
        "       train_regret_winner_13[slice4],\r\n",
        "       train_regret_winner_14[slice4],\r\n",
        "       train_regret_winner_15[slice4],\r\n",
        "       train_regret_winner_16[slice4],\r\n",
        "       train_regret_winner_17[slice4],\r\n",
        "       train_regret_winner_18[slice4],\r\n",
        "       train_regret_winner_19[slice4],\r\n",
        "       train_regret_winner_20[slice4]]\r\n",
        "\r\n",
        "loser4_results = pd.DataFrame(loser4).sort_values(by=[0], ascending=False)\r\n",
        "winner4_results = pd.DataFrame(winner4).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser4 = np.asarray(loser4_results[4:5][0])[0]\r\n",
        "median_loser4 = np.asarray(loser4_results[9:10][0])[0]\r\n",
        "upper_loser4 = np.asarray(loser4_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner4 = np.asarray(winner4_results[4:5][0])[0]\r\n",
        "median_winner4 = np.asarray(winner4_results[9:10][0])[0]\r\n",
        "upper_winner4 = np.asarray(winner4_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN6pn6cNGyGZ"
      },
      "source": [
        "# Iteration5 :\r\n",
        "\r\n",
        "slice5 = 4\r\n",
        "\r\n",
        "loser5 = [train_regret_loser_1[slice5],\r\n",
        "       train_regret_loser_2[slice5],\r\n",
        "       train_regret_loser_3[slice5],\r\n",
        "       train_regret_loser_4[slice5],\r\n",
        "       train_regret_loser_5[slice5],\r\n",
        "       train_regret_loser_6[slice5],\r\n",
        "       train_regret_loser_7[slice5],\r\n",
        "       train_regret_loser_8[slice5],\r\n",
        "       train_regret_loser_9[slice5],\r\n",
        "       train_regret_loser_10[slice5],\r\n",
        "       train_regret_loser_11[slice5],\r\n",
        "       train_regret_loser_12[slice5],\r\n",
        "       train_regret_loser_13[slice5],\r\n",
        "       train_regret_loser_14[slice5],\r\n",
        "       train_regret_loser_15[slice5],\r\n",
        "       train_regret_loser_16[slice5],\r\n",
        "       train_regret_loser_17[slice5],\r\n",
        "       train_regret_loser_18[slice5],\r\n",
        "       train_regret_loser_19[slice5],\r\n",
        "       train_regret_loser_20[slice5]]\r\n",
        "\r\n",
        "winner5 = [train_regret_winner_1[slice5],\r\n",
        "       train_regret_winner_2[slice5],\r\n",
        "       train_regret_winner_3[slice5],\r\n",
        "       train_regret_winner_4[slice5],\r\n",
        "       train_regret_winner_5[slice5],\r\n",
        "       train_regret_winner_6[slice5],\r\n",
        "       train_regret_winner_7[slice5],\r\n",
        "       train_regret_winner_8[slice5],\r\n",
        "       train_regret_winner_9[slice5],\r\n",
        "       train_regret_winner_10[slice5],\r\n",
        "       train_regret_winner_11[slice5],\r\n",
        "       train_regret_winner_12[slice5],\r\n",
        "       train_regret_winner_13[slice5],\r\n",
        "       train_regret_winner_14[slice5],\r\n",
        "       train_regret_winner_15[slice5],\r\n",
        "       train_regret_winner_16[slice5],\r\n",
        "       train_regret_winner_17[slice5],\r\n",
        "       train_regret_winner_18[slice5],\r\n",
        "       train_regret_winner_19[slice5],\r\n",
        "       train_regret_winner_20[slice5]]\r\n",
        "\r\n",
        "loser5_results = pd.DataFrame(loser5).sort_values(by=[0], ascending=False)\r\n",
        "winner5_results = pd.DataFrame(winner5).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser5 = np.asarray(loser5_results[4:5][0])[0]\r\n",
        "median_loser5 = np.asarray(loser5_results[9:10][0])[0]\r\n",
        "upper_loser5 = np.asarray(loser5_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner5 = np.asarray(winner5_results[4:5][0])[0]\r\n",
        "median_winner5 = np.asarray(winner5_results[9:10][0])[0]\r\n",
        "upper_winner5 = np.asarray(winner5_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urt-8ta6GyYX"
      },
      "source": [
        "# Iteration6 :\r\n",
        "\r\n",
        "slice6 = 5\r\n",
        "\r\n",
        "loser6 = [train_regret_loser_1[slice6],\r\n",
        "       train_regret_loser_2[slice6],\r\n",
        "       train_regret_loser_3[slice6],\r\n",
        "       train_regret_loser_4[slice6],\r\n",
        "       train_regret_loser_5[slice6],\r\n",
        "       train_regret_loser_6[slice6],\r\n",
        "       train_regret_loser_7[slice6],\r\n",
        "       train_regret_loser_8[slice6],\r\n",
        "       train_regret_loser_9[slice6],\r\n",
        "       train_regret_loser_10[slice6],\r\n",
        "       train_regret_loser_11[slice6],\r\n",
        "       train_regret_loser_12[slice6],\r\n",
        "       train_regret_loser_13[slice6],\r\n",
        "       train_regret_loser_14[slice6],\r\n",
        "       train_regret_loser_15[slice6],\r\n",
        "       train_regret_loser_16[slice6],\r\n",
        "       train_regret_loser_17[slice6],\r\n",
        "       train_regret_loser_18[slice6],\r\n",
        "       train_regret_loser_19[slice6],\r\n",
        "       train_regret_loser_20[slice6]]\r\n",
        "\r\n",
        "winner6 = [train_regret_winner_1[slice6],\r\n",
        "       train_regret_winner_2[slice6],\r\n",
        "       train_regret_winner_3[slice6],\r\n",
        "       train_regret_winner_4[slice6],\r\n",
        "       train_regret_winner_5[slice6],\r\n",
        "       train_regret_winner_6[slice6],\r\n",
        "       train_regret_winner_7[slice6],\r\n",
        "       train_regret_winner_8[slice6],\r\n",
        "       train_regret_winner_9[slice6],\r\n",
        "       train_regret_winner_10[slice6],\r\n",
        "       train_regret_winner_11[slice6],\r\n",
        "       train_regret_winner_12[slice6],\r\n",
        "       train_regret_winner_13[slice6],\r\n",
        "       train_regret_winner_14[slice6],\r\n",
        "       train_regret_winner_15[slice6],\r\n",
        "       train_regret_winner_16[slice6],\r\n",
        "       train_regret_winner_17[slice6],\r\n",
        "       train_regret_winner_18[slice6],\r\n",
        "       train_regret_winner_19[slice6],\r\n",
        "       train_regret_winner_20[slice6]]\r\n",
        "\r\n",
        "loser6_results = pd.DataFrame(loser6).sort_values(by=[0], ascending=False)\r\n",
        "winner6_results = pd.DataFrame(winner6).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser6 = np.asarray(loser6_results[4:5][0])[0]\r\n",
        "median_loser6 = np.asarray(loser6_results[9:10][0])[0]\r\n",
        "upper_loser6 = np.asarray(loser6_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner6 = np.asarray(winner6_results[4:5][0])[0]\r\n",
        "median_winner6 = np.asarray(winner6_results[9:10][0])[0]\r\n",
        "upper_winner6 = np.asarray(winner6_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQJb0cU0GybL"
      },
      "source": [
        "# Iteration7 :\r\n",
        "\r\n",
        "slice7 = 6\r\n",
        "\r\n",
        "loser7 = [train_regret_loser_1[slice7],\r\n",
        "       train_regret_loser_2[slice7],\r\n",
        "       train_regret_loser_3[slice7],\r\n",
        "       train_regret_loser_4[slice7],\r\n",
        "       train_regret_loser_5[slice7],\r\n",
        "       train_regret_loser_6[slice7],\r\n",
        "       train_regret_loser_7[slice7],\r\n",
        "       train_regret_loser_8[slice7],\r\n",
        "       train_regret_loser_9[slice7],\r\n",
        "       train_regret_loser_10[slice7],\r\n",
        "       train_regret_loser_11[slice7],\r\n",
        "       train_regret_loser_12[slice7],\r\n",
        "       train_regret_loser_13[slice7],\r\n",
        "       train_regret_loser_14[slice7],\r\n",
        "       train_regret_loser_15[slice7],\r\n",
        "       train_regret_loser_16[slice7],\r\n",
        "       train_regret_loser_17[slice7],\r\n",
        "       train_regret_loser_18[slice7],\r\n",
        "       train_regret_loser_19[slice7],\r\n",
        "       train_regret_loser_20[slice7]]\r\n",
        "\r\n",
        "winner7 = [train_regret_winner_1[slice7],\r\n",
        "       train_regret_winner_2[slice7],\r\n",
        "       train_regret_winner_3[slice7],\r\n",
        "       train_regret_winner_4[slice7],\r\n",
        "       train_regret_winner_5[slice7],\r\n",
        "       train_regret_winner_6[slice7],\r\n",
        "       train_regret_winner_7[slice7],\r\n",
        "       train_regret_winner_8[slice7],\r\n",
        "       train_regret_winner_9[slice7],\r\n",
        "       train_regret_winner_10[slice7],\r\n",
        "       train_regret_winner_11[slice7],\r\n",
        "       train_regret_winner_12[slice7],\r\n",
        "       train_regret_winner_13[slice7],\r\n",
        "       train_regret_winner_14[slice7],\r\n",
        "       train_regret_winner_15[slice7],\r\n",
        "       train_regret_winner_16[slice7],\r\n",
        "       train_regret_winner_17[slice7],\r\n",
        "       train_regret_winner_18[slice7],\r\n",
        "       train_regret_winner_19[slice7],\r\n",
        "       train_regret_winner_20[slice7]]\r\n",
        "\r\n",
        "loser7_results = pd.DataFrame(loser7).sort_values(by=[0], ascending=False)\r\n",
        "winner7_results = pd.DataFrame(winner7).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser7 = np.asarray(loser7_results[4:5][0])[0]\r\n",
        "median_loser7 = np.asarray(loser7_results[9:10][0])[0]\r\n",
        "upper_loser7 = np.asarray(loser7_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner7 = np.asarray(winner7_results[4:5][0])[0]\r\n",
        "median_winner7 = np.asarray(winner7_results[9:10][0])[0]\r\n",
        "upper_winner7 = np.asarray(winner7_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O8pwUkWGyeD"
      },
      "source": [
        "# Iteration8 :\r\n",
        "\r\n",
        "slice8 = 7\r\n",
        "\r\n",
        "loser8 = [train_regret_loser_1[slice8],\r\n",
        "       train_regret_loser_2[slice8],\r\n",
        "       train_regret_loser_3[slice8],\r\n",
        "       train_regret_loser_4[slice8],\r\n",
        "       train_regret_loser_5[slice8],\r\n",
        "       train_regret_loser_6[slice8],\r\n",
        "       train_regret_loser_7[slice8],\r\n",
        "       train_regret_loser_8[slice8],\r\n",
        "       train_regret_loser_9[slice8],\r\n",
        "       train_regret_loser_10[slice8],\r\n",
        "       train_regret_loser_11[slice8],\r\n",
        "       train_regret_loser_12[slice8],\r\n",
        "       train_regret_loser_13[slice8],\r\n",
        "       train_regret_loser_14[slice8],\r\n",
        "       train_regret_loser_15[slice8],\r\n",
        "       train_regret_loser_16[slice8],\r\n",
        "       train_regret_loser_17[slice8],\r\n",
        "       train_regret_loser_18[slice8],\r\n",
        "       train_regret_loser_19[slice8],\r\n",
        "       train_regret_loser_20[slice8]]\r\n",
        "\r\n",
        "winner8 = [train_regret_winner_1[slice8],\r\n",
        "       train_regret_winner_2[slice8],\r\n",
        "       train_regret_winner_3[slice8],\r\n",
        "       train_regret_winner_4[slice8],\r\n",
        "       train_regret_winner_5[slice8],\r\n",
        "       train_regret_winner_6[slice8],\r\n",
        "       train_regret_winner_7[slice8],\r\n",
        "       train_regret_winner_8[slice8],\r\n",
        "       train_regret_winner_9[slice8],\r\n",
        "       train_regret_winner_10[slice8],\r\n",
        "       train_regret_winner_11[slice8],\r\n",
        "       train_regret_winner_12[slice8],\r\n",
        "       train_regret_winner_13[slice8],\r\n",
        "       train_regret_winner_14[slice8],\r\n",
        "       train_regret_winner_15[slice8],\r\n",
        "       train_regret_winner_16[slice8],\r\n",
        "       train_regret_winner_17[slice8],\r\n",
        "       train_regret_winner_18[slice8],\r\n",
        "       train_regret_winner_19[slice8],\r\n",
        "       train_regret_winner_20[slice8]]\r\n",
        "\r\n",
        "loser8_results = pd.DataFrame(loser8).sort_values(by=[0], ascending=False)\r\n",
        "winner8_results = pd.DataFrame(winner8).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser8 = np.asarray(loser8_results[4:5][0])[0]\r\n",
        "median_loser8 = np.asarray(loser8_results[9:10][0])[0]\r\n",
        "upper_loser8 = np.asarray(loser8_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner8 = np.asarray(winner8_results[4:5][0])[0]\r\n",
        "median_winner8 = np.asarray(winner8_results[9:10][0])[0]\r\n",
        "upper_winner8 = np.asarray(winner8_results[14:15][0])[0]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74IRSixNGyg5"
      },
      "source": [
        "# Iteration9 :\r\n",
        "\r\n",
        "slice9 = 8\r\n",
        "\r\n",
        "loser9 = [train_regret_loser_1[slice9],\r\n",
        "       train_regret_loser_2[slice9],\r\n",
        "       train_regret_loser_3[slice9],\r\n",
        "       train_regret_loser_4[slice9],\r\n",
        "       train_regret_loser_5[slice9],\r\n",
        "       train_regret_loser_6[slice9],\r\n",
        "       train_regret_loser_7[slice9],\r\n",
        "       train_regret_loser_8[slice9],\r\n",
        "       train_regret_loser_9[slice9],\r\n",
        "       train_regret_loser_10[slice9],\r\n",
        "       train_regret_loser_11[slice9],\r\n",
        "       train_regret_loser_12[slice9],\r\n",
        "       train_regret_loser_13[slice9],\r\n",
        "       train_regret_loser_14[slice9],\r\n",
        "       train_regret_loser_15[slice9],\r\n",
        "       train_regret_loser_16[slice9],\r\n",
        "       train_regret_loser_17[slice9],\r\n",
        "       train_regret_loser_18[slice9],\r\n",
        "       train_regret_loser_19[slice9],\r\n",
        "       train_regret_loser_20[slice9]]\r\n",
        "\r\n",
        "winner9 = [train_regret_winner_1[slice9],\r\n",
        "       train_regret_winner_2[slice9],\r\n",
        "       train_regret_winner_3[slice9],\r\n",
        "       train_regret_winner_4[slice9],\r\n",
        "       train_regret_winner_5[slice9],\r\n",
        "       train_regret_winner_6[slice9],\r\n",
        "       train_regret_winner_7[slice9],\r\n",
        "       train_regret_winner_8[slice9],\r\n",
        "       train_regret_winner_9[slice9],\r\n",
        "       train_regret_winner_10[slice9],\r\n",
        "       train_regret_winner_11[slice9],\r\n",
        "       train_regret_winner_12[slice9],\r\n",
        "       train_regret_winner_13[slice9],\r\n",
        "       train_regret_winner_14[slice9],\r\n",
        "       train_regret_winner_15[slice9],\r\n",
        "       train_regret_winner_16[slice9],\r\n",
        "       train_regret_winner_17[slice9],\r\n",
        "       train_regret_winner_18[slice9],\r\n",
        "       train_regret_winner_19[slice9],\r\n",
        "       train_regret_winner_20[slice9]]\r\n",
        "\r\n",
        "loser9_results = pd.DataFrame(loser9).sort_values(by=[0], ascending=False)\r\n",
        "winner9_results = pd.DataFrame(winner9).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser9 = np.asarray(loser9_results[4:5][0])[0]\r\n",
        "median_loser9 = np.asarray(loser9_results[9:10][0])[0]\r\n",
        "upper_loser9 = np.asarray(loser9_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner9 = np.asarray(winner9_results[4:5][0])[0]\r\n",
        "median_winner9 = np.asarray(winner9_results[9:10][0])[0]\r\n",
        "upper_winner9 = np.asarray(winner9_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJDnAlE4Gyjt"
      },
      "source": [
        "# Iteration10 :\r\n",
        "\r\n",
        "slice10 = 9\r\n",
        "\r\n",
        "loser10 = [train_regret_loser_1[slice10],\r\n",
        "       train_regret_loser_2[slice10],\r\n",
        "       train_regret_loser_3[slice10],\r\n",
        "       train_regret_loser_4[slice10],\r\n",
        "       train_regret_loser_5[slice10],\r\n",
        "       train_regret_loser_6[slice10],\r\n",
        "       train_regret_loser_7[slice10],\r\n",
        "       train_regret_loser_8[slice10],\r\n",
        "       train_regret_loser_9[slice10],\r\n",
        "       train_regret_loser_10[slice10],\r\n",
        "       train_regret_loser_11[slice10],\r\n",
        "       train_regret_loser_12[slice10],\r\n",
        "       train_regret_loser_13[slice10],\r\n",
        "       train_regret_loser_14[slice10],\r\n",
        "       train_regret_loser_15[slice10],\r\n",
        "       train_regret_loser_16[slice10],\r\n",
        "       train_regret_loser_17[slice10],\r\n",
        "       train_regret_loser_18[slice10],\r\n",
        "       train_regret_loser_19[slice10],\r\n",
        "       train_regret_loser_20[slice10]]\r\n",
        "\r\n",
        "winner10 = [train_regret_winner_1[slice10],\r\n",
        "       train_regret_winner_2[slice10],\r\n",
        "       train_regret_winner_3[slice10],\r\n",
        "       train_regret_winner_4[slice10],\r\n",
        "       train_regret_winner_5[slice10],\r\n",
        "       train_regret_winner_6[slice10],\r\n",
        "       train_regret_winner_7[slice10],\r\n",
        "       train_regret_winner_8[slice10],\r\n",
        "       train_regret_winner_9[slice10],\r\n",
        "       train_regret_winner_10[slice10],\r\n",
        "       train_regret_winner_11[slice10],\r\n",
        "       train_regret_winner_12[slice10],\r\n",
        "       train_regret_winner_13[slice10],\r\n",
        "       train_regret_winner_14[slice10],\r\n",
        "       train_regret_winner_15[slice10],\r\n",
        "       train_regret_winner_16[slice10],\r\n",
        "       train_regret_winner_17[slice10],\r\n",
        "       train_regret_winner_18[slice10],\r\n",
        "       train_regret_winner_19[slice10],\r\n",
        "       train_regret_winner_20[slice10]]\r\n",
        "\r\n",
        "loser10_results = pd.DataFrame(loser10).sort_values(by=[0], ascending=False)\r\n",
        "winner10_results = pd.DataFrame(winner10).sort_values(by=[0], ascending=False)\r\n",
        "\r\n",
        "### Best training regret minimization IQR - loser:\r\n",
        "lower_loser10 = np.asarray(loser10_results[4:5][0])[0]\r\n",
        "median_loser10 = np.asarray(loser10_results[9:10][0])[0]\r\n",
        "upper_loser10 = np.asarray(loser10_results[14:15][0])[0]\r\n",
        "\r\n",
        "lower_winner10 = np.asarray(winner10_results[4:5][0])[0]\r\n",
        "median_winner10 = np.asarray(winner10_results[9:10][0])[0]\r\n",
        "upper_winner10 = np.asarray(winner10_results[14:15][0])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGDzLGoCGyl7"
      },
      "source": [
        "### Summarize arrays: 'Loser'\r\n",
        "\r\n",
        "lower_loser = [lower_loser1,\r\n",
        "            lower_loser2,\r\n",
        "            lower_loser3,\r\n",
        "            lower_loser4,\r\n",
        "            lower_loser5,\r\n",
        "            lower_loser6,\r\n",
        "            lower_loser7,\r\n",
        "            lower_loser8,\r\n",
        "            lower_loser9,\r\n",
        "            lower_loser10,\r\n",
        "            lower_loser11]\r\n",
        "\r\n",
        "median_loser = [median_loser1,\r\n",
        "            median_loser2,\r\n",
        "            median_loser3,\r\n",
        "            median_loser4,\r\n",
        "            median_loser5,\r\n",
        "            median_loser6,\r\n",
        "            median_loser7,\r\n",
        "            median_loser8,\r\n",
        "            median_loser9,\r\n",
        "            median_loser10,\r\n",
        "            median_loser11]\r\n",
        "\r\n",
        "upper_loser = [upper_loser1,\r\n",
        "            upper_loser2,\r\n",
        "            upper_loser3,\r\n",
        "            upper_loser4,\r\n",
        "            upper_loser5,\r\n",
        "            upper_loser6,\r\n",
        "            upper_loser7,\r\n",
        "            upper_loser8,\r\n",
        "            upper_loser9,\r\n",
        "            upper_loser10,\r\n",
        "            upper_loser11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0FWrtVXGyov"
      },
      "source": [
        "### Summarize arrays: 'Winner'\r\n",
        "\r\n",
        "lower_winner = [lower_winner1,\r\n",
        "            lower_winner2,\r\n",
        "            lower_winner3,\r\n",
        "            lower_winner4,\r\n",
        "            lower_winner5,\r\n",
        "            lower_winner6,\r\n",
        "            lower_winner7,\r\n",
        "            lower_winner8,\r\n",
        "            lower_winner9,\r\n",
        "            lower_winner10,\r\n",
        "            lower_winner11]\r\n",
        "\r\n",
        "median_winner = [median_winner1,\r\n",
        "            median_winner2,\r\n",
        "            median_winner3,\r\n",
        "            median_winner4,\r\n",
        "            median_winner5,\r\n",
        "            median_winner6,\r\n",
        "            median_winner7,\r\n",
        "            median_winner8,\r\n",
        "            median_winner9,\r\n",
        "            median_winner10,\r\n",
        "            median_winner11]\r\n",
        "\r\n",
        "upper_winner = [upper_winner1,\r\n",
        "            upper_winner2,\r\n",
        "            upper_winner3,\r\n",
        "            upper_winner4,\r\n",
        "            upper_winner5,\r\n",
        "            upper_winner6,\r\n",
        "            upper_winner7,\r\n",
        "            upper_winner8,\r\n",
        "            upper_winner9,\r\n",
        "            upper_winner10,\r\n",
        "            upper_winner11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1CIOmuxGyq6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "b429d8f8-636b-42f3-9127-c0b564c6a266"
      },
      "source": [
        "### Visualize!\r\n",
        "\r\n",
        "title = obj_func\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(median_loser, color = 'Red')\r\n",
        "plt.plot(median_winner, color = 'Yellow')\r\n",
        "\r\n",
        "xstar = np.arange(0, max_iter+1, step=1)\r\n",
        "plt.fill_between(xstar, lower_loser, upper_loser, facecolor = 'Red', alpha=0.4, label='GP EI Regret IQR: Newton-CG + Exact Hessian')\r\n",
        "plt.fill_between(xstar, lower_winner, upper_winner, facecolor = 'Yellow', alpha=0.4, label='GP EI Regret IQR: L-BFGS-B')\r\n",
        "\r\n",
        "plt.title(title, weight = 'bold')\r\n",
        "plt.xlabel('(Post-initialization) iteration $\\it{k}$', weight = 'bold', family = 'Arial') # x-axis label\r\n",
        "plt.ylabel('log(Regret)', weight = 'bold', family = 'Arial') # y-axis label\r\n",
        "plt.legend(loc=1) # add plot legend\r\n",
        "\r\n",
        "plt.show() #visualize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id2Uf2m8KF4T"
      },
      "source": [
        "## 'Loser' and 'Winner' are terms used to differentiate between the 1st surrogate vs. 2nd surrogate \r\n",
        "\r\n",
        "## In this example the 'Loser' surrogate i.e. Newton-CG + Exact Hessian minimizes training regret IQR versus the 'winner' i.e. L-BFGS-B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psyLOs-MGytY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ceee190-bd3e-4d61-b8b8-6fcc28f02dc3"
      },
      "source": [
        "lower_winner11, median_winner11, upper_winner11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.955060950631902, 8.878776071707552)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGJk2ehuJobR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bea6656-1840-4404-a632-6c596a05db78"
      },
      "source": [
        "y_low_win = np.exp(lower_winner11)\r\n",
        "y_median_win = np.exp(median_winner11)\r\n",
        "y_upper_win = np.exp(upper_winner11)\r\n",
        "\r\n",
        "y_low_win, y_median_win, y_upper_win"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7888.000000000001, 7746.999999999994, 7177.999999999996)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPGhgpdkfwZw",
        "outputId": "b3d08463-edd4-4ec8-f58d-e9752c2b3338"
      },
      "source": [
        "f_syn_polarity(0.5683654)\r\n",
        "\r\n",
        "## x = 56.84 days corresponds to the median training regret of y = 7,747 daily cases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5Yk6XJAIoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ea3f2f6-f403-4b17-e915-e6058f296e2d"
      },
      "source": [
        "lower_loser11, median_loser11, upper_loser11"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8.973097896282471, 8.955060950631902, 8.852521917335372)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GOrmWNtROQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a20920b-0bf3-4f95-e9c2-41ca339167f1"
      },
      "source": [
        "y_low_lose = np.exp(lower_loser11)\r\n",
        "y_median_lose = np.exp(median_loser11)\r\n",
        "y_upper_lose = np.exp(upper_loser11)\r\n",
        "\r\n",
        "y_low_lose, y_median_lose, y_upper_lose"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7888.000000000001, 7746.999999999994, 6992.000000000001)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSmOe-ZFgWDx",
        "outputId": "e4611b83-073d-4ba3-e11f-142fc34e60ca"
      },
      "source": [
        "f_syn_polarity(0.5683654)\r\n",
        "\r\n",
        "## x = 56.84 days corresponds to the median training regret of y = 7,747 daily cases"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbXDCg4So7bO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}